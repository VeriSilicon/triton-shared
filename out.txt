-- Testing: 215 tests, 16 workers --
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_nested_loop.mlir (1 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_nested_loop.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir:26:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[CST_1_:%.+]] = arith.constant 1 : index
              ^
<stdin>:2:232: note: scanning from here
 func.func @reduce_kernel_2d_0d(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
                                                                                                                                                                                                                                       ^
<stdin>:7:4: note: possible intended match here
 %c1_i32 = arith.constant 1 : i32
   ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module {
          2:  func.func @reduce_kernel_2d_0d(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
dag:26'0                                                                                                                                                                                                                                            X error: no match found
          3:  %0 = builtin.unrealized_conversion_cast %arg0 : memref<*xf32> to !tt.ptr<f32>
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c2_i32 = arith.constant 2 : i32
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %c8_i32 = arith.constant 8 : i32
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %c0_i32 = arith.constant 0 : i32
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %c1_i32 = arith.constant 1 : i32
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:26'1        ?                               possible intended match
          8:  %1 = tt.addptr %0, %arg4 : !tt.ptr<f32>, i32
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          9:  %2 = scf.for %arg13 = %c0_i32 to %c8_i32 step %c1_i32 iter_args(%arg14 = %1) -> (!tt.ptr<f32>) : i32 {
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         10:  %3 = scf.for %arg15 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg16 = %arg14) -> (!tt.ptr<f32>) : i32 {
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         11:  %4 = arith.muli %arg13, %arg15 : i32
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  %5 = arith.sitofp %4 : i32 to f32
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir (2 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir:23:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_0_:%.+]] = arith.index_cast [[PARAM_7_]] : i32 to index
              ^
<stdin>:2:440: note: scanning from here
 func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) {
                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
<stdin>:2:440: note: with "PARAM_7_" equal to "%arg13"
 func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) {
                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
<stdin>:8:2: note: possible intended match here
 %2 = arith.sitofp %arg7 : i32 to f32
 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module {
          2:  func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) {
dag:23'0                                                                                                                                                                                                                                                                                                                                                                                                                                                            X error: no match found
dag:23'1                                                                                                                                                                                                                                                                                                                                                                                                                                                              with "PARAM_7_" equal to "%arg13"
          3:  %0 = builtin.unrealized_conversion_cast %arg1 : memref<*xf32> to !tt.ptr<f32>
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c1_i32 = arith.constant 1 : i32
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %c5_i32 = arith.constant 5 : i32
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %c0_i32 = arith.constant 0 : i32
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %1 = tt.addptr %0, %arg7 : !tt.ptr<f32>, i32
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          8:  %2 = arith.sitofp %arg7 : i32 to f32
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:23'2      ?                                     possible intended match
          9:  scf.for %arg16 = %c0_i32 to %c5_i32 step %c1_i32 : i32 {
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         10:  %3 = tt.addptr %1, %arg16 : !tt.ptr<f32>, i32
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         11:  tt.store %3, %2 : !tt.ptr<f32>
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  }
dag:23'0     ~~~
         13:  return
dag:23'0     ~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_scalar.mlir (3 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_scalar.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %res, %3 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: note: see current operation: tt.store %arg1, %5 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %res, %3 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: note: see current operation: tt.store %arg1, %5 : !tt.ptr<bf16>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<bf16>, !tt.ptr<bf16>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<bf16>) -> tensor<128x!tt.ptr<bf16>>
    %3 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x!tt.ptr<bf16>>) -> tensor<128xbf16>
    %4 = "tt.reduce"(%3) <{axis = 0 : i32}> ({
    ^bb0(%arg2: bf16, %arg3: bf16):
      %5 = "arith.addf"(%arg2, %arg3) <{fastmath = #arith.fastmath<none>}> : (bf16, bf16) -> bf16
      "tt.reduce.return"(%5) : (bf16) -> ()
    }) : (tensor<128xbf16>) -> bf16
    "tt.store"(%0, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, bf16) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
!tt.ptr<bf16>
module {
  tt.func @kernel(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [128], strides: [1], offsets: [0], shape: [0], order: [] : <bf16> to tensor<128x!tt.ptr<bf16>>
    %1 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x!tt.ptr<bf16>>) -> tensor<128xbf16>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg2: bf16, %arg3: bf16):
      %4 = arith.addf %arg2, %arg3 : bf16
      tt.reduce.return %4 : bf16
    }) : (tensor<128xbf16>) -> bf16
    %3 = "tts.create_ptr"(%arg1, %c0_i32) : (!tt.ptr<bf16>, i32) -> !tt.ptr<bf16>
    tt.store %3, %2 : !tt.ptr<bf16>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:22:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_1_]] to offset: [0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
              ^
<stdin>:2:139: note: scanning from here
 func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
                                                                                                                                          ^
<stdin>:2:139: note: with "PARAM_1_" equal to "%arg1"
 func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
                                                                                                                                          ^
<stdin>:19:16: note: possible intended match here
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%c0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
               ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module {
          2:  func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
dag:22'0                                                                                                                                               X error: no match found
dag:22'1                                                                                                                                                 with "PARAM_1_" equal to "%arg1"
          3:  %c0 = arith.constant 0 : index
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %cst = arith.constant 0.000000e+00 : f32
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [128], strides: [1] : memref<*xbf16> to memref<128xbf16, strided<[1]>>
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %alloc = memref.alloc() : memref<128xbf16>
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  memref.copy %reinterpret_cast, %alloc : memref<128xbf16, strided<[1]>> to memref<128xbf16>
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         14:  %4 = arith.addf %3, %init : f32
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         15:  linalg.yield %4 : f32
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~
         16:  }
dag:22'0     ~~~
         17:  %extracted = tensor.extract %reduced[] : tensor<f32>
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         18:  %2 = arith.truncf %extracted : f32 to bf16
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         19:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%c0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:22'2                    ?                                                                                                                                             possible intended match
         20:  affine.store %2, %reinterpret_cast_0[0] : memref<1xbf16, strided<[1], offset: ?>>
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         21:  return
dag:22'0     ~~~~~~~~
         22:  }
dag:22'0     ~~~
         23: }
dag:22'0     ~~
         24:
dag:22'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_chain.mlir (4 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_chain.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: remark: PtrAnalysis: scalar loadOp will not be rewritten
      %6 = tt.load %2 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: note: see current operation: %16 = tt.load %8 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: remark: PtrAnalysis: Failed to rewrite LoadOp
      %6 = tt.load %2 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: note: see current operation: %16 = tt.load %8 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: remark: PtrAnalysis: scalar loadOp will not be rewritten
      %7 = tt.load %3 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: note: see current operation: %17 = tt.load %10 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: remark: PtrAnalysis: Failed to rewrite LoadOp
      %7 = tt.load %3 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: note: see current operation: %17 = tt.load %10 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: remark: PtrAnalysis: scalar storeOp will not be rewritten
      tt.store %4, %6 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: note: see current operation: tt.store %13, %16 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: remark: PtrAnalysis: Failed to rewrite StoreOp
      tt.store %4, %6 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: note: see current operation: tt.store %13, %16 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: remark: PtrAnalysis: scalar storeOp will not be rewritten
      tt.store %5, %7 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: note: see current operation: tt.store %15, %17 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: remark: PtrAnalysis: Failed to rewrite StoreOp
      tt.store %5, %7 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: note: see current operation: tt.store %15, %17 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<f32>) -> (), sym_name = "addptr", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 2 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 10 : i32}> : () -> i32
    %4 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
    %6 = "tt.addptr"(%1, %5) : (i32, i32) -> !tt.ptr<f32>
    %7 = "tt.addptr"(%0, %5) : (i32, i32) -> !tt.ptr<f32>
    "scf.for"(%4, %3, %2) ({
    ^bb0(%arg2: i32):
      %8 = "tt.addptr"(%6, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %9 = "tt.addptr"(%8, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %10 = "tt.addptr"(%7, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %11 = "tt.addptr"(%10, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %12 = "tt.load"(%8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<f32>) -> f32
      %13 = "tt.load"(%9) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<f32>) -> f32
      "tt.store"(%10, %12) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
      "tt.store"(%11, %13) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
      "scf.yield"() : () -> ()
    }) : (i32, i32, i32) -> ()
    "tt.return"() : () -> ()
  }) {noinline = false} : () -> ()
}) : () -> ()
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
~~~
accumulate
%6 = "arith.addi"(%1, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%7 = "tt.addptr"(%1, %5) : (i32, i32) -> !tt.ptr<f32>
~~~
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
~~~
accumulate
%8 = "arith.addi"(%0, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%9 = "tt.addptr"(%0, %5) : (i32, i32) -> !tt.ptr<f32>
~~~
%7 = "tt.addptr"(%1, %5) : (i32, i32) -> !tt.ptr<f32>
~~~
accumulate
%10 = "arith.addi"(%7, %arg2) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> i32
%11 = "tt.addptr"(%7, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
~~~
%9 = "tt.addptr"(%0, %5) : (i32, i32) -> !tt.ptr<f32>
~~~
accumulate
%13 = "arith.addi"(%9, %arg2) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> i32
%14 = "tt.addptr"(%9, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
~~~
%11 = "tt.addptr"(%7, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
!tt.ptr<f32>
%14 = "tt.addptr"(%9, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
!tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<f32>) -> (), sym_name = "addptr", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 2 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 10 : i32}> : () -> i32
    %4 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %5 = "arith.constant"() <{value = 1 : i32}> : () -> i32
    %6 = "arith.addi"(%1, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %7 = "tt.addptr"(%1, %5) : (i32, i32) -> !tt.ptr<f32>
    %8 = "arith.addi"(%0, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %9 = "tt.addptr"(%0, %5) : (i32, i32) -> !tt.ptr<f32>
    "scf.for"(%4, %3, %2) ({
    ^bb0(%arg2: i32):
      %10 = "arith.addi"(%7, %arg2) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> i32
      %11 = "tt.addptr"(%7, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %12 = "tt.addptr"(%11, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %13 = "arith.addi"(%9, %arg2) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> i32
      %14 = "tt.addptr"(%9, %arg2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %15 = "tt.addptr"(%14, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %16 = "tts.create_ptr"(%arg0, %11) : (!tt.ptr<f32>, !tt.ptr<f32>) -> !tt.ptr<f32>
      %17 = "tt.load"(%16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<f32>) -> f32
      %18 = "tt.load"(%12) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<f32>) -> f32
      %19 = "tts.create_ptr"(%arg1, %14) : (!tt.ptr<f32>, !tt.ptr<f32>) -> !tt.ptr<f32>
      "tt.store"(%19, %17) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
      "tt.store"(%15, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
      "scf.yield"() : () -> ()
    }) : (i32, i32, i32) -> ()
    "tt.return"() : () -> ()
  }) {noinline = false} : () -> ()
}) : () -> ()
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :13:12: error: 'tt.addptr' op operand #0 must be ptr or ranked tensor of ptr values, but got 'i32'
      %3 = tt.addptr %2, %c1_i32 : !tt.ptr<f32>, i32
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :13:12: note: see current operation: %9 = "tt.addptr"(%8, %5) : (i32, i32) -> !tt.ptr<f32>
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_addi_reduce.mlir (5 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_addi_reduce.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "addi", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %3 = "arith.addi"(%arg1, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
      "tt.reduce.return"(%3) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
!tt.ptr<i32>
module {
  tt.func public @addi(%arg0: !tt.ptr<i32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %2 = arith.addi %arg1, %arg2 : i32
      tt.reduce.return %2 : i32
    }) : (tensor<4096xi32>) -> i32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    tt.store %1, %0 : !tt.ptr<i32>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:19:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:2:113: note: scanning from here
 func.func @addi(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                ^
<stdin>:2:113: note: with "PARAM_0_" equal to "%arg0"
 func.func @addi(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                ^
<stdin>:15:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module {
          2:  func.func @addi(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
dag:19'0                                                                                                                     X error: no match found
dag:19'1                                                                                                                       with "PARAM_0_" equal to "%arg0"
          3:  %c0 = arith.constant 0 : index
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c0_i32 = arith.constant 0 : i32
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %0 = tensor.empty() : tensor<4096xi32>
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32>
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %2 = bufferization.alloc_tensor() : tensor<i32>
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         10:  (%in: i32, %init: i32) {
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
         11:  %3 = arith.addi %in, %init : i32
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  linalg.yield %3 : i32
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~
         13:  }
dag:19'0     ~~~
         14:  %extracted = tensor.extract %reduced[] : tensor<i32>
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         15:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:19'2                  ?                                                                                                                                           possible intended match
         16:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>>
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         17:  return
dag:19'0     ~~~~~~~~
         18:  }
dag:19'0     ~~~
         19: }
dag:19'0     ~~
         20:
dag:19'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir (6 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %c, %6 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: note: see current operation: tt.store %arg2, %14 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %c, %6 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: note: see current operation: tt.store %arg2, %14 : tensor<1024x!tt.ptr<f32>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<f32>, tensor<1024x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: tensor<1024x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %4 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %5 = "tts.load"(%3) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %6 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %7 = "arith.addf"(%5, %6) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %8 = "arith.subf"(%7, %6) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %9 = "arith.mulf"(%8, %6) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %10 = "arith.divf"(%9, %6) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    %11 = "arith.cmpf"(%10, %6) <{fastmath = #arith.fastmath<none>, predicate = 1 : i64}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xi1>
    %12 = "arith.select"(%11, %5, %6) : (tensor<1024xi1>, tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    "tt.store"(%0, %12) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
tensor<1024x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: tensor<1024x!tt.ptr<f32>>) {
    %cst = arith.constant dense<0> : tensor<1024xi32>
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %1 = tts.make_tptr %arg1 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %2 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %3 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %4 = arith.addf %2, %3 : tensor<1024xf32>
    %5 = arith.subf %4, %3 : tensor<1024xf32>
    %6 = arith.mulf %5, %3 : tensor<1024xf32>
    %7 = arith.divf %6, %3 : tensor<1024xf32>
    %8 = arith.cmpf oeq, %7, %3 : tensor<1024xf32>
    %9 = arith.select %8, %2, %3 : tensor<1024xi1>, tensor<1024xf32>
    %10 = "tts.create_ptr"(%arg2, %cst) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    tt.store %10, %9 : tensor<1024x!tt.ptr<f32>>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:32:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xf32>, [[PARAM_1_:%.+]]: memref<*xf32>, [[PARAM_2_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_3_:%.+]]: i32, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32, [[PARAM_8_:%.+]]: i32) {
               ^
<stdin>:3:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: memref<1024xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: #map = affine_map<(d0) -> (d0)>
         2: module {
         3:  func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: memref<1024xf32>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
same:32                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         4:  %c0 = arith.constant 0 : index
same:32     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1]>>
same:32     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [0], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1]>>
same:32     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %alloc = memref.alloc() : memref<1024xf32>
same:32     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         8:  memref.copy %reinterpret_cast, %alloc : memref<1024xf32, strided<[1]>> to memref<1024xf32>
same:32     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir (7 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %d, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %d, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<f32>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i1>, !tt.ptr<f32>, !tt.ptr<f32>, tensor<1024x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<i1>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: tensor<1024x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %4 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<i1>) -> tensor<1024x!tt.ptr<i1>>
    %5 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %6 = "tts.make_tptr"(%arg2) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %7 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<i1>>) -> tensor<1024xi1>
    %8 = "tts.load"(%5) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %9 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %10 = "arith.select"(%7, %8, %9) : (tensor<1024xi1>, tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
    "tt.store"(%0, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
tensor<1024x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<i1>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: tensor<1024x!tt.ptr<f32>>) {
    %cst = arith.constant dense<0> : tensor<1024xi32>
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <i1> to tensor<1024x!tt.ptr<i1>>
    %1 = tts.make_tptr %arg1 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %2 = tts.make_tptr %arg2 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %3 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<i1>>) -> tensor<1024xi1>
    %4 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %5 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %6 = arith.select %3, %4, %5 : tensor<1024xi1>, tensor<1024xf32>
    %7 = "tts.create_ptr"(%arg3, %cst) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    tt.store %7, %6 : tensor<1024x!tt.ptr<f32>>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:31:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xi1>, [[PARAM_1_:%.+]]: memref<*xf32>, [[PARAM_2_:%.+]]: memref<*xf32>, [[PARAM_3_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32, [[PARAM_8_:%.+]]: i32, [[PARAM_9_:%.+]]: i32) {
               ^
<stdin>:3:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xi1>, %arg1: memref<*xf32>, %arg2: memref<*xf32>, %arg3: memref<1024xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: #map = affine_map<(d0) -> (d0)>
         2: module {
         3:  func.func @kernel(%arg0: memref<*xi1>, %arg1: memref<*xf32>, %arg2: memref<*xf32>, %arg3: memref<1024xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
same:31                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         4:  %c0 = arith.constant 0 : index
same:31     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [1024], strides: [1] : memref<*xi1> to memref<1024xi1, strided<[1]>>
same:31     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [0], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1]>>
same:31     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1]>>
same:31     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         8:  %alloc = memref.alloc() : memref<1024xi1>
same:31     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir (8 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 128 : index}> : () -> index
    %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<128x128xf32>}> : () -> tensor<128x128xf32>
    %4 = "arith.constant"() <{value = 3 : index}> : () -> index
    %5 = "arith.constant"() <{value = 12 : index}> : () -> index
    %6 = "arith.constant"() <{value = 0 : index}> : () -> index
    %7 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
    %8 = "arith.muli"(%7, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %9 = "arith.index_cast"(%8) : (i32) -> index
    %10 = "tt.addptr"(%0, %8) : (i32, i32) -> !tt.ptr<f32>
    %11:3 = "scf.for"(%6, %5, %4, %3, %10, %9) ({
    ^bb0(%arg5: index, %arg6: tensor<128x128xf32>, %arg7: !tt.ptr<f32>, %arg8: index):
      %16 = "arith.addi"(%arg8, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %17 = "tts.make_tptr"(%arg1, %16) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
      %18 = "tts.load"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
      %19 = "math.exp"(%18) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
      %20 = "arith.addf"(%arg6, %19) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
      %21 = "arith.index_cast"(%arg5) : (index) -> i32
      %22 = "arith.addi"(%arg8, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %23 = "tt.addptr"(%arg7, %21) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      "scf.yield"(%20, %23, %22) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
    }) : (index, index, index, tensor<128x128xf32>, !tt.ptr<f32>, index) -> (tensor<128x128xf32>, !tt.ptr<f32>, index)
    %12 = "arith.muli"(%7, %arg3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %13 = "arith.index_cast"(%12) : (i32) -> index
    %14 = "arith.addi"(%13, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
    %15 = "tts.make_tptr"(%arg0, %14) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
    "tts.store"(%15, %11#0) <{static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
~~~
accumulate
%10 = "arith.addi"(%0, %8) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%11 = "tt.addptr"(%0, %8) : (i32, i32) -> !tt.ptr<f32>
~~~
%11 = "tt.addptr"(%0, %8) : (i32, i32) -> !tt.ptr<f32>
arg number: 4
init arg size
3
num region iter-args
3
dump from that index
iter arg
init arg
%3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<128x128xf32>}> : () -> tensor<128x128xf32>
%11 = "tt.addptr"(%0, %8) : (i32, i32) -> !tt.ptr<f32>
%9 = "arith.index_cast"(%8) : (i32) -> index
<block argument> of type 'i32' at index: 2
~~~
accumulate
%24 = "arith.addi"(%arg7, %22) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%25 = "tt.addptr"(%arg7, %22) : (i32, i32) -> !tt.ptr<f32>
~~~
%12:3 = "scf.for"(%6, %5, %4, %3, %11, %9) ({
^bb0(%arg5: index, %arg6: tensor<128x128xf32>, %arg7: i32, %arg8: index):
  %17 = "arith.addi"(%arg8, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %18 = "tts.make_tptr"(%arg1, %17) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
  %19 = "tts.load"(%18) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
  %20 = "math.exp"(%19) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
  %21 = "arith.addf"(%arg6, %20) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
  %22 = "arith.index_cast"(%arg5) : (index) -> i32
  %23 = "arith.addi"(%arg8, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %24 = "arith.addi"(%arg7, %22) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %25 = "tt.addptr"(%arg7, %22) : (i32, i32) -> !tt.ptr<f32>
  "scf.yield"(%21, %25, %23) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
}) : (index, index, index, tensor<128x128xf32>, !tt.ptr<f32>, index) -> (tensor<128x128xf32>, i32, index)
%25 = "tt.addptr"(%arg7, %22) : (i32, i32) -> !tt.ptr<f32>
++++++++++++++
yield op
"scf.yield"(%21, %25, %23) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
val index: 1
%25 = "tt.addptr"(%arg7, %22) : (i32, i32) -> !tt.ptr<f32>
++++++++++++++
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 128 : index}> : () -> index
    %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<128x128xf32>}> : () -> tensor<128x128xf32>
    %4 = "arith.constant"() <{value = 3 : index}> : () -> index
    %5 = "arith.constant"() <{value = 12 : index}> : () -> index
    %6 = "arith.constant"() <{value = 0 : index}> : () -> index
    %7 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
    %8 = "arith.muli"(%7, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %9 = "arith.index_cast"(%8) : (i32) -> index
    %10 = "arith.addi"(%0, %8) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %11 = "tt.addptr"(%0, %8) : (i32, i32) -> !tt.ptr<f32>
    %12:3 = "scf.for"(%6, %5, %4, %3, %11, %9) ({
    ^bb0(%arg5: index, %arg6: tensor<128x128xf32>, %arg7: i32, %arg8: index):
      %17 = "arith.addi"(%arg8, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %18 = "tts.make_tptr"(%arg1, %17) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
      %19 = "tts.load"(%18) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
      %20 = "math.exp"(%19) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
      %21 = "arith.addf"(%arg6, %20) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
      %22 = "arith.index_cast"(%arg5) : (index) -> i32
      %23 = "arith.addi"(%arg8, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %24 = "arith.addi"(%arg7, %22) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
      %25 = "tt.addptr"(%arg7, %22) : (i32, i32) -> !tt.ptr<f32>
      "scf.yield"(%21, %25, %23) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
    }) : (index, index, index, tensor<128x128xf32>, !tt.ptr<f32>, index) -> (tensor<128x128xf32>, i32, index)
    %13 = "arith.muli"(%7, %arg3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %14 = "arith.index_cast"(%13) : (i32) -> index
    %15 = "arith.addi"(%14, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
    %16 = "tts.make_tptr"(%arg0, %15) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
    "tts.store"(%16, %12#0) <{static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir:70:11: error: CHECK: expected string not found in input
// CHECK: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_1_]] to offset: {{.}}[[VAR_3_]]{{.}}, sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
          ^
<stdin>:12:41: note: scanning from here
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:12:41: note: with "PARAM_1_" equal to "%arg1"
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:12:41: note: with "VAR_3_" equal to "%3"
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:15:18: note: possible intended match here
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%8], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1], offset: ?>>
                 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            .
            .
            .
            7:  %c128 = arith.constant 128 : index
            8:  %cst = arith.constant 0.000000e+00 : f32
            9:  %0 = tensor.empty() : tensor<128x128xf32>
           10:  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<128x128xf32>) -> tensor<128x128xf32>
           11:  %2 = arith.muli %arg8, %arg2 : i32
           12:  %3 = arith.index_cast %2 : i32 to index
check:70'0                                             X error: no match found
check:70'1                                               with "PARAM_1_" equal to "%arg1"
check:70'2                                               with "VAR_3_" equal to "%3"
           13:  %4:3 = scf.for %arg11 = %c0 to %c12 step %c3 iter_args(%arg12 = %1, %arg13 = %2, %arg14 = %3) -> (tensor<128x128xf32>, i32, index) {
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           14:  %8 = arith.addi %arg14, %c128 : index
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           15:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%8], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1], offset: ?>>
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:70'3                      ?                                                                                                                                                           possible intended match
           16:  %alloc = memref.alloc() : memref<128x128xf32>
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           17:  memref.copy %reinterpret_cast_0, %alloc : memref<128x128xf32, strided<[1, 1], offset: ?>> to memref<128x128xf32>
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           18:  %9 = bufferization.to_tensor %alloc restrict writable : memref<128x128xf32>
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           19:  %10 = linalg.generic {indexing_maps = [#map, #map], iterator_types = ["parallel", "parallel"]} ins(%9 : tensor<128x128xf32>) outs(%9 : tensor<128x128xf32>) {
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           20:  ^bb0(%in: f32, %out: f32):
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            .
            .
            .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir (9 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>) -> (), sym_name = "maxnumf", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<4096xf32>}> : () -> tensor<4096xf32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32, %arg2: f32):
      %3 = "arith.maxnumf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
      "tt.reduce.return"(%3) : (f32) -> ()
    }) : (tensor<4096xf32>) -> f32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
!tt.ptr<f32>
module {
  tt.func public @maxnumf(%arg0: !tt.ptr<f32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0.000000e+00> : tensor<4096xf32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32, %arg2: f32):
      %2 = arith.maxnumf %arg1, %arg2 : f32
      tt.reduce.return %2 : f32
    }) : (tensor<4096xf32>) -> f32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    tt.store %1, %0 : !tt.ptr<f32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>) -> (), sym_name = "minnumf", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<4096xf32>}> : () -> tensor<4096xf32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32, %arg2: f32):
      %3 = "arith.minnumf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>}> : (f32, f32) -> f32
      "tt.reduce.return"(%3) : (f32) -> ()
    }) : (tensor<4096xf32>) -> f32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
!tt.ptr<f32>
module {
  tt.func public @minnumf(%arg0: !tt.ptr<f32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0.000000e+00> : tensor<4096xf32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32, %arg2: f32):
      %2 = arith.minnumf %arg1, %arg2 : f32
      tt.reduce.return %2 : f32
    }) : (tensor<4096xf32>) -> f32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    tt.store %1, %0 : !tt.ptr<f32>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:20:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:2:116: note: scanning from here
 func.func @maxnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:2:116: note: with "PARAM_0_" equal to "%arg0"
 func.func @maxnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:16:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:57:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:24:116: note: scanning from here
 func.func @minnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:24:116: note: with "PARAM_0_" equal to "%arg0"
 func.func @minnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:38:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module {
          2:  func.func @maxnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
dag:20'0                                                                                                                        X error: no match found
dag:20'1                                                                                                                          with "PARAM_0_" equal to "%arg0"
          3:  %c0 = arith.constant 0 : index
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %cst = arith.constant 0xFF800000 : f32
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %cst_0 = arith.constant 0.000000e+00 : f32
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %0 = tensor.empty() : tensor<4096xf32>
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<4096xf32>) -> tensor<4096xf32>
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         11:  (%in: f32, %init: f32) {
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  %3 = arith.maxnumf %in, %init : f32
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         13:  linalg.yield %3 : f32
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~
         14:  }
dag:20'0     ~~~
         15:  %extracted = tensor.extract %reduced[] : tensor<f32>
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         16:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:20'2                  ?                                                                                                                                           possible intended match
         17:  affine.store %extracted, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>>
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         18:  return
dag:20'0     ~~~~~~~~
         19:  }
dag:20'0     ~~~
         20: }
dag:20'0     ~~
         21:
dag:20'0     ~
         22: // -----
dag:20'0     ~~~~~~~~~
         23: module {
dag:20'0     ~~~~~~~~~
         24:  func.func @minnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
dag:20'0     ~~~~~~~~~~~~~~~~~~~
dag:57'0                                                                                                                        X error: no match found
dag:57'1                                                                                                                          with "PARAM_0_" equal to "%arg0"
         25:  %c0 = arith.constant 0 : index
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         26:  %cst = arith.constant 0x7F800000 : f32
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         27:  %cst_0 = arith.constant 0.000000e+00 : f32
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         28:  %0 = tensor.empty() : tensor<4096xf32>
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         29:  %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<4096xf32>) -> tensor<4096xf32>
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         33:  (%in: f32, %init: f32) {
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
         34:  %3 = arith.minnumf %in, %init : f32
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         35:  linalg.yield %3 : f32
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~
         36:  }
dag:57'0     ~~~
         37:  %extracted = tensor.extract %reduced[] : tensor<f32>
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         38:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:57'2                  ?                                                                                                                                           possible intended match
         39:  affine.store %extracted, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>>
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         40:  return
dag:57'0     ~~~~~~~~
         41:  }
dag:57'0     ~~~
         42: }
dag:57'0     ~~
         43:
dag:57'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_splat_float.mlir (10 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_splat_float.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %save0, %0 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: note: see current operation: tt.store %arg2, %0 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %save0, %0 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: note: see current operation: tt.store %arg2, %0 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %save1, %1 : tensor<128x256x!tt.ptr<bf16>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: note: see current operation: tt.store %arg3, %1 : tensor<128x256x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %save1, %1 : tensor<128x256x!tt.ptr<bf16>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: note: see current operation: tt.store %arg3, %1 : tensor<128x256x!tt.ptr<bf16>>
"builtin.module"() ({
  "tt.func"() <{function_type = (f32, bf16, tensor<1024x!tt.ptr<f32>>, tensor<128x256x!tt.ptr<bf16>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: f32, %arg1: bf16, %arg2: tensor<1024x!tt.ptr<f32>>, %arg3: tensor<128x256x!tt.ptr<bf16>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<128x256xi32>}> : () -> tensor<128x256xi32>
    %1 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %2 = "tt.splat"(%arg0) : (f32) -> tensor<1024xf32>
    %3 = "tt.splat"(%arg1) : (bf16) -> tensor<128x256xbf16>
    "tt.store"(%1, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.store"(%0, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x256xi32>, tensor<128x256xbf16>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%1 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
tensor<1024x!tt.ptr<f32>>
%0 = "arith.constant"() <{value = dense<0> : tensor<128x256xi32>}> : () -> tensor<128x256xi32>
tensor<128x256x!tt.ptr<bf16>>
module {
  tt.func @kernel(%arg0: f32, %arg1: bf16, %arg2: tensor<1024x!tt.ptr<f32>>, %arg3: tensor<128x256x!tt.ptr<bf16>>) {
    %cst = arith.constant dense<0> : tensor<128x256xi32>
    %cst_0 = arith.constant dense<0> : tensor<1024xi32>
    %0 = tt.splat %arg0 : f32 -> tensor<1024xf32>
    %1 = tt.splat %arg1 : bf16 -> tensor<128x256xbf16>
    %2 = "tts.create_ptr"(%arg2, %cst_0) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    tt.store %2, %0 : tensor<1024x!tt.ptr<f32>>
    %3 = "tts.create_ptr"(%arg3, %cst) : (tensor<128x256x!tt.ptr<bf16>>, tensor<128x256xi32>) -> tensor<128x256x!tt.ptr<bf16>>
    tt.store %3, %1 : tensor<128x256x!tt.ptr<bf16>>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:16:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: f32, [[PARAM_1_:%.+]]: bf16, [[PARAM_2_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_3_:%.+]]: tensor<128x256x!tt.ptr<bf16>>, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32, [[PARAM_8_:%.+]]: i32, [[PARAM_9_:%.+]]: i32) {
               ^
<stdin>:2:19: note: scanning from here
 func.func @kernel(%arg0: f32, %arg1: bf16, %arg2: memref<1024xf32>, %arg3: memref<128x256xbf16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: module {
         2:  func.func @kernel(%arg0: f32, %arg1: bf16, %arg2: memref<1024xf32>, %arg3: memref<128x256xbf16>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
same:16                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         3:  %c0 = arith.constant 0 : index
same:16     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         4:  affine.for %arg10 = 0 to 1024 {
same:16     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  memref.store %arg0, %arg2[%c0] : memref<1024xf32>
same:16     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  }
same:16     ~~~
         7:  %collapse_shape = memref.collapse_shape %arg3 [[0, 1]] : memref<128x256xbf16> into memref<32768xbf16>
same:16     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir (11 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
      tt.store %arg11, %2 : !tt.ptr<f32>
      ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: note: see current operation: tt.store %arg11, %3 : !tt.ptr<f32>
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: remark: PtrAnalysis: Failed to rewrite StoreOp
      tt.store %arg11, %2 : !tt.ptr<f32>
      ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: note: see current operation: tt.store %arg11, %3 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, {}, {}, {}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "reduce_kernel_2d_0d1d2de3de"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 1 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 5 : i32}> : () -> i32
    %4 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %5 = "arith.index_cast"(%arg7) : (i32) -> index
    %6 = "tt.addptr"(%0, %arg7) : (i32, i32) -> !tt.ptr<f32>
    %7 = "arith.sitofp"(%arg7) : (i32) -> f32
    %8:3 = "scf.for"(%4, %3, %2, %6, %5, %5) ({
    ^bb0(%arg10: i32, %arg11: !tt.ptr<f32>, %arg12: index, %arg13: index):
      "tt.store"(%arg11, %7) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
      %9 = "arith.index_cast"(%arg10) : (i32) -> index
      %10 = "arith.addi"(%arg12, %9) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %11 = "tt.addptr"(%arg11, %arg10) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %12 = "arith.addi"(%arg13, %9) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      "scf.yield"(%11, %10, %12) : (!tt.ptr<f32>, index, index) -> ()
    }) : (i32, i32, i32, !tt.ptr<f32>, index, index) -> (!tt.ptr<f32>, index, index)
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
~~~
accumulate
%6 = "arith.addi"(%0, %arg7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%7 = "tt.addptr"(%0, %arg7) : (i32, i32) -> !tt.ptr<f32>
~~~
%7 = "tt.addptr"(%0, %arg7) : (i32, i32) -> !tt.ptr<f32>
arg number: 3
init arg size
3
num region iter-args
3
dump from that index
iter arg
init arg
%7 = "tt.addptr"(%0, %arg7) : (i32, i32) -> !tt.ptr<f32>
%5 = "arith.index_cast"(%arg7) : (i32) -> index
%5 = "arith.index_cast"(%arg7) : (i32) -> index
<block argument> of type 'i32' at index: 1
!tt.ptr<f32>
%9:3 = "scf.for"(%4, %3, %2, %7, %5, %5) ({
^bb0(%arg10: i32, %arg11: i32, %arg12: index, %arg13: index):
  %10 = "tts.create_ptr"(%arg1, %arg11) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
  "tt.store"(%10, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
  %11 = "arith.index_cast"(%arg10) : (i32) -> index
  %12 = "arith.addi"(%arg12, %11) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %13 = "tt.addptr"(%arg11, %arg10) : (i32, i32) -> !tt.ptr<f32>
  %14 = "arith.addi"(%arg13, %11) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  "scf.yield"(%13, %12, %14) : (!tt.ptr<f32>, index, index) -> ()
}) : (i32, i32, i32, !tt.ptr<f32>, index, index) -> (i32, index, index)
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, {}, {}, {}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "reduce_kernel_2d_0d1d2de3de"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 1 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 5 : i32}> : () -> i32
    %4 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %5 = "arith.index_cast"(%arg7) : (i32) -> index
    %6 = "arith.addi"(%0, %arg7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %7 = "tt.addptr"(%0, %arg7) : (i32, i32) -> !tt.ptr<f32>
    %8 = "arith.sitofp"(%arg7) : (i32) -> f32
    %9:3 = "scf.for"(%4, %3, %2, %7, %5, %5) ({
    ^bb0(%arg10: i32, %arg11: i32, %arg12: index, %arg13: index):
      %10 = "tts.create_ptr"(%arg1, %arg11) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      "tt.store"(%10, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
      %11 = "arith.index_cast"(%arg10) : (i32) -> index
      %12 = "arith.addi"(%arg12, %11) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %13 = "tt.addptr"(%arg11, %arg10) : (i32, i32) -> !tt.ptr<f32>
      %14 = "arith.addi"(%arg13, %11) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      "scf.yield"(%13, %12, %14) : (!tt.ptr<f32>, index, index) -> ()
    }) : (i32, i32, i32, !tt.ptr<f32>, index, index) -> (i32, index, index)
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:13:12: error: 'tt.addptr' op operand #0 must be ptr or ranked tensor of ptr values, but got 'i32'
      %4 = tt.addptr %arg11, %arg10 : !tt.ptr<f32>, i32
           ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:13:12: note: see current operation: %12 = "tt.addptr"(%arg11, %arg10) : (i32, i32) -> !tt.ptr<f32>
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for.mlir (12 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1024xf32>}> : () -> tensor<1024xf32>
    %3 = "arith.constant"() <{value = 3 : index}> : () -> index
    %4 = "arith.constant"() <{value = 12 : index}> : () -> index
    %5 = "arith.constant"() <{value = 0 : index}> : () -> index
    %6 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
    %7 = "arith.muli"(%6, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %8 = "arith.index_cast"(%7) : (i32) -> index
    %9 = "tt.addptr"(%0, %7) : (i32, i32) -> !tt.ptr<f32>
    %10:3 = "scf.for"(%5, %4, %3, %9, %8, %2) ({
    ^bb0(%arg5: index, %arg6: !tt.ptr<f32>, %arg7: index, %arg8: tensor<1024xf32>):
      %14 = "tts.make_tptr"(%arg1, %arg7) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
      %15 = "tts.load"(%14) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
      %16 = "math.exp"(%15) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
      %17 = "arith.addf"(%arg8, %16) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
      %18 = "arith.index_cast"(%arg5) : (index) -> i32
      %19 = "arith.addi"(%arg7, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %20 = "tt.addptr"(%arg6, %18) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      "scf.yield"(%20, %19, %17) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
    }) : (index, index, index, !tt.ptr<f32>, index, tensor<1024xf32>) -> (!tt.ptr<f32>, index, tensor<1024xf32>)
    %11 = "arith.muli"(%6, %arg3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %12 = "arith.index_cast"(%11) : (i32) -> index
    %13 = "tts.make_tptr"(%arg0, %12) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
    "tts.store"(%13, %10#2) <{static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
~~~
accumulate
%9 = "arith.addi"(%0, %7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%10 = "tt.addptr"(%0, %7) : (i32, i32) -> !tt.ptr<f32>
~~~
%10 = "tt.addptr"(%0, %7) : (i32, i32) -> !tt.ptr<f32>
arg number: 3
init arg size
3
num region iter-args
3
dump from that index
iter arg
init arg
%10 = "tt.addptr"(%0, %7) : (i32, i32) -> !tt.ptr<f32>
%8 = "arith.index_cast"(%7) : (i32) -> index
%2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1024xf32>}> : () -> tensor<1024xf32>
<block argument> of type 'i32' at index: 1
~~~
accumulate
%21 = "arith.addi"(%arg6, %19) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%22 = "tt.addptr"(%arg6, %19) : (i32, i32) -> !tt.ptr<f32>
~~~
%11:3 = "scf.for"(%5, %4, %3, %10, %8, %2) ({
^bb0(%arg5: index, %arg6: i32, %arg7: index, %arg8: tensor<1024xf32>):
  %15 = "tts.make_tptr"(%arg1, %arg7) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
  %16 = "tts.load"(%15) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
  %17 = "math.exp"(%16) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
  %18 = "arith.addf"(%arg8, %17) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
  %19 = "arith.index_cast"(%arg5) : (index) -> i32
  %20 = "arith.addi"(%arg7, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %21 = "arith.addi"(%arg6, %19) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
  %22 = "tt.addptr"(%arg6, %19) : (i32, i32) -> !tt.ptr<f32>
  "scf.yield"(%22, %20, %18) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
}) : (index, index, index, !tt.ptr<f32>, index, tensor<1024xf32>) -> (i32, index, tensor<1024xf32>)
%22 = "tt.addptr"(%arg6, %19) : (i32, i32) -> !tt.ptr<f32>
++++++++++++++
yield op
"scf.yield"(%22, %20, %18) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
val index: 0
%22 = "tt.addptr"(%arg6, %19) : (i32, i32) -> !tt.ptr<f32>
++++++++++++++
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1024xf32>}> : () -> tensor<1024xf32>
    %3 = "arith.constant"() <{value = 3 : index}> : () -> index
    %4 = "arith.constant"() <{value = 12 : index}> : () -> index
    %5 = "arith.constant"() <{value = 0 : index}> : () -> index
    %6 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
    %7 = "arith.muli"(%6, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %8 = "arith.index_cast"(%7) : (i32) -> index
    %9 = "arith.addi"(%0, %7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %10 = "tt.addptr"(%0, %7) : (i32, i32) -> !tt.ptr<f32>
    %11:3 = "scf.for"(%5, %4, %3, %10, %8, %2) ({
    ^bb0(%arg5: index, %arg6: i32, %arg7: index, %arg8: tensor<1024xf32>):
      %15 = "tts.make_tptr"(%arg1, %arg7) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
      %16 = "tts.load"(%15) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
      %17 = "math.exp"(%16) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
      %18 = "arith.addf"(%arg8, %17) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
      %19 = "arith.index_cast"(%arg5) : (index) -> i32
      %20 = "arith.addi"(%arg7, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %21 = "arith.addi"(%arg6, %19) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
      %22 = "tt.addptr"(%arg6, %19) : (i32, i32) -> !tt.ptr<f32>
      "scf.yield"(%22, %20, %18) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
    }) : (index, index, index, !tt.ptr<f32>, index, tensor<1024xf32>) -> (i32, index, tensor<1024xf32>)
    %12 = "arith.muli"(%6, %arg3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %13 = "arith.index_cast"(%12) : (i32) -> index
    %14 = "tts.make_tptr"(%arg0, %13) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
    "tts.store"(%14, %11#2) <{static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir:50:11: error: CHECK: expected string not found in input
// CHECK: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_1_]] to offset: {{.}}[[VAR_3_]]{{.}}, sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
          ^
<stdin>:11:41: note: scanning from here
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:11:41: note: with "PARAM_1_" equal to "%arg1"
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:11:41: note: with "VAR_3_" equal to "%3"
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:34:18: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%6], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1], offset: ?>>
                 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            .
            .
            .
            6:  %c3 = arith.constant 3 : index
            7:  %cst = arith.constant 0.000000e+00 : f32
            8:  %0 = tensor.empty() : tensor<1024xf32>
            9:  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1024xf32>) -> tensor<1024xf32>
           10:  %2 = arith.muli %arg8, %arg2 : i32
           11:  %3 = arith.index_cast %2 : i32 to index
check:50'0                                             X error: no match found
check:50'1                                               with "PARAM_1_" equal to "%arg1"
check:50'2                                               with "VAR_3_" equal to "%3"
           12:  %4:3 = scf.for %arg11 = %c0 to %c12 step %c3 iter_args(%arg12 = %2, %arg13 = %3, %arg14 = %1) -> (i32, index, tensor<1024xf32>) {
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           13:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%arg13], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1], offset: ?>>
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           14:  %alloc = memref.alloc() : memref<1024xf32>
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           15:  memref.copy %reinterpret_cast_0, %alloc : memref<1024xf32, strided<[1], offset: ?>> to memref<1024xf32>
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           16:  %7 = bufferization.to_tensor %alloc restrict writable : memref<1024xf32>
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            .
            .
            .
           29:  %12 = arith.addi %arg12, %10 : i32
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           30:  scf.yield %12, %11, %9 : i32, index, tensor<1024xf32>
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           31:  }
check:50'0     ~~~
           32:  %5 = arith.muli %arg8, %arg3 : i32
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           33:  %6 = arith.index_cast %5 : i32 to index
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           34:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%6], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1], offset: ?>>
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:50'3                      ?                                                                                                                                            possible intended match
           35:  bufferization.materialize_in_destination %4#2 in writable %reinterpret_cast : (tensor<1024xf32>, memref<1024xf32, strided<[1], offset: ?>>) -> ()
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           36:  return
check:50'0     ~~~~~~~~
           37:  }
check:50'0     ~~~
           38: }
check:50'0     ~~
           39:
check:50'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_loopback.mlir (13 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_loopback.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: remark: PtrAnalysis: scalar loadOp will not be rewritten
    %10 = tt.load %0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false}: !tt.ptr<bf16>
          ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: note: see current operation: %4 = tt.load %1 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: remark: PtrAnalysis: Failed to rewrite LoadOp
    %10 = tt.load %0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false}: !tt.ptr<bf16>
          ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: note: see current operation: %4 = tt.load %1 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: remark: PtrAnalysis: scalar storeOp will not be rewritten
    tt.store %1, %10 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: note: see current operation: tt.store %3, %4 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %1, %10 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: note: see current operation: tt.store %3, %4 : !tt.ptr<bf16>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<bf16>, !tt.ptr<bf16>, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "tt.addptr"(%1, %arg2) : (i32, i32) -> !tt.ptr<bf16>
    %3 = "tt.addptr"(%0, %arg2) : (i32, i32) -> !tt.ptr<bf16>
    %4 = "tt.load"(%2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<bf16>) -> bf16
    "tt.store"(%3, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<bf16>, bf16) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
~~~
accumulate
%2 = "arith.addi"(%1, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%3 = "tt.addptr"(%1, %arg2) : (i32, i32) -> !tt.ptr<bf16>
~~~
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
~~~
accumulate
%4 = "arith.addi"(%0, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%5 = "tt.addptr"(%0, %arg2) : (i32, i32) -> !tt.ptr<bf16>
~~~
%3 = "tt.addptr"(%1, %arg2) : (i32, i32) -> !tt.ptr<bf16>
!tt.ptr<bf16>
%5 = "tt.addptr"(%0, %arg2) : (i32, i32) -> !tt.ptr<bf16>
!tt.ptr<bf16>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<bf16>, !tt.ptr<bf16>, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.addi"(%1, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %3 = "tt.addptr"(%1, %arg2) : (i32, i32) -> !tt.ptr<bf16>
    %4 = "arith.addi"(%0, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %5 = "tt.addptr"(%0, %arg2) : (i32, i32) -> !tt.ptr<bf16>
    %6 = "tts.create_ptr"(%arg0, %3) : (!tt.ptr<bf16>, !tt.ptr<bf16>) -> !tt.ptr<bf16>
    %7 = "tt.load"(%6) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (!tt.ptr<bf16>) -> bf16
    %8 = "tts.create_ptr"(%arg1, %5) : (!tt.ptr<bf16>, !tt.ptr<bf16>) -> !tt.ptr<bf16>
    "tt.store"(%8, %7) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<bf16>, bf16) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:22:11: error: CHECK: expected string not found in input
// CHECK: [[LOAD_VAR_reinterpret_cast_MEM_:%.+]] = affine.load [[VAR_reinterpret_cast_]][0] : memref<1xbf16, strided<[1], offset: ?>>
          ^
<stdin>:6:155: note: scanning from here
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
                                                                                                                                                          ^
<stdin>:6:155: note: with "VAR_reinterpret_cast_" equal to "%reinterpret_cast"
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
                                                                                                                                                          ^
<stdin>:7:19: note: possible intended match here
 affine.store %1, %reinterpret_cast_0[0] : memref<1xbf16, strided<[1], offset: ?>>
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            1: module {
            2:  func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
            3:  %0 = arith.index_cast %arg2 : i32 to index
            4:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
            5:  %1 = affine.load %reinterpret_cast[0] : memref<1xbf16, strided<[1], offset: ?>>
            6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
check:22'0                                                                                                                                                               X error: no match found
check:22'1                                                                                                                                                                 with "VAR_reinterpret_cast_" equal to "%reinterpret_cast"
            7:  affine.store %1, %reinterpret_cast_0[0] : memref<1xbf16, strided<[1], offset: ?>>
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:22'2                       ?                                                                 possible intended match
            8:  return
check:22'0     ~~~~~~~~
            9:  }
check:22'0     ~~~
           10: }
check:22'0     ~~
           11:
check:22'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir (14 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %res, %6 : tensor<256x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: note: see current operation: tt.store %arg1, %19 : tensor<256x16x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %res, %6 : tensor<256x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: note: see current operation: tt.store %arg1, %19 : tensor<256x16x!tt.ptr<bf16>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<bf16>, tensor<256x16x!tt.ptr<bf16>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<bf16>, %arg1: tensor<256x16x!tt.ptr<bf16>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<256x16xi32>}> : () -> tensor<256x16xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 256 : index}> : () -> index
    %3 = "tts.make_tptr"(%arg0, %2) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, order = array<i32>, sizes = array<i64: 32, 256, 16>, static_offsets = array<i64: 0, 0, 0>, static_shape = array<i64: 0, 0, 0>, static_strides = array<i64: -9223372036854775808, 1, 1>}> : (!tt.ptr<bf16>, index) -> tensor<32x256x16x!tt.ptr<bf16>>
    %4 = "tts.load"(%3) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<32x256x16x!tt.ptr<bf16>>) -> tensor<32x256x16xbf16>
    %5 = "tt.reduce"(%4) <{axis = 0 : i32}> ({
    ^bb0(%arg2: bf16, %arg3: bf16):
      %6 = "arith.cmpf"(%arg2, %arg3) <{fastmath = #arith.fastmath<none>, predicate = 2 : i64}> : (bf16, bf16) -> i1
      %7 = "arith.select"(%6, %arg2, %arg3) : (i1, bf16, bf16) -> bf16
      "tt.reduce.return"(%7) : (bf16) -> ()
    }) : (tensor<32x256x16xbf16>) -> tensor<256x16xbf16>
    "tt.store"(%0, %5) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<256x16xi32>, tensor<256x16xbf16>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%0 = "arith.constant"() <{value = dense<0> : tensor<256x16xi32>}> : () -> tensor<256x16xi32>
tensor<256x16x!tt.ptr<bf16>>
module {
  tt.func @kernel(%arg0: !tt.ptr<bf16>, %arg1: tensor<256x16x!tt.ptr<bf16>>) {
    %cst = arith.constant dense<0> : tensor<256x16xi32>
    %c0_i32 = arith.constant 0 : i32
    %c256 = arith.constant 256 : index
    %0 = tts.make_tptr %arg0 to sizes: [32, 256, 16], strides: [%c256, 1, 1], offsets: [0, 0, 0], shape: [0, 0, 0], order: [] : <bf16> to tensor<32x256x16x!tt.ptr<bf16>>
    %1 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<32x256x16x!tt.ptr<bf16>>) -> tensor<32x256x16xbf16>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg2: bf16, %arg3: bf16):
      %4 = arith.cmpf ogt, %arg2, %arg3 : bf16
      %5 = arith.select %4, %arg2, %arg3 : bf16
      tt.reduce.return %5 : bf16
    }) : (tensor<32x256x16xbf16>) -> tensor<256x16xbf16>
    %3 = "tts.create_ptr"(%arg1, %cst) : (tensor<256x16x!tt.ptr<bf16>>, tensor<256x16xi32>) -> tensor<256x16x!tt.ptr<bf16>>
    tt.store %3, %2 : tensor<256x16x!tt.ptr<bf16>>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:43:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xbf16>, [[PARAM_1_:%.+]]: tensor<256x16x!tt.ptr<bf16>>, [[PARAM_2_:%.+]]: i32, [[PARAM_3_:%.+]]: i32, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32) {
               ^
<stdin>:2:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<256x16xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: module {
         2:  func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<256x16xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
same:43                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         3:  %c0 = arith.constant 0 : index
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         4:  %cst = arith.constant 0xFF80 : bf16
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %c256 = arith.constant 256 : index
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [32, 256, 16], strides: [%c256, 1, 1] : memref<*xbf16> to memref<32x256x16xbf16, strided<[?, 1, 1]>>
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %alloc = memref.alloc() : memref<32x256x16xbf16>
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir (15 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %c, %res0 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: note: see current operation: tt.store %arg2, %15 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %c, %res0 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: note: see current operation: tt.store %arg2, %15 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %d, %res1 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: note: see current operation: tt.store %arg3, %16 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %d, %res1 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: note: see current operation: tt.store %arg3, %16 : tensor<128x128x!tt.ptr<f32>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<f32>, tensor<128x128x!tt.ptr<f32>>, tensor<128x128x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: tensor<128x128x!tt.ptr<f32>>, %arg3: tensor<128x128x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %1 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %4 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %5 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %6 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %7 = "tts.load"(%5) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %8 = "arith.addf"(%6, %7) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
    %9 = "arith.subf"(%6, %7) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
    "tt.store"(%1, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.store"(%0, %9) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%1 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
tensor<128x128x!tt.ptr<f32>>
%0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
tensor<128x128x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: tensor<128x128x!tt.ptr<f32>>, %arg3: tensor<128x128x!tt.ptr<f32>>) {
    %cst = arith.constant dense<0> : tensor<128x128xi32>
    %cst_0 = arith.constant dense<0> : tensor<128x128xi32>
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %1 = tts.make_tptr %arg1 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %2 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %3 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %4 = arith.addf %2, %3 : tensor<128x128xf32>
    %5 = arith.subf %2, %3 : tensor<128x128xf32>
    %6 = "tts.create_ptr"(%arg2, %cst_0) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %6, %4 : tensor<128x128x!tt.ptr<f32>>
    %7 = "tts.create_ptr"(%arg3, %cst) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %7, %5 : tensor<128x128x!tt.ptr<f32>>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:35:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xf32>, [[PARAM_1_:%.+]]: memref<*xf32>, [[PARAM_2_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_3_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32, [[PARAM_8_:%.+]]: i32, [[PARAM_9_:%.+]]: i32) {
               ^
<stdin>:3:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: memref<128x128xf32>, %arg3: memref<128x128xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: #map = affine_map<(d0, d1) -> (d0, d1)>
         2: module {
         3:  func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: memref<128x128xf32>, %arg3: memref<128x128xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
same:35                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         4:  %c0 = arith.constant 0 : index
same:35     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1]>>
same:35     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1]>>
same:35     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %alloc = memref.alloc() : memref<128x128xf32>
same:35     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         8:  memref.copy %reinterpret_cast, %alloc : memref<128x128xf32, strided<[1, 1]>> to memref<128x128xf32>
same:35     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/nested_loops.mlir (16 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/nested_loops.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir
module {
  tt.func public @nested2_complex_body(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c3 = arith.constant 3 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = arith.muli %arg2, %c2_i32 : i32
    %3 = arith.index_cast %2 : i32 to index
    %4:2 = scf.for %arg4 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %c0) -> (index, index)  : i32 {
      %5 = arith.addi %arg5, %c1 : index
      %6 = arith.addi %arg6, %c1 : index
      %7:2 = scf.for %arg7 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg8 = %5, %arg9 = %6) -> (index, index)  : i32 {
        %12 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %13 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg8, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %14 = "tts.load"(%13) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%12, %14) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %15 = arith.addi %arg8, %c3 : index
        %16 = arith.addi %arg9, %c3 : index
        scf.yield %15, %16 : index, index
      }
      %8 = arith.addi %arg5, %3 : index
      %9 = arith.addi %8, %c1 : index
      %10 = arith.addi %arg6, %3 : index
      %11 = arith.addi %10, %c1 : index
      scf.yield %9, %11 : index, index
    }
    tt.return
  }
  tt.func public @nested2_use_loop_results(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c2_i32 = arith.constant 2 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c4_i32 = arith.constant 4 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = arith.muli %arg3, %c4_i32 : i32
    %3 = arith.index_cast %2 : i32 to index
    %4:2 = scf.for %arg4 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %c0) -> (index, index)  : i32 {
      %5 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg6, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %6 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg5, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %7 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%5, %7) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %8 = arith.addi %arg5, %3 : index
      %9 = arith.addi %arg6, %3 : index
      %10:2 = scf.for %arg7 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg8 = %8, %arg9 = %9) -> (index, index)  : i32 {
        %11 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %12 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg8, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%11, %13) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %14 = arith.addi %arg8, %3 : index
        %15 = arith.addi %arg9, %3 : index
        scf.yield %14, %15 : index, index
      }
      scf.yield %10#0, %10#1 : index, index
    }
    tt.return
  }
  tt.func public @nested3(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %3 = arith.muli %arg3, %c2_i32 : i32
    %4 = arith.index_cast %3 : i32 to index
    %5:3 = scf.for %arg4 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %2, %arg7 = %c0) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %6 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg5, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %7 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %8:3 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5, %arg10 = %arg6, %arg11 = %arg7) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %10 = arith.addi %arg9, %4 : index
        %11 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%10, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %12 = "tts.load"(%11) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %13:3 = scf.for %arg12 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg13 = %10, %arg14 = %arg10, %arg15 = %arg11) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
          %14 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg15, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %15 = arith.addi %arg13, %4 : index
          %16 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%15, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %17 = "tts.load"(%16) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          "tts.store"(%14, %7) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %18 = arith.addi %arg15, %4 : index
          %19 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%18, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%19, %12) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %20 = arith.addi %18, %4 : index
          %21 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%20, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%21, %17) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %22 = arith.addi %20, %4 : index
          %23 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          scf.yield %15, %23, %22 : index, tensor<2x2x!tt.ptr<f32>>, index
        }
        scf.yield %13#0, %13#1, %13#2 : index, tensor<2x2x!tt.ptr<f32>>, index
      }
      %9 = arith.addi %8#0, %4 : index
      scf.yield %9, %8#1, %8#2 : index, tensor<2x2x!tt.ptr<f32>>, index
    }
    tt.return
  }
  tt.func public @nested_use_same_level_loop_result(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %3 = arith.muli %arg3, %c2_i32 : i32
    %4 = arith.index_cast %3 : i32 to index
    %5:3 = scf.for %arg4 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %2, %arg7 = %c0) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %6 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5) -> (index)  : i32 {
        %9 = arith.addi %arg9, %4 : index
        scf.yield %9 : index
      }
      %7:3 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %6, %arg10 = %arg6, %arg11 = %arg7) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %9 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg11, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %10 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %11 = "tts.load"(%10) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %12 = arith.addi %arg9, %4 : index
        %13 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%12, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %14 = "tts.load"(%13) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%9, %11) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %15 = arith.addi %arg11, %4 : index
        %16 = arith.addi %15, %4 : index
        %17 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%16, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        "tts.store"(%17, %14) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %18 = arith.addi %16, %4 : index
        %19 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%18, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %20 = arith.addi %12, %4 : index
        scf.yield %20, %19, %18 : index, tensor<2x2x!tt.ptr<f32>>, index
      }
      %8 = arith.addi %7#0, %4 : index
      scf.yield %8, %7#1, %7#2 : index, tensor<2x2x!tt.ptr<f32>>, index
    }
    tt.return
  }
}
%c0_i32_0 = arith.constant 0 : i32
%c0_i32 = arith.constant 0 : i32
%c0_i32_0 = arith.constant 0 : i32
%c0_i32 = arith.constant 0 : i32
%c0_i32_0 = arith.constant 0 : i32
%c0_i32 = arith.constant 0 : i32
%c0_i32_0 = arith.constant 0 : i32
%c0_i32 = arith.constant 0 : i32
module {
  tt.func public @nested2_complex_body(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c3 = arith.constant 3 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = arith.muli %arg2, %c2_i32 : i32
    %3 = arith.index_cast %2 : i32 to index
    %4:2 = scf.for %arg4 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %c0) -> (index, index)  : i32 {
      %5 = arith.addi %arg5, %c1 : index
      %6 = arith.addi %arg6, %c1 : index
      %7:2 = scf.for %arg7 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg8 = %5, %arg9 = %6) -> (index, index)  : i32 {
        %12 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %13 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg8, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %14 = "tts.load"(%13) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%12, %14) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %15 = arith.addi %arg8, %c3 : index
        %16 = arith.addi %arg9, %c3 : index
        scf.yield %15, %16 : index, index
      }
      %8 = arith.addi %arg5, %3 : index
      %9 = arith.addi %8, %c1 : index
      %10 = arith.addi %arg6, %3 : index
      %11 = arith.addi %10, %c1 : index
      scf.yield %9, %11 : index, index
    }
    tt.return
  }
  tt.func public @nested2_use_loop_results(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c2_i32 = arith.constant 2 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c4_i32 = arith.constant 4 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = arith.muli %arg3, %c4_i32 : i32
    %3 = arith.index_cast %2 : i32 to index
    %4:2 = scf.for %arg4 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %c0) -> (index, index)  : i32 {
      %5 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg6, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %6 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg5, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %7 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%5, %7) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %8 = arith.addi %arg5, %3 : index
      %9 = arith.addi %arg6, %3 : index
      %10:2 = scf.for %arg7 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg8 = %8, %arg9 = %9) -> (index, index)  : i32 {
        %11 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %12 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg8, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%11, %13) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %14 = arith.addi %arg8, %3 : index
        %15 = arith.addi %arg9, %3 : index
        scf.yield %14, %15 : index, index
      }
      scf.yield %10#0, %10#1 : index, index
    }
    tt.return
  }
  tt.func public @nested3(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %3 = arith.muli %arg3, %c2_i32 : i32
    %4 = arith.index_cast %3 : i32 to index
    %5:3 = scf.for %arg4 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %2, %arg7 = %c0) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %6 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg5, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %7 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %8:3 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5, %arg10 = %arg6, %arg11 = %arg7) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %10 = arith.addi %arg9, %4 : index
        %11 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%10, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %12 = "tts.load"(%11) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %13:3 = scf.for %arg12 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg13 = %10, %arg14 = %arg10, %arg15 = %arg11) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
          %14 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg15, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %15 = arith.addi %arg13, %4 : index
          %16 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%15, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %17 = "tts.load"(%16) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          "tts.store"(%14, %7) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %18 = arith.addi %arg15, %4 : index
          %19 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%18, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%19, %12) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %20 = arith.addi %18, %4 : index
          %21 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%20, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%21, %17) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %22 = arith.addi %20, %4 : index
          %23 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          scf.yield %15, %23, %22 : index, tensor<2x2x!tt.ptr<f32>>, index
        }
        scf.yield %13#0, %13#1, %13#2 : index, tensor<2x2x!tt.ptr<f32>>, index
      }
      %9 = arith.addi %8#0, %4 : index
      scf.yield %9, %8#1, %8#2 : index, tensor<2x2x!tt.ptr<f32>>, index
    }
    tt.return
  }
  tt.func public @nested_use_same_level_loop_result(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %3 = arith.muli %arg3, %c2_i32 : i32
    %4 = arith.index_cast %3 : i32 to index
    %5:3 = scf.for %arg4 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %2, %arg7 = %c0) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %6 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5) -> (index)  : i32 {
        %9 = arith.addi %arg9, %4 : index
        scf.yield %9 : index
      }
      %7:3 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %6, %arg10 = %arg6, %arg11 = %arg7) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %9 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg11, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %10 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %11 = "tts.load"(%10) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %12 = arith.addi %arg9, %4 : index
        %13 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%12, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %14 = "tts.load"(%13) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%9, %11) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %15 = arith.addi %arg11, %4 : index
        %16 = arith.addi %15, %4 : index
        %17 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%16, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        "tts.store"(%17, %14) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %18 = arith.addi %16, %4 : index
        %19 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%18, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %20 = arith.addi %12, %4 : index
        scf.yield %20, %19, %18 : index, tensor<2x2x!tt.ptr<f32>>, index
      }
      %8 = arith.addi %7#0, %4 : index
      scf.yield %8, %7#1, %7#2 : index, tensor<2x2x!tt.ptr<f32>>, index
    }
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir:1 offset :104:11: error: failed to legalize unresolved materialization from ('memref<2x2xf32, strided<[?, ?]>>') to 'tensor<2x2x!tt.ptr<f32>>' that remained live after conversion
    %15 = tt.addptr %14, %8 : tensor<2x2x!tt.ptr<f32>>, tensor<2x2xi32>
          ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir:1 offset :104:11: note: see current operation: %9 = "builtin.unrealized_conversion_cast"(%8) : (memref<2x2xf32, strided<[?, ?]>>) -> tensor<2x2x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir:1 offset :109:13: note: see existing live user here:
%7:3 = scf.for %arg10 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg11 = %c0, %arg12 = %4, %arg13 = %c0) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
  %8 = arith.addi %arg11, %c0 : index
  %reinterpret_cast_0 = memref.reinterpret_cast %arg0 to offset: [%8], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
  %alloc = memref.alloc() : memref<2x2xf32>
  memref.copy %reinterpret_cast_0, %alloc : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
  %9 = bufferization.to_tensor %alloc restrict writable : memref<2x2xf32>
  %10:3 = scf.for %arg14 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg15 = %arg11, %arg16 = %arg12, %arg17 = %arg13) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
    %12 = arith.addi %arg15, %6 : index
    %13 = arith.addi %12, %c0 : index
    %reinterpret_cast_1 = memref.reinterpret_cast %arg0 to offset: [%13], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
    %alloc_2 = memref.alloc() : memref<2x2xf32>
    memref.copy %reinterpret_cast_1, %alloc_2 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
    %14 = bufferization.to_tensor %alloc_2 restrict writable : memref<2x2xf32>
    %15:3 = scf.for %arg18 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg19 = %12, %arg20 = %arg16, %arg21 = %arg17) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %16 = arith.addi %arg21, %c0 : index
      %reinterpret_cast_3 = memref.reinterpret_cast %arg1 to offset: [%16], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
      %17 = arith.addi %arg19, %6 : index
      %18 = arith.addi %17, %c0 : index
      %reinterpret_cast_4 = memref.reinterpret_cast %arg0 to offset: [%18], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
      %alloc_5 = memref.alloc() : memref<2x2xf32>
      memref.copy %reinterpret_cast_4, %alloc_5 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
      %19 = bufferization.to_tensor %alloc_5 restrict writable : memref<2x2xf32>
      bufferization.materialize_in_destination %9 in writable %reinterpret_cast_3 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
      %20 = arith.addi %arg21, %6 : index
      %21 = arith.addi %20, %c0 : index
      %reinterpret_cast_6 = memref.reinterpret_cast %arg1 to offset: [%21], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
      bufferization.materialize_in_destination %14 in writable %reinterpret_cast_6 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
      %22 = arith.addi %20, %6 : index
      %23 = arith.addi %22, %c0 : index
      %reinterpret_cast_7 = memref.reinterpret_cast %arg1 to offset: [%23], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
      bufferization.materialize_in_destination %19 in writable %reinterpret_cast_7 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
      %24 = arith.addi %22, %6 : index
      %25 = arith.addi %24, %c0 : index
      %reinterpret_cast_8 = memref.reinterpret_cast %arg1 to offset: [%25], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
      %26 = builtin.unrealized_conversion_cast %reinterpret_cast_8 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
      scf.yield %17, %26, %24 : index, tensor<2x2x!tt.ptr<f32>>, index
    }
    scf.yield %15#0, %15#1, %15#2 : index, tensor<2x2x!tt.ptr<f32>>, index
  }
  %11 = arith.addi %10#0, %6 : index
  scf.yield %11, %10#1, %10#2 : index, tensor<2x2x!tt.ptr<f32>>, index
}
    %20:2 = scf.for %arg4 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg5 = %11, %arg6 = %15) -> (tensor<2x2x!tt.ptr<f32>>, tensor<2x2x!tt.ptr<f32>>)  : i32 {
            ^
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir (17 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save0, %5 : tensor<1024x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save0, %5 : tensor<1024x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save1, %6 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: note: see current operation: tt.store %arg4, %14 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save1, %6 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: note: see current operation: tt.store %arg4, %14 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save2, %7 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: note: see current operation: tt.store %arg5, %15 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save2, %7 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: note: see current operation: tt.store %arg5, %15 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save3, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: note: see current operation: tt.store %arg6, %16 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save3, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: note: see current operation: tt.store %arg6, %16 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save4, %11 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: note: see current operation: tt.store %arg7, %17 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save4, %11 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: note: see current operation: tt.store %arg7, %17 : tensor<1024x!tt.ptr<f32>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<i32>, !tt.ptr<f16>, tensor<1024x!tt.ptr<bf16>>, tensor<1024x!tt.ptr<f32>>, tensor<1024x!tt.ptr<f32>>, tensor<1024x!tt.ptr<f32>>, tensor<1024x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<i32>, %arg2: !tt.ptr<f16>, %arg3: tensor<1024x!tt.ptr<bf16>>, %arg4: tensor<1024x!tt.ptr<f32>>, %arg5: tensor<1024x!tt.ptr<f32>>, %arg6: tensor<1024x!tt.ptr<f32>>, %arg7: tensor<1024x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %1 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %2 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %3 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %4 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
    %5 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %7 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %8 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>) -> tensor<1024x!tt.ptr<f32>>
    %9 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<i32>) -> tensor<1024x!tt.ptr<i32>>
    %10 = "tts.make_tptr"(%arg2) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: 0>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f16>) -> tensor<1024x!tt.ptr<f16>>
    %11 = "tts.load"(%8) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %12 = "tts.load"(%9) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<i32>>) -> tensor<1024xi32>
    %13 = "tts.load"(%10) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f16>>) -> tensor<1024xf16>
    %14 = "arith.truncf"(%11) : (tensor<1024xf32>) -> tensor<1024xbf16>
    %15 = "math.exp"(%11) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
    %16 = "arith.sitofp"(%12) : (tensor<1024xi32>) -> tensor<1024xf32>
    %17 = "arith.extf"(%13) : (tensor<1024xf16>) -> tensor<1024xf32>
    %18 = "math.sqrt"(%11) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
    "tt.store"(%4, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xbf16>) -> ()
    "tt.store"(%3, %15) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.store"(%2, %16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.store"(%1, %17) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.store"(%0, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024xi32>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%7 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%5 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%4 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
tensor<1024x!tt.ptr<bf16>>
%3 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
tensor<1024x!tt.ptr<f32>>
%2 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
tensor<1024x!tt.ptr<f32>>
%1 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
tensor<1024x!tt.ptr<f32>>
%0 = "arith.constant"() <{value = dense<0> : tensor<1024xi32>}> : () -> tensor<1024xi32>
tensor<1024x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<i32>, %arg2: !tt.ptr<f16>, %arg3: tensor<1024x!tt.ptr<bf16>>, %arg4: tensor<1024x!tt.ptr<f32>>, %arg5: tensor<1024x!tt.ptr<f32>>, %arg6: tensor<1024x!tt.ptr<f32>>, %arg7: tensor<1024x!tt.ptr<f32>>) {
    %cst = arith.constant dense<0> : tensor<1024xi32>
    %cst_0 = arith.constant dense<0> : tensor<1024xi32>
    %cst_1 = arith.constant dense<0> : tensor<1024xi32>
    %cst_2 = arith.constant dense<0> : tensor<1024xi32>
    %cst_3 = arith.constant dense<0> : tensor<1024xi32>
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_4 = arith.constant 0 : i32
    %c0_i32_5 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %1 = tts.make_tptr %arg1 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <i32> to tensor<1024x!tt.ptr<i32>>
    %2 = tts.make_tptr %arg2 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f16> to tensor<1024x!tt.ptr<f16>>
    %3 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %4 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<i32>>) -> tensor<1024xi32>
    %5 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f16>>) -> tensor<1024xf16>
    %6 = arith.truncf %3 : tensor<1024xf32> to tensor<1024xbf16>
    %7 = math.exp %3 : tensor<1024xf32>
    %8 = arith.sitofp %4 : tensor<1024xi32> to tensor<1024xf32>
    %9 = arith.extf %5 : tensor<1024xf16> to tensor<1024xf32>
    %10 = math.sqrt %3 : tensor<1024xf32>
    %11 = "tts.create_ptr"(%arg3, %cst_3) : (tensor<1024x!tt.ptr<bf16>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<bf16>>
    tt.store %11, %6 : tensor<1024x!tt.ptr<bf16>>
    %12 = "tts.create_ptr"(%arg4, %cst_2) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    tt.store %12, %7 : tensor<1024x!tt.ptr<f32>>
    %13 = "tts.create_ptr"(%arg5, %cst_1) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    tt.store %13, %8 : tensor<1024x!tt.ptr<f32>>
    %14 = "tts.create_ptr"(%arg6, %cst_0) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    tt.store %14, %9 : tensor<1024x!tt.ptr<f32>>
    %15 = "tts.create_ptr"(%arg7, %cst) : (tensor<1024x!tt.ptr<f32>>, tensor<1024xi32>) -> tensor<1024x!tt.ptr<f32>>
    tt.store %15, %10 : tensor<1024x!tt.ptr<f32>>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:43:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xf32>, [[PARAM_1_:%.+]]: memref<*xi32>, [[PARAM_2_:%.+]]: memref<*xf16>, [[PARAM_3_:%.+]]: tensor<1024x!tt.ptr<bf16>>, [[PARAM_4_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_5_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_6_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_7_:%.+]]: tensor<1024x!tt.ptr<f32>>, [[PARAM_8_:%.+]]: i32, [[PARAM_9_:%.+]]: i32, [[PARAM_10_:%.+]]: i32, [[PARAM_11_:%.+]]: i32, [[PARAM_12_:%.+]]: i32, [[PARAM_13_:%.+]]: i32) {
               ^
<stdin>:3:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xi32>, %arg2: memref<*xf16>, %arg3: memref<1024xbf16>, %arg4: memref<1024xf32>, %arg5: memref<1024xf32>, %arg6: memref<1024xf32>, %arg7: memref<1024xf32>, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: #map = affine_map<(d0) -> (d0)>
         2: module {
         3:  func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xi32>, %arg2: memref<*xf16>, %arg3: memref<1024xbf16>, %arg4: memref<1024xf32>, %arg5: memref<1024xf32>, %arg6: memref<1024xf32>, %arg7: memref<1024xf32>, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32) {
same:43                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         4:  %c0 = arith.constant 0 : index
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1]>>
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [0], sizes: [1024], strides: [1] : memref<*xi32> to memref<1024xi32, strided<[1]>>
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [1024], strides: [1] : memref<*xf16> to memref<1024xf16, strided<[1]>>
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         8:  %alloc = memref.alloc() : memref<1024xf32>
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_stacked.mlir (18 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_stacked.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir:1 offset :47:13: warning: PtrAnalysis: allowing adding pointer state with modulo in dim 0 to another pointer state with offset in dim 0.
Please verify the operand that contains a scalar is meant to increment pointers in dim1. If that is not the case it WILL LEAD TO WRONG COMPILATION RESULTS.

To avoid this warning, use expand_dims (instead of splat) to explicitly specify which dimension contains the scalar.
      %33 = tt.addptr %arg9, %30 : tensor<4x4x!tt.ptr<f32>>, tensor<4x4xi32>
            ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir:1 offset :47:13: note: see current operation: %48 = tt.addptr %arg9, %42 : tensor<4x4x!tt.ptr<f32>>, tensor<4x4xi32>
module {
  tt.func public @wrap_stacked_masked_loop_01234567(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %cst = arith.constant -9.900000e+01 : f32
    %c0 = arith.constant 0 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %c4_i32 = arith.constant 4 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg4 : i32 to index
    %2 = arith.muli %1, %c2 : index
    %3 = arith.muli %0, %1 : index
    %4 = arith.index_cast %arg5 : i32 to index
    %5 = arith.muli %4, %c3 : index
    %6 = arith.index_cast %arg6 : i32 to index
    %7 = arith.index_cast %arg7 : i32 to index
    %8 = arith.muli %arg5, %c4_i32 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10:2 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %2, %arg10 = %c0) -> (index, index)  : i32 {
      %11 = tts.make_tptr %arg1 to sizes: [4, 4], strides: [%6, %7], offsets: [%arg10, %c0], shape: [0, 0], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %12 = tts.make_tptr %arg0 to sizes: [4, 4], strides: [%1, %4], offsets: [%arg9, %5], shape: [%3, 0], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %13 = "tts.load"(%12, %cst) <{operandSegmentSizes = array<i32: 1, 0, 1>, static_mask_dims = array<i64: 4, 3>}> : (tensor<4x4x!tt.ptr<f32>>, f32) -> tensor<4x4xf32>
      "tts.store"(%11, %13) <{static_mask_dims = array<i64>}> : (tensor<4x4x!tt.ptr<f32>>, tensor<4x4xf32>) -> ()
      %14 = arith.addi %arg9, %9 : index
      %15 = arith.addi %arg10, %9 : index
      scf.yield %14, %15 : index, index
    }
    tt.return
  }
}
%c0_i32_0 = arith.constant 0 : i32
%c0_i32 = arith.constant 0 : i32
module {
  tt.func public @wrap_stacked_masked_loop_01234567(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %cst = arith.constant -9.900000e+01 : f32
    %c0 = arith.constant 0 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %c4_i32 = arith.constant 4 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg4 : i32 to index
    %2 = arith.muli %1, %c2 : index
    %3 = arith.muli %0, %1 : index
    %4 = arith.index_cast %arg5 : i32 to index
    %5 = arith.muli %4, %c3 : index
    %6 = arith.index_cast %arg6 : i32 to index
    %7 = arith.index_cast %arg7 : i32 to index
    %8 = arith.muli %arg5, %c4_i32 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10:2 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %2, %arg10 = %c0) -> (index, index)  : i32 {
      %11 = tts.make_tptr %arg1 to sizes: [4, 4], strides: [%6, %7], offsets: [%arg10, %c0], shape: [0, 0], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %12 = tts.make_tptr %arg0 to sizes: [4, 4], strides: [%1, %4], offsets: [%arg9, %5], shape: [%3, 0], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %13 = "tts.load"(%12, %cst) <{operandSegmentSizes = array<i32: 1, 0, 1>, static_mask_dims = array<i64: 4, 3>}> : (tensor<4x4x!tt.ptr<f32>>, f32) -> tensor<4x4xf32>
      "tts.store"(%11, %13) <{static_mask_dims = array<i64>}> : (tensor<4x4x!tt.ptr<f32>>, tensor<4x4xf32>) -> ()
      %14 = arith.addi %arg9, %9 : index
      %15 = arith.addi %arg10, %9 : index
      scf.yield %14, %15 : index, index
    }
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir:1 offset :44:13: error: failed to legalize operation 'tts.make_tptr' that was explicitly marked illegal
    %31:2 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %15, %arg10 = %26) -> (tensor<4x4x!tt.ptr<f32>>, tensor<4x4x!tt.ptr<f32>>)  : i32 {
            ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir:1 offset :44:13: note: see current operation: %24 = "tts.make_tptr"(%1, %11, %14, %arg15, %15, %13) <{operandSegmentSizes = array<i32: 1, 2, 2, 1>, order = array<i32>, sizes = array<i64: 4, 4>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: -9223372036854775808, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index, index) -> tensor<4x4x!tt.ptr<f32>>
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_complex_offset.mlir (19 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_complex_offset.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --structured-to-memref --split-input-file /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --structured-to-memref --split-input-file /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir:22:11: error: CHECK: expected string not found in input
// CHECK: %0 = arith.remsi %arg8, %arg3 : i32
          ^
<stdin>:6:36: note: scanning from here
 %c128 = arith.constant 128 : index
                                   ^
<stdin>:7:2: note: possible intended match here
 %1 = arith.remsi %arg8, %arg3 : i32
 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            1: module {
            2:  func.func @fused_attention_fwd_kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i64, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) -> tensor<128x128xbf16> {
            3:  %0 = builtin.unrealized_conversion_cast %arg0 : memref<*xbf16> to !tt.ptr<bf16>
            4:  %c1 = arith.constant 1 : index
            5:  %c0 = arith.constant 0 : index
            6:  %c128 = arith.constant 128 : index
check:22'0                                        X error: no match found
            7:  %1 = arith.remsi %arg8, %arg3 : i32
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:22'1      ?                                    possible intended match
            8:  %2 = arith.extsi %1 : i32 to i64
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            9:  %3 = arith.muli %2, %arg2 : i64
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           10:  %4 = tt.addptr %0, %3 : !tt.ptr<bf16>, i64
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           11:  %5 = arith.addi %c0, %c0 : index
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           12:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%5], sizes: [128, 128], strides: [%c128, %c1] : memref<*xbf16> to memref<128x128xbf16, strided<[?, ?], offset: ?>>
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            .
            .
            .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax.mlir (20 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, f32, f32) -> (), sym_name = "minmax_olt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.cmpf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>, predicate = 4 : i64}> : (f32, f32) -> i1
    %2 = "arith.select"(%1, %arg1, %arg2) : (i1, f32, f32) -> f32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
!tt.ptr<f32>
module {
  tt.func public @minmax_olt(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32) {
    %c0_i32 = arith.constant 0 : i32
    %0 = arith.cmpf olt, %arg1, %arg2 : f32
    %1 = arith.select %0, %arg1, %arg2 : f32
    %2 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    tt.store %2, %1 : !tt.ptr<f32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, f32, f32) -> (), sym_name = "minmax_ole", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.cmpf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>, predicate = 5 : i64}> : (f32, f32) -> i1
    %2 = "arith.select"(%1, %arg1, %arg2) : (i1, f32, f32) -> f32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
!tt.ptr<f32>
module {
  tt.func public @minmax_ole(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32) {
    %c0_i32 = arith.constant 0 : i32
    %0 = arith.cmpf ole, %arg1, %arg2 : f32
    %1 = arith.select %0, %arg1, %arg2 : f32
    %2 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    tt.store %2, %1 : !tt.ptr<f32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, f32, f32) -> (), sym_name = "minmax_ogt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.cmpf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>, predicate = 2 : i64}> : (f32, f32) -> i1
    %2 = "arith.select"(%1, %arg1, %arg2) : (i1, f32, f32) -> f32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
!tt.ptr<f32>
module {
  tt.func public @minmax_ogt(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32) {
    %c0_i32 = arith.constant 0 : i32
    %0 = arith.cmpf ogt, %arg1, %arg2 : f32
    %1 = arith.select %0, %arg1, %arg2 : f32
    %2 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    tt.store %2, %1 : !tt.ptr<f32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, f32, f32) -> (), sym_name = "minmax_oge", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.cmpf"(%arg1, %arg2) <{fastmath = #arith.fastmath<none>, predicate = 3 : i64}> : (f32, f32) -> i1
    %2 = "arith.select"(%1, %arg1, %arg2) : (i1, f32, f32) -> f32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
!tt.ptr<f32>
module {
  tt.func public @minmax_oge(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32) {
    %c0_i32 = arith.constant 0 : i32
    %0 = arith.cmpf oge, %arg1, %arg2 : f32
    %1 = arith.select %0, %arg1, %arg2 : f32
    %2 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    tt.store %2, %1 : !tt.ptr<f32>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:46:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:2:143: note: scanning from here
 func.func @minmax_olt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:2:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_olt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:5:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:53:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:13:143: note: scanning from here
 func.func @minmax_ole(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:13:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ole(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:16:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:60:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:24:143: note: scanning from here
 func.func @minmax_ogt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:24:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ogt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:27:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:67:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:35:143: note: scanning from here
 func.func @minmax_oge(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:35:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_oge(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:38:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module {
          2:  func.func @minmax_olt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
dag:46'0                                                                                                                                                   X error: no match found
dag:46'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
          3:  %c0 = arith.constant 0 : index
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %0 = arith.minimumf %arg1, %arg2 : f32
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:46'2                  ?                                                                                                                                           possible intended match
          6:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>>
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  return
dag:46'0     ~~~~~~~~
          8:  }
dag:46'0     ~~~
          9: }
dag:46'0     ~~
         10:
dag:46'0     ~
         11: // -----
dag:46'0     ~~~~~~~~~
         12: module {
dag:46'0     ~~~~~~~~~
         13:  func.func @minmax_ole(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~
dag:53'0                                                                                                                                                   X error: no match found
dag:53'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
         14:  %c0 = arith.constant 0 : index
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         15:  %0 = arith.minimumf %arg1, %arg2 : f32
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         16:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:53'2                  ?                                                                                                                                           possible intended match
         17:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>>
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         18:  return
dag:53'0     ~~~~~~~~
         19:  }
dag:53'0     ~~~
         20: }
dag:53'0     ~~
         21:
dag:53'0     ~
         22: // -----
dag:53'0     ~~~~~~~~~
         23: module {
dag:53'0     ~~~~~~~~~
         24:  func.func @minmax_ogt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~
dag:60'0                                                                                                                                                   X error: no match found
dag:60'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
         25:  %c0 = arith.constant 0 : index
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         26:  %0 = arith.maximumf %arg1, %arg2 : f32
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         27:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:60'2                  ?                                                                                                                                           possible intended match
         28:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>>
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         29:  return
dag:60'0     ~~~~~~~~
         30:  }
dag:60'0     ~~~
         31: }
dag:60'0     ~~
         32:
dag:60'0     ~
         33: // -----
dag:60'0     ~~~~~~~~~
         34: module {
dag:60'0     ~~~~~~~~~
         35:  func.func @minmax_oge(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~
dag:67'0                                                                                                                                                   X error: no match found
dag:67'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
         36:  %c0 = arith.constant 0 : index
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         37:  %0 = arith.maximumf %arg1, %arg2 : f32
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         38:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:67'2                  ?                                                                                                                                           possible intended match
         39:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>>
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         40:  return
dag:67'0     ~~~~~~~~
         41:  }
dag:67'0     ~~~
         42: }
dag:67'0     ~~
         43:
dag:67'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir (21 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save0, %5 : tensor<128x128x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save0, %5 : tensor<128x128x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save1, %6 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: note: see current operation: tt.store %arg4, %20 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save1, %6 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: note: see current operation: tt.store %arg4, %20 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save2, %7 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: note: see current operation: tt.store %arg5, %21 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save2, %7 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: note: see current operation: tt.store %arg5, %21 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save3, %10 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: note: see current operation: tt.store %arg6, %22 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save3, %10 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: note: see current operation: tt.store %arg6, %22 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save4, %11 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: note: see current operation: tt.store %arg7, %23 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save4, %11 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: note: see current operation: tt.store %arg7, %23 : tensor<128x128x!tt.ptr<f32>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<f32>, !tt.ptr<i32>, !tt.ptr<f16>, tensor<128x128x!tt.ptr<bf16>>, tensor<128x128x!tt.ptr<f32>>, tensor<128x128x!tt.ptr<f32>>, tensor<128x128x!tt.ptr<f32>>, tensor<128x128x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<i32>, %arg2: !tt.ptr<f16>, %arg3: tensor<128x128x!tt.ptr<bf16>>, %arg4: tensor<128x128x!tt.ptr<f32>>, %arg5: tensor<128x128x!tt.ptr<f32>>, %arg6: tensor<128x128x!tt.ptr<f32>>, %arg7: tensor<128x128x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %1 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %2 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %3 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %4 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %5 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %7 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %8 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %9 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<i32>) -> tensor<128x128x!tt.ptr<i32>>
    %10 = "tts.make_tptr"(%arg2) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f16>) -> tensor<128x128x!tt.ptr<f16>>
    %11 = "tts.load"(%8) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %12 = "tts.load"(%9) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<i32>>) -> tensor<128x128xi32>
    %13 = "tts.load"(%10) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f16>>) -> tensor<128x128xf16>
    %14 = "arith.truncf"(%11) : (tensor<128x128xf32>) -> tensor<128x128xbf16>
    %15 = "math.exp"(%11) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
    %16 = "arith.sitofp"(%12) : (tensor<128x128xi32>) -> tensor<128x128xf32>
    %17 = "arith.extf"(%13) : (tensor<128x128xf16>) -> tensor<128x128xf32>
    %18 = "math.sqrt"(%11) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
    "tt.store"(%4, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xbf16>) -> ()
    "tt.store"(%3, %15) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.store"(%2, %16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.store"(%1, %17) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.store"(%0, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%7 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%5 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%4 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
tensor<128x128x!tt.ptr<bf16>>
%3 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
tensor<128x128x!tt.ptr<f32>>
%2 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
tensor<128x128x!tt.ptr<f32>>
%1 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
tensor<128x128x!tt.ptr<f32>>
%0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
tensor<128x128x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<i32>, %arg2: !tt.ptr<f16>, %arg3: tensor<128x128x!tt.ptr<bf16>>, %arg4: tensor<128x128x!tt.ptr<f32>>, %arg5: tensor<128x128x!tt.ptr<f32>>, %arg6: tensor<128x128x!tt.ptr<f32>>, %arg7: tensor<128x128x!tt.ptr<f32>>) {
    %cst = arith.constant dense<0> : tensor<128x128xi32>
    %cst_0 = arith.constant dense<0> : tensor<128x128xi32>
    %cst_1 = arith.constant dense<0> : tensor<128x128xi32>
    %cst_2 = arith.constant dense<0> : tensor<128x128xi32>
    %cst_3 = arith.constant dense<0> : tensor<128x128xi32>
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_4 = arith.constant 0 : i32
    %c0_i32_5 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %1 = tts.make_tptr %arg1 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <i32> to tensor<128x128x!tt.ptr<i32>>
    %2 = tts.make_tptr %arg2 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f16> to tensor<128x128x!tt.ptr<f16>>
    %3 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %4 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<i32>>) -> tensor<128x128xi32>
    %5 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f16>>) -> tensor<128x128xf16>
    %6 = arith.truncf %3 : tensor<128x128xf32> to tensor<128x128xbf16>
    %7 = math.exp %3 : tensor<128x128xf32>
    %8 = arith.sitofp %4 : tensor<128x128xi32> to tensor<128x128xf32>
    %9 = arith.extf %5 : tensor<128x128xf16> to tensor<128x128xf32>
    %10 = math.sqrt %3 : tensor<128x128xf32>
    %11 = "tts.create_ptr"(%arg3, %cst_3) : (tensor<128x128x!tt.ptr<bf16>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<bf16>>
    tt.store %11, %6 : tensor<128x128x!tt.ptr<bf16>>
    %12 = "tts.create_ptr"(%arg4, %cst_2) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %12, %7 : tensor<128x128x!tt.ptr<f32>>
    %13 = "tts.create_ptr"(%arg5, %cst_1) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %13, %8 : tensor<128x128x!tt.ptr<f32>>
    %14 = "tts.create_ptr"(%arg6, %cst_0) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %14, %9 : tensor<128x128x!tt.ptr<f32>>
    %15 = "tts.create_ptr"(%arg7, %cst) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %15, %10 : tensor<128x128x!tt.ptr<f32>>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:49:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xf32>, [[PARAM_1_:%.+]]: memref<*xi32>, [[PARAM_2_:%.+]]: memref<*xf16>, [[PARAM_3_:%.+]]: tensor<128x128x!tt.ptr<bf16>>, [[PARAM_4_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_5_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_6_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_7_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_8_:%.+]]: i32, [[PARAM_9_:%.+]]: i32, [[PARAM_10_:%.+]]: i32, [[PARAM_11_:%.+]]: i32, [[PARAM_12_:%.+]]: i32, [[PARAM_13_:%.+]]: i32) {
               ^
<stdin>:3:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xi32>, %arg2: memref<*xf16>, %arg3: memref<128x128xbf16>, %arg4: memref<128x128xf32>, %arg5: memref<128x128xf32>, %arg6: memref<128x128xf32>, %arg7: memref<128x128xf32>, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: #map = affine_map<(d0, d1) -> (d0, d1)>
         2: module {
         3:  func.func @kernel(%arg0: memref<*xf32>, %arg1: memref<*xi32>, %arg2: memref<*xf16>, %arg3: memref<128x128xbf16>, %arg4: memref<128x128xf32>, %arg5: memref<128x128xf32>, %arg6: memref<128x128xf32>, %arg7: memref<128x128xf32>, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32) {
same:49                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         4:  %c0 = arith.constant 0 : index
same:49     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1]>>
same:49     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xi32> to memref<128x128xi32, strided<[1, 1]>>
same:49     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xf16> to memref<128x128xf16, strided<[1, 1]>>
same:49     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         8:  %alloc = memref.alloc() : memref<128x128xf32>
same:49     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_side_by_side.mlir (22 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_side_by_side.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir
module {
  tt.func public @wrap_side_by_side_masked_loop_01234567(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %cst = arith.constant -9.900000e+01 : f32
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c2 = arith.constant 2 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %c4_i32 = arith.constant 4 : i32
    %0 = arith.index_cast %arg4 : i32 to index
    %1 = arith.muli %0, %c2 : index
    %2 = arith.index_cast %arg3 : i32 to index
    %3 = arith.index_cast %arg5 : i32 to index
    %4 = arith.muli %3, %c6 : index
    %5 = arith.muli %2, %3 : index
    %6 = arith.index_cast %arg6 : i32 to index
    %7 = arith.index_cast %arg7 : i32 to index
    %8 = arith.muli %arg4, %c4_i32 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.muli %arg5, %c4_i32 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12:2 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %1, %arg10 = %c0) -> (index, index)  : i32 {
      %13 = tts.make_tptr %arg1 to sizes: [4, 4], strides: [%6, %7], offsets: [%arg10, %c0], shape: [0, 0], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %14 = tts.make_tptr %arg0 to sizes: [4, 4], strides: [%0, %3], offsets: [%arg9, %4], shape: [0, %5], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %15 = "tts.load"(%14, %cst) <{operandSegmentSizes = array<i32: 1, 0, 1>, static_mask_dims = array<i64: 2, 4>}> : (tensor<4x4x!tt.ptr<f32>>, f32) -> tensor<4x4xf32>
      "tts.store"(%13, %15) <{static_mask_dims = array<i64>}> : (tensor<4x4x!tt.ptr<f32>>, tensor<4x4xf32>) -> ()
      %16 = arith.addi %arg9, %9 : index
      %17 = arith.addi %arg10, %11 : index
      scf.yield %16, %17 : index, index
    }
    tt.return
  }
}
%c0_i32_0 = arith.constant 0 : i32
%c0_i32 = arith.constant 0 : i32
module {
  tt.func public @wrap_side_by_side_masked_loop_01234567(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %cst = arith.constant -9.900000e+01 : f32
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c2 = arith.constant 2 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %c4_i32 = arith.constant 4 : i32
    %0 = arith.index_cast %arg4 : i32 to index
    %1 = arith.muli %0, %c2 : index
    %2 = arith.index_cast %arg3 : i32 to index
    %3 = arith.index_cast %arg5 : i32 to index
    %4 = arith.muli %3, %c6 : index
    %5 = arith.muli %2, %3 : index
    %6 = arith.index_cast %arg6 : i32 to index
    %7 = arith.index_cast %arg7 : i32 to index
    %8 = arith.muli %arg4, %c4_i32 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.muli %arg5, %c4_i32 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12:2 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %1, %arg10 = %c0) -> (index, index)  : i32 {
      %13 = tts.make_tptr %arg1 to sizes: [4, 4], strides: [%6, %7], offsets: [%arg10, %c0], shape: [0, 0], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %14 = tts.make_tptr %arg0 to sizes: [4, 4], strides: [%0, %3], offsets: [%arg9, %4], shape: [0, %5], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %15 = "tts.load"(%14, %cst) <{operandSegmentSizes = array<i32: 1, 0, 1>, static_mask_dims = array<i64: 2, 4>}> : (tensor<4x4x!tt.ptr<f32>>, f32) -> tensor<4x4xf32>
      "tts.store"(%13, %15) <{static_mask_dims = array<i64>}> : (tensor<4x4x!tt.ptr<f32>>, tensor<4x4xf32>) -> ()
      %16 = arith.addi %arg9, %9 : index
      %17 = arith.addi %arg10, %11 : index
      scf.yield %16, %17 : index, index
    }
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir:1 offset :46:13: error: failed to legalize operation 'tts.make_tptr' that was explicitly marked illegal
    %33:2 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %15, %arg10 = %26) -> (tensor<4x4x!tt.ptr<f32>>, tensor<4x4x!tt.ptr<f32>>)  : i32 {
            ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir:1 offset :46:13: note: see current operation: %26 = "tts.make_tptr"(%1, %10, %13, %arg15, %14, %15) <{operandSegmentSizes = array<i32: 1, 2, 2, 1>, order = array<i32>, sizes = array<i64: 4, 4>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, -9223372036854775808>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index, index) -> tensor<4x4x!tt.ptr<f32>>
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir (23 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %d, %100 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %d, %100 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<f32>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i1>, !tt.ptr<f32>, !tt.ptr<f32>, tensor<128x128x!tt.ptr<f32>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<i1>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: tensor<128x128x!tt.ptr<f32>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %4 = "tts.make_tptr"(%arg0) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<i1>) -> tensor<128x128x!tt.ptr<i1>>
    %5 = "tts.make_tptr"(%arg1) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %6 = "tts.make_tptr"(%arg2) <{operandSegmentSizes = array<i32: 1, 0, 0, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: 0, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>) -> tensor<128x128x!tt.ptr<f32>>
    %7 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<i1>>) -> tensor<128x128xi1>
    %8 = "tts.load"(%5) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %9 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %10 = "arith.select"(%7, %8, %9) : (tensor<128x128xi1>, tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
    "tt.store"(%0, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128xi32>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%0 = "arith.constant"() <{value = dense<0> : tensor<128x128xi32>}> : () -> tensor<128x128xi32>
tensor<128x128x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<i1>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: tensor<128x128x!tt.ptr<f32>>) {
    %cst = arith.constant dense<0> : tensor<128x128xi32>
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <i1> to tensor<128x128x!tt.ptr<i1>>
    %1 = tts.make_tptr %arg1 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %2 = tts.make_tptr %arg2 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %3 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<i1>>) -> tensor<128x128xi1>
    %4 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %5 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %6 = arith.select %3, %4, %5 : tensor<128x128xi1>, tensor<128x128xf32>
    %7 = "tts.create_ptr"(%arg3, %cst) : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xi32>) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %7, %6 : tensor<128x128x!tt.ptr<f32>>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:37:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xi1>, [[PARAM_1_:%.+]]: memref<*xf32>, [[PARAM_2_:%.+]]: memref<*xf32>, [[PARAM_3_:%.+]]: tensor<128x128x!tt.ptr<f32>>, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32, [[PARAM_8_:%.+]]: i32, [[PARAM_9_:%.+]]: i32) {
               ^
<stdin>:3:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xi1>, %arg1: memref<*xf32>, %arg2: memref<*xf32>, %arg3: memref<128x128xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: #map = affine_map<(d0, d1) -> (d0, d1)>
         2: module {
         3:  func.func @kernel(%arg0: memref<*xi1>, %arg1: memref<*xf32>, %arg2: memref<*xf32>, %arg3: memref<128x128xf32>, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
same:37                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         4:  %c0 = arith.constant 0 : index
same:37     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xi1> to memref<128x128xi1, strided<[1, 1]>>
same:37     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1]>>
same:37     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %reinterpret_cast_1 = memref.reinterpret_cast %arg2 to offset: [0], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1]>>
same:37     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         8:  %alloc = memref.alloc() : memref<128x128xi1>
same:37     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_middle_dim.mlir (24 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_middle_dim.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %out, %5 : tensor<32x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: note: see current operation: tt.store %arg2, %19 : tensor<32x16x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %out, %5 : tensor<32x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: note: see current operation: tt.store %arg2, %19 : tensor<32x16x!tt.ptr<bf16>>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<bf16>, !tt.ptr<bf16>, tensor<32x16x!tt.ptr<bf16>>) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: tensor<32x16x!tt.ptr<bf16>>):
    %0 = "arith.constant"() <{value = dense<0> : tensor<32x16xi32>}> : () -> tensor<32x16xi32>
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 256 : index}> : () -> index
    %4 = "tts.make_tptr"(%arg0, %3) <{operandSegmentSizes = array<i32: 1, 1, 0, 0>, order = array<i32>, sizes = array<i64: 32, 256, 16>, static_offsets = array<i64: 0, 0, 0>, static_shape = array<i64: 0, 0, 0>, static_strides = array<i64: -9223372036854775808, 1, 1>}> : (!tt.ptr<bf16>, index) -> tensor<32x256x16x!tt.ptr<bf16>>
    %5 = "tts.load"(%4) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<32x256x16x!tt.ptr<bf16>>) -> tensor<32x256x16xbf16>
    %6 = "tt.reduce"(%5) <{axis = 1 : i32}> ({
    ^bb0(%arg3: bf16, %arg4: bf16):
      %7 = "arith.addf"(%arg3, %arg4) <{fastmath = #arith.fastmath<none>}> : (bf16, bf16) -> bf16
      "tt.reduce.return"(%7) : (bf16) -> ()
    }) : (tensor<32x256x16xbf16>) -> tensor<32x16xbf16>
    "tt.store"(%0, %6) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x16xi32>, tensor<32x16xbf16>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
%0 = "arith.constant"() <{value = dense<0> : tensor<32x16xi32>}> : () -> tensor<32x16xi32>
tensor<32x16x!tt.ptr<bf16>>
module {
  tt.func @kernel(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: tensor<32x16x!tt.ptr<bf16>>) {
    %cst = arith.constant dense<0> : tensor<32x16xi32>
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c256 = arith.constant 256 : index
    %0 = tts.make_tptr %arg0 to sizes: [32, 256, 16], strides: [%c256, 1, 1], offsets: [0, 0, 0], shape: [0, 0, 0], order: [] : <bf16> to tensor<32x256x16x!tt.ptr<bf16>>
    %1 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<32x256x16x!tt.ptr<bf16>>) -> tensor<32x256x16xbf16>
    %2 = "tt.reduce"(%1) <{axis = 1 : i32}> ({
    ^bb0(%arg3: bf16, %arg4: bf16):
      %4 = arith.addf %arg3, %arg4 : bf16
      tt.reduce.return %4 : bf16
    }) : (tensor<32x256x16xbf16>) -> tensor<32x16xbf16>
    %3 = "tts.create_ptr"(%arg2, %cst) : (tensor<32x16x!tt.ptr<bf16>>, tensor<32x16xi32>) -> tensor<32x16x!tt.ptr<bf16>>
    tt.store %3, %2 : tensor<32x16x!tt.ptr<bf16>>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:43:16: error: CHECK-SAME: expected string not found in input
// CHECK-SAME: ([[PARAM_0_:%.+]]: memref<*xbf16>, [[PARAM_1_:%.+]]: memref<*xbf16>, [[PARAM_2_:%.+]]: tensor<32x16x!tt.ptr<bf16>>, [[PARAM_3_:%.+]]: i32, [[PARAM_4_:%.+]]: i32, [[PARAM_5_:%.+]]: i32, [[PARAM_6_:%.+]]: i32, [[PARAM_7_:%.+]]: i32, [[PARAM_8_:%.+]]: i32) {
               ^
<stdin>:2:19: note: scanning from here
 func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: memref<32x16xbf16>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
         1: module {
         2:  func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: memref<32x16xbf16>, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
same:43                       X~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ error: no match found
         3:  %c0 = arith.constant 0 : index
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         4:  %cst = arith.constant 0.000000e+00 : bf16
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         5:  %c256 = arith.constant 256 : index
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         6:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [32, 256, 16], strides: [%c256, 1, 1] : memref<*xbf16> to memref<32x256x16xbf16, strided<[?, 1, 1]>>
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         7:  %alloc = memref.alloc() : memref<32x256x16xbf16>
same:43     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         .
         .
         .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop.mlir (25 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir:20:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[CST_0_:%.+]] = arith.constant 0 : index
              ^
<stdin>:2:232: note: scanning from here
 func.func @reduce_kernel_2d_0d(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
                                                                                                                                                                                                                                       ^
<stdin>:5:4: note: possible intended match here
 %c0_i32 = arith.constant 0 : i32
   ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module {
          2:  func.func @reduce_kernel_2d_0d(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
dag:20'0                                                                                                                                                                                                                                            X error: no match found
          3:  %0 = builtin.unrealized_conversion_cast %arg0 : memref<*xf32> to !tt.ptr<f32>
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c8_i32 = arith.constant 8 : i32
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %c0_i32 = arith.constant 0 : i32
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:20'1        ?                               possible intended match
          6:  %c1_i32 = arith.constant 1 : i32
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %1 = scf.for %arg13 = %c0_i32 to %c8_i32 step %c1_i32 iter_args(%arg14 = %0) -> (!tt.ptr<f32>) : i32 {
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          8:  %2 = arith.sitofp %arg13 : i32 to f32
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          9:  tt.store %arg14, %2 : !tt.ptr<f32>
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         10:  %3 = tt.addptr %arg14, %c1_i32 : !tt.ptr<f32>, i32
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-05-layer-norm-dwdb.mlir (26 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_argmin_argmax_2d.mlir (27 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/tensor_indices_loop_iterargs_nested.mlir (28 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_argmin_argmax.mlir (29 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_dim1.mlir (30 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-03-matrix-multiplication.mlir (31 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/ridiculously_nested_loops.mlir (32 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/ridiculously_nested_loops.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir

/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir:23:11: error: failed to legalize unresolved materialization from ('memref<2x2xf32, strided<[?, ?]>>') to 'tensor<2x2x!tt.ptr<f32>>' that remained live after conversion
    %15 = tt.addptr %14, %8 : tensor<2x2x!tt.ptr<f32>>, tensor<2x2xi32>
          ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir:23:11: note: see current operation: %9 = "builtin.unrealized_conversion_cast"(%8) : (memref<2x2xf32, strided<[?, ?]>>) -> tensor<2x2x!tt.ptr<f32>>
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir:32:13: note: see existing live user here:
%7:3 = scf.for %arg10 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg11 = %c0, %arg12 = %4, %arg13 = %c0) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
  %8 = arith.addi %arg11, %c0 : index
  %reinterpret_cast_0 = memref.reinterpret_cast %arg0 to offset: [%8], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
  %alloc = memref.alloc() : memref<2x2xf32>
  memref.copy %reinterpret_cast_0, %alloc : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
  %9 = bufferization.to_tensor %alloc restrict writable : memref<2x2xf32>
  %10:4 = scf.for %arg14 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg15 = %arg11, %arg16 = %arg12, %arg17 = %arg13, %arg18 = %9) -> (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
    %13 = arith.addi %arg15, %6 : index
    %14 = arith.addi %13, %c0 : index
    %reinterpret_cast_1 = memref.reinterpret_cast %arg0 to offset: [%14], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
    %alloc_2 = memref.alloc() : memref<2x2xf32>
    memref.copy %reinterpret_cast_1, %alloc_2 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
    %15 = bufferization.to_tensor %alloc_2 restrict writable : memref<2x2xf32>
    %16:5 = scf.for %arg19 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg20 = %13, %arg21 = %arg16, %arg22 = %arg17, %arg23 = %arg18, %arg24 = %15) -> (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
      %18 = arith.addi %arg22, %c0 : index
      %reinterpret_cast_3 = memref.reinterpret_cast %arg1 to offset: [%18], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
      %19 = arith.addi %arg20, %6 : index
      %20 = arith.addi %19, %c0 : index
      %reinterpret_cast_4 = memref.reinterpret_cast %arg0 to offset: [%20], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
      %21 = builtin.unrealized_conversion_cast %reinterpret_cast_4 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
      %alloc_5 = memref.alloc() : memref<2x2xf32>
      memref.copy %reinterpret_cast_4, %alloc_5 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
      %22 = bufferization.to_tensor %alloc_5 restrict writable : memref<2x2xf32>
      bufferization.materialize_in_destination %arg23 in writable %reinterpret_cast_3 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
      %23 = arith.addi %arg22, %6 : index
      %24 = arith.addi %23, %c0 : index
      %reinterpret_cast_6 = memref.reinterpret_cast %arg1 to offset: [%24], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
      bufferization.materialize_in_destination %arg24 in writable %reinterpret_cast_6 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
      %25 = arith.addi %23, %6 : index
      %26 = arith.addi %25, %c0 : index
      %reinterpret_cast_7 = memref.reinterpret_cast %arg1 to offset: [%26], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
      bufferization.materialize_in_destination %22 in writable %reinterpret_cast_7 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
      %27 = arith.addi %25, %6 : index
      %28 = arith.addi %27, %c0 : index
      %reinterpret_cast_8 = memref.reinterpret_cast %arg1 to offset: [%28], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
      %29 = builtin.unrealized_conversion_cast %reinterpret_cast_8 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
      %30:7 = scf.for %arg25 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg26 = %arg23, %arg27 = %21, %arg28 = %19, %arg29 = %arg24, %arg30 = %22, %arg31 = %29, %arg32 = %27) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %32 = arith.addi %arg28, %c0 : index
        %reinterpret_cast_9 = memref.reinterpret_cast %arg0 to offset: [%32], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
        %alloc_10 = memref.alloc() : memref<2x2xf32>
        memref.copy %reinterpret_cast_9, %alloc_10 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
        %33 = bufferization.to_tensor %alloc_10 restrict writable : memref<2x2xf32>
        %34:7 = scf.for %arg33 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg34 = %arg27, %arg35 = %arg28, %arg36 = %arg29, %arg37 = %arg30, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
          %35 = arith.addi %arg35, %6 : index
          %36 = arith.addi %35, %c0 : index
          %reinterpret_cast_11 = memref.reinterpret_cast %arg0 to offset: [%36], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
          %37 = builtin.unrealized_conversion_cast %reinterpret_cast_11 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
          %alloc_12 = memref.alloc() : memref<2x2xf32>
          memref.copy %reinterpret_cast_11, %alloc_12 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
          %38 = bufferization.to_tensor %alloc_12 restrict writable : memref<2x2xf32>
          %39:7 = scf.for %arg41 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg42 = %37, %arg43 = %35, %arg44 = %arg37, %arg45 = %arg38, %arg46 = %arg39, %arg47 = %arg40, %arg48 = %38) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
            %40 = arith.addi %arg46, %c0 : index
            %reinterpret_cast_13 = memref.reinterpret_cast %arg1 to offset: [%40], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
            %41 = arith.addi %arg43, %6 : index
            %42 = arith.addi %41, %c0 : index
            %reinterpret_cast_14 = memref.reinterpret_cast %arg0 to offset: [%42], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
            %43 = builtin.unrealized_conversion_cast %reinterpret_cast_14 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
            %alloc_15 = memref.alloc() : memref<2x2xf32>
            memref.copy %reinterpret_cast_14, %alloc_15 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
            %44 = bufferization.to_tensor %alloc_15 restrict writable : memref<2x2xf32>
            bufferization.materialize_in_destination %arg47 in writable %reinterpret_cast_13 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
            %45 = arith.addi %arg46, %6 : index
            %46 = arith.addi %45, %c0 : index
            %reinterpret_cast_16 = memref.reinterpret_cast %arg1 to offset: [%46], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
            bufferization.materialize_in_destination %arg48 in writable %reinterpret_cast_16 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
            %47 = arith.addi %45, %6 : index
            %48 = arith.addi %47, %c0 : index
            %reinterpret_cast_17 = memref.reinterpret_cast %arg1 to offset: [%48], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
            bufferization.materialize_in_destination %44 in writable %reinterpret_cast_17 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
            %49 = arith.addi %47, %6 : index
            %50 = arith.addi %49, %c0 : index
            %reinterpret_cast_18 = memref.reinterpret_cast %arg1 to offset: [%50], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
            %51 = builtin.unrealized_conversion_cast %reinterpret_cast_18 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
            %52:7 = scf.for %arg49 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg50 = %arg47, %arg51 = %43, %arg52 = %41, %arg53 = %arg48, %arg54 = %44, %arg55 = %51, %arg56 = %49) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
              %53 = arith.addi %arg52, %c0 : index
              %reinterpret_cast_19 = memref.reinterpret_cast %arg0 to offset: [%53], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
              %alloc_20 = memref.alloc() : memref<2x2xf32>
              memref.copy %reinterpret_cast_19, %alloc_20 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
              %54 = bufferization.to_tensor %alloc_20 restrict writable : memref<2x2xf32>
              %55:7 = scf.for %arg57 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg58 = %arg51, %arg59 = %arg52, %arg60 = %arg53, %arg61 = %arg54, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %54) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
                %56 = arith.addi %arg59, %6 : index
                %57 = arith.addi %56, %c0 : index
                %reinterpret_cast_21 = memref.reinterpret_cast %arg0 to offset: [%57], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
                %58 = builtin.unrealized_conversion_cast %reinterpret_cast_21 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
                %alloc_22 = memref.alloc() : memref<2x2xf32>
                memref.copy %reinterpret_cast_21, %alloc_22 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
                %59 = bufferization.to_tensor %alloc_22 restrict writable : memref<2x2xf32>
                %60:7 = scf.for %arg65 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg66 = %58, %arg67 = %56, %arg68 = %arg61, %arg69 = %arg62, %arg70 = %arg63, %arg71 = %arg64, %arg72 = %59) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
                  %61 = arith.addi %arg70, %c0 : index
                  %reinterpret_cast_23 = memref.reinterpret_cast %arg1 to offset: [%61], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
                  %62 = arith.addi %arg67, %6 : index
                  %63 = arith.addi %62, %c0 : index
                  %reinterpret_cast_24 = memref.reinterpret_cast %arg0 to offset: [%63], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
                  %64 = builtin.unrealized_conversion_cast %reinterpret_cast_24 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
                  %alloc_25 = memref.alloc() : memref<2x2xf32>
                  memref.copy %reinterpret_cast_24, %alloc_25 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
                  %65 = bufferization.to_tensor %alloc_25 restrict writable : memref<2x2xf32>
                  bufferization.materialize_in_destination %arg71 in writable %reinterpret_cast_23 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
                  %66 = arith.addi %arg70, %6 : index
                  %67 = arith.addi %66, %c0 : index
                  %reinterpret_cast_26 = memref.reinterpret_cast %arg1 to offset: [%67], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
                  bufferization.materialize_in_destination %arg72 in writable %reinterpret_cast_26 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
                  %68 = arith.addi %66, %6 : index
                  %69 = arith.addi %68, %c0 : index
                  %reinterpret_cast_27 = memref.reinterpret_cast %arg1 to offset: [%69], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
                  bufferization.materialize_in_destination %65 in writable %reinterpret_cast_27 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
                  %70 = arith.addi %68, %6 : index
                  %71 = arith.addi %70, %c0 : index
                  %reinterpret_cast_28 = memref.reinterpret_cast %arg1 to offset: [%71], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
                  %72 = builtin.unrealized_conversion_cast %reinterpret_cast_28 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
                  %73:7 = scf.for %arg73 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg74 = %arg71, %arg75 = %64, %arg76 = %62, %arg77 = %arg72, %arg78 = %65, %arg79 = %72, %arg80 = %70) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                    %74 = arith.addi %arg76, %c0 : index
                    %reinterpret_cast_29 = memref.reinterpret_cast %arg0 to offset: [%74], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
                    %alloc_30 = memref.alloc() : memref<2x2xf32>
                    memref.copy %reinterpret_cast_29, %alloc_30 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
                    %75 = bufferization.to_tensor %alloc_30 restrict writable : memref<2x2xf32>
                    %76:6 = scf.for %arg81 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg82 = %arg75, %arg83 = %arg76, %arg84 = %arg77, %arg85 = %arg78, %arg86 = %arg79, %arg87 = %arg80) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                      %77 = arith.addi %arg83, %6 : index
                      %78 = arith.addi %77, %c0 : index
                      %reinterpret_cast_31 = memref.reinterpret_cast %arg0 to offset: [%78], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
                      %79 = builtin.unrealized_conversion_cast %reinterpret_cast_31 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
                      %alloc_32 = memref.alloc() : memref<2x2xf32>
                      memref.copy %reinterpret_cast_31, %alloc_32 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
                      %80 = bufferization.to_tensor %alloc_32 restrict writable : memref<2x2xf32>
                      %81:5 = scf.for %arg88 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg89 = %79, %arg90 = %77, %arg91 = %arg85, %arg92 = %arg86, %arg93 = %arg87) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                        %82 = arith.addi %arg93, %c0 : index
                        %reinterpret_cast_33 = memref.reinterpret_cast %arg1 to offset: [%82], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
                        %83 = arith.addi %arg90, %6 : index
                        %84 = arith.addi %83, %c0 : index
                        %reinterpret_cast_34 = memref.reinterpret_cast %arg0 to offset: [%84], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
                        %85 = builtin.unrealized_conversion_cast %reinterpret_cast_34 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
                        %alloc_35 = memref.alloc() : memref<2x2xf32>
                        memref.copy %reinterpret_cast_34, %alloc_35 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
                        %86 = bufferization.to_tensor %alloc_35 restrict writable : memref<2x2xf32>
                        bufferization.materialize_in_destination %75 in writable %reinterpret_cast_33 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
                        %87 = arith.addi %arg93, %6 : index
                        %88 = arith.addi %87, %c0 : index
                        %reinterpret_cast_36 = memref.reinterpret_cast %arg1 to offset: [%88], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
                        bufferization.materialize_in_destination %80 in writable %reinterpret_cast_36 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
                        %89 = arith.addi %87, %6 : index
                        %90 = arith.addi %89, %c0 : index
                        %reinterpret_cast_37 = memref.reinterpret_cast %arg1 to offset: [%90], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
                        bufferization.materialize_in_destination %86 in writable %reinterpret_cast_37 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
                        %91 = arith.addi %89, %6 : index
                        %92 = arith.addi %91, %c0 : index
                        %reinterpret_cast_38 = memref.reinterpret_cast %arg1 to offset: [%92], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
                        %93 = builtin.unrealized_conversion_cast %reinterpret_cast_38 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
                        scf.yield %85, %83, %86, %93, %91 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                      }
                      scf.yield %81#0, %81#1, %80, %81#2, %81#3, %81#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                    }
                    scf.yield %75, %76#0, %76#1, %76#2, %76#3, %76#4, %76#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                  }
                  scf.yield %73#1, %73#2, %73#4, %73#5, %73#6, %73#0, %73#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
                }
                scf.yield %60#0, %60#1, %60#6, %60#2, %60#3, %60#4, %60#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
              }
              scf.yield %55#6, %55#0, %55#1, %55#2, %55#3, %55#4, %55#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
            }
            scf.yield %52#1, %52#2, %52#4, %52#5, %52#6, %52#0, %52#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
          }
          scf.yield %39#0, %39#1, %39#6, %39#2, %39#3, %39#4, %39#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
        }
        scf.yield %34#6, %34#0, %34#1, %34#2, %34#3, %34#4, %34#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
      }
      %31:7 = scf.for %arg25 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg26 = %30#0, %arg27 = %30#1, %arg28 = %30#2, %arg29 = %30#3, %arg30 = %30#4, %arg31 = %30#5, %arg32 = %30#6) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %32 = arith.addi %arg28, %c0 : index
        %reinterpret_cast_9 = memref.reinterpret_cast %arg0 to offset: [%32], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
        %alloc_10 = memref.alloc() : memref<2x2xf32>
        memref.copy %reinterpret_cast_9, %alloc_10 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
        %33 = bufferization.to_tensor %alloc_10 restrict writable : memref<2x2xf32>
        %34:6 = scf.for %arg33 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg34 = %arg27, %arg35 = %arg28, %arg36 = %arg29, %arg37 = %arg30, %arg38 = %arg31, %arg39 = %arg32) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
          %35 = arith.addi %arg35, %6 : index
          %36 = arith.addi %35, %c0 : index
          %reinterpret_cast_11 = memref.reinterpret_cast %arg0 to offset: [%36], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
          %37 = builtin.unrealized_conversion_cast %reinterpret_cast_11 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
          %alloc_12 = memref.alloc() : memref<2x2xf32>
          memref.copy %reinterpret_cast_11, %alloc_12 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
          %38 = bufferization.to_tensor %alloc_12 restrict writable : memref<2x2xf32>
          %39:5 = scf.for %arg40 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg41 = %37, %arg42 = %35, %arg43 = %arg37, %arg44 = %arg38, %arg45 = %arg39) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
            %40 = arith.addi %arg45, %c0 : index
            %reinterpret_cast_13 = memref.reinterpret_cast %arg1 to offset: [%40], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
            %41 = arith.addi %arg42, %6 : index
            %42 = arith.addi %41, %c0 : index
            %reinterpret_cast_14 = memref.reinterpret_cast %arg0 to offset: [%42], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
            %43 = builtin.unrealized_conversion_cast %reinterpret_cast_14 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
            %alloc_15 = memref.alloc() : memref<2x2xf32>
            memref.copy %reinterpret_cast_14, %alloc_15 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
            %44 = bufferization.to_tensor %alloc_15 restrict writable : memref<2x2xf32>
            bufferization.materialize_in_destination %33 in writable %reinterpret_cast_13 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
            %45 = arith.addi %arg45, %6 : index
            %46 = arith.addi %45, %c0 : index
            %reinterpret_cast_16 = memref.reinterpret_cast %arg1 to offset: [%46], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
            bufferization.materialize_in_destination %38 in writable %reinterpret_cast_16 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
            %47 = arith.addi %45, %6 : index
            %48 = arith.addi %47, %c0 : index
            %reinterpret_cast_17 = memref.reinterpret_cast %arg1 to offset: [%48], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
            bufferization.materialize_in_destination %44 in writable %reinterpret_cast_17 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
            %49 = arith.addi %47, %6 : index
            %50 = arith.addi %49, %c0 : index
            %reinterpret_cast_18 = memref.reinterpret_cast %arg1 to offset: [%50], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
            %51 = builtin.unrealized_conversion_cast %reinterpret_cast_18 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
            scf.yield %43, %41, %44, %51, %49 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
          }
          scf.yield %39#0, %39#1, %38, %39#2, %39#3, %39#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
        }
        scf.yield %33, %34#0, %34#1, %34#2, %34#3, %34#4, %34#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
      }
      scf.yield %31#2, %31#5, %31#6, %31#0, %31#3 : index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
    }
    %17 = arith.addi %16#0, %6 : index
    scf.yield %17, %16#1, %16#2, %16#3 : index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
  }
  %11:3 = scf.for %arg14 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg15 = %10#0, %arg16 = %10#1, %arg17 = %10#2) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
    %13 = arith.addi %arg15, %c0 : index
    %reinterpret_cast_1 = memref.reinterpret_cast %arg0 to offset: [%13], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
    %alloc_2 = memref.alloc() : memref<2x2xf32>
    memref.copy %reinterpret_cast_1, %alloc_2 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
    %14 = bufferization.to_tensor %alloc_2 restrict writable : memref<2x2xf32>
    %15:3 = scf.for %arg18 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg19 = %arg15, %arg20 = %arg16, %arg21 = %arg17) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %17 = arith.addi %arg19, %6 : index
      %18 = arith.addi %17, %c0 : index
      %reinterpret_cast_3 = memref.reinterpret_cast %arg0 to offset: [%18], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
      %alloc_4 = memref.alloc() : memref<2x2xf32>
      memref.copy %reinterpret_cast_3, %alloc_4 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
      %19 = bufferization.to_tensor %alloc_4 restrict writable : memref<2x2xf32>
      %20:3 = scf.for %arg22 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg23 = %17, %arg24 = %arg20, %arg25 = %arg21) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %21 = arith.addi %arg25, %c0 : index
        %reinterpret_cast_5 = memref.reinterpret_cast %arg1 to offset: [%21], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
        %22 = arith.addi %arg23, %6 : index
        %23 = arith.addi %22, %c0 : index
        %reinterpret_cast_6 = memref.reinterpret_cast %arg0 to offset: [%23], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
        %alloc_7 = memref.alloc() : memref<2x2xf32>
        memref.copy %reinterpret_cast_6, %alloc_7 : memref<2x2xf32, strided<[?, ?], offset: ?>> to memref<2x2xf32>
        %24 = bufferization.to_tensor %alloc_7 restrict writable : memref<2x2xf32>
        bufferization.materialize_in_destination %14 in writable %reinterpret_cast_5 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
        %25 = arith.addi %arg25, %6 : index
        %26 = arith.addi %25, %c0 : index
        %reinterpret_cast_8 = memref.reinterpret_cast %arg1 to offset: [%26], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
        bufferization.materialize_in_destination %19 in writable %reinterpret_cast_8 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
        %27 = arith.addi %25, %6 : index
        %28 = arith.addi %27, %c0 : index
        %reinterpret_cast_9 = memref.reinterpret_cast %arg1 to offset: [%28], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
        bufferization.materialize_in_destination %24 in writable %reinterpret_cast_9 : (tensor<2x2xf32>, memref<2x2xf32, strided<[?, ?], offset: ?>>) -> ()
        %29 = arith.addi %27, %6 : index
        %30 = arith.addi %29, %c0 : index
        %reinterpret_cast_10 = memref.reinterpret_cast %arg1 to offset: [%30], sizes: [2, 2], strides: [%2, %3] : memref<*xf32> to memref<2x2xf32, strided<[?, ?], offset: ?>>
        %31 = builtin.unrealized_conversion_cast %reinterpret_cast_10 : memref<2x2xf32, strided<[?, ?], offset: ?>> to tensor<2x2x!tt.ptr<f32>>
        scf.yield %22, %31, %29 : index, tensor<2x2x!tt.ptr<f32>>, index
      }
      scf.yield %20#0, %20#1, %20#2 : index, tensor<2x2x!tt.ptr<f32>>, index
    }
    %16 = arith.addi %15#0, %6 : index
    scf.yield %16, %15#1, %15#2 : index, tensor<2x2x!tt.ptr<f32>>, index
  }
  %12 = arith.addi %11#0, %6 : index
  scf.yield %12, %11#1, %11#2 : index, tensor<2x2x!tt.ptr<f32>>, index
}
    %24:2 = scf.for %arg4 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg5 = %11, %arg6 = %15) -> (tensor<2x2x!tt.ptr<f32>>, tensor<2x2x!tt.ptr<f32>>)  : i32 {
            ^
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir

--

********************
XFAIL: TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_unsupported_add_offset.mlir (33 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_advance.mlir (34 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/triton-to-structured-prepass.mlir (35 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/make_tensor_ptr_ordering_error.mlir (36 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/early_return.mlir (37 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_reduce.mlir (38 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_reduce.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "minmax_sgt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %3 = "arith.cmpi"(%arg1, %arg2) <{predicate = 4 : i64}> : (i32, i32) -> i1
      %4 = "arith.select"(%3, %arg1, %arg2) : (i1, i32, i32) -> i32
      "tt.reduce.return"(%4) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
!tt.ptr<i32>
module {
  tt.func public @minmax_sgt(%arg0: !tt.ptr<i32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %2 = arith.cmpi sgt, %arg1, %arg2 : i32
      %3 = arith.select %2, %arg1, %arg2 : i32
      tt.reduce.return %3 : i32
    }) : (tensor<4096xi32>) -> i32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    tt.store %1, %0 : !tt.ptr<i32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "minmax_ugt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %3 = "arith.cmpi"(%arg1, %arg2) <{predicate = 8 : i64}> : (i32, i32) -> i1
      %4 = "arith.select"(%3, %arg1, %arg2) : (i1, i32, i32) -> i32
      "tt.reduce.return"(%4) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
!tt.ptr<i32>
module {
  tt.func public @minmax_ugt(%arg0: !tt.ptr<i32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %2 = arith.cmpi ugt, %arg1, %arg2 : i32
      %3 = arith.select %2, %arg1, %arg2 : i32
      tt.reduce.return %3 : i32
    }) : (tensor<4096xi32>) -> i32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    tt.store %1, %0 : !tt.ptr<i32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "minmax_slt", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %3 = "arith.cmpi"(%arg1, %arg2) <{predicate = 2 : i64}> : (i32, i32) -> i1
      %4 = "arith.select"(%3, %arg1, %arg2) : (i1, i32, i32) -> i32
      "tt.reduce.return"(%4) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
!tt.ptr<i32>
module {
  tt.func public @minmax_slt(%arg0: !tt.ptr<i32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %2 = arith.cmpi slt, %arg1, %arg2 : i32
      %3 = arith.select %2, %arg1, %arg2 : i32
      tt.reduce.return %3 : i32
    }) : (tensor<4096xi32>) -> i32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    tt.store %1, %0 : !tt.ptr<i32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
"builtin.module"() ({
  "tt.func"() <{function_type = (!tt.ptr<i32>) -> (), sym_name = "minmax_ult", sym_visibility = "public"}> ({
  ^bb0(%arg0: !tt.ptr<i32>):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = dense<0> : tensor<4096xi32>}> : () -> tensor<4096xi32>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %3 = "arith.cmpi"(%arg1, %arg2) <{predicate = 6 : i64}> : (i32, i32) -> i1
      %4 = "arith.select"(%3, %arg1, %arg2) : (i1, i32, i32) -> i32
      "tt.reduce.return"(%4) : (i32) -> ()
    }) : (tensor<4096xi32>) -> i32
    "tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
!tt.ptr<i32>
module {
  tt.func public @minmax_ult(%arg0: !tt.ptr<i32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %2 = arith.cmpi ult, %arg1, %arg2 : i32
      %3 = arith.select %2, %arg1, %arg2 : i32
      tt.reduce.return %3 : i32
    }) : (tensor<4096xi32>) -> i32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    tt.store %1, %0 : !tt.ptr<i32>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:20:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:2:119: note: scanning from here
 func.func @minmax_sgt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:2:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_sgt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:16:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:57:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:24:119: note: scanning from here
 func.func @minmax_ugt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:24:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ugt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:37:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:94:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:45:119: note: scanning from here
 func.func @minmax_slt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:45:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_slt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:59:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:132:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:67:119: note: scanning from here
 func.func @minmax_ult(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:67:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ult(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:81:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
           1: module {
           2:  func.func @minmax_sgt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
dag:20'0                                                                                                                            X error: no match found
dag:20'1                                                                                                                              with "PARAM_0_" equal to "%arg0"
           3:  %c0 = arith.constant 0 : index
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           4:  %c-2147483648_i32 = arith.constant -2147483648 : i32
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           5:  %c0_i32 = arith.constant 0 : i32
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           6:  %0 = tensor.empty() : tensor<4096xi32>
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           7:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32>
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          11:  (%in: i32, %init: i32) {
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~
          12:  %3 = arith.maxsi %in, %init : i32
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          13:  linalg.yield %3 : i32
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~
          14:  }
dag:20'0      ~~~
          15:  %extracted = tensor.extract %reduced[] : tensor<i32>
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          16:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:20'2                   ?                                                                                                                                           possible intended match
          17:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>>
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          18:  return
dag:20'0      ~~~~~~~~
          19:  }
dag:20'0      ~~~
          20: }
dag:20'0      ~~
          21:
dag:20'0      ~
          22: // -----
dag:20'0      ~~~~~~~~~
          23: module {
dag:20'0      ~~~~~~~~~
          24:  func.func @minmax_ugt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~
dag:57'0                                                                                                                            X error: no match found
dag:57'1                                                                                                                              with "PARAM_0_" equal to "%arg0"
          25:  %c0 = arith.constant 0 : index
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          26:  %c0_i32 = arith.constant 0 : i32
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          27:  %0 = tensor.empty() : tensor<4096xi32>
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          28:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32>
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          29:  %2 = bufferization.alloc_tensor() : tensor<i32>
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          32:  (%in: i32, %init: i32) {
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~
          33:  %3 = arith.maxui %in, %init : i32
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          34:  linalg.yield %3 : i32
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~
          35:  }
dag:57'0      ~~~
          36:  %extracted = tensor.extract %reduced[] : tensor<i32>
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          37:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:57'2                   ?                                                                                                                                           possible intended match
          38:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>>
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          39:  return
dag:57'0      ~~~~~~~~
          40:  }
dag:57'0      ~~~
          41: }
dag:57'0      ~~
          42:
dag:57'0      ~
          43: // -----
dag:57'0      ~~~~~~~~~
          44: module {
dag:57'0      ~~~~~~~~~
          45:  func.func @minmax_slt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~
dag:94'0                                                                                                                            X error: no match found
dag:94'1                                                                                                                              with "PARAM_0_" equal to "%arg0"
          46:  %c0 = arith.constant 0 : index
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          47:  %c2147483647_i32 = arith.constant 2147483647 : i32
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          48:  %c0_i32 = arith.constant 0 : i32
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          49:  %0 = tensor.empty() : tensor<4096xi32>
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          50:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32>
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          54:  (%in: i32, %init: i32) {
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~
          55:  %3 = arith.minsi %in, %init : i32
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          56:  linalg.yield %3 : i32
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~
          57:  }
dag:94'0      ~~~
          58:  %extracted = tensor.extract %reduced[] : tensor<i32>
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          59:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:94'2                   ?                                                                                                                                           possible intended match
          60:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>>
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          61:  return
dag:94'0      ~~~~~~~~
          62:  }
dag:94'0      ~~~
          63: }
dag:94'0      ~~
          64:
dag:94'0      ~
          65: // -----
dag:94'0      ~~~~~~~~~
          66: module {
dag:94'0      ~~~~~~~~~
          67:  func.func @minmax_ult(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~
dag:132'0                                                                                                                           X error: no match found
dag:132'1                                                                                                                             with "PARAM_0_" equal to "%arg0"
          68:  %c0 = arith.constant 0 : index
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          69:  %c-1_i32 = arith.constant -1 : i32
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          70:  %c0_i32 = arith.constant 0 : i32
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          71:  %0 = tensor.empty() : tensor<4096xi32>
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          72:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32>
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          76:  (%in: i32, %init: i32) {
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
          77:  %3 = arith.minui %in, %init : i32
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          78:  linalg.yield %3 : i32
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~
          79:  }
dag:132'0     ~~~
          80:  %extracted = tensor.extract %reduced[] : tensor<i32>
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          81:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:132'2                  ?                                                                                                                                           possible intended match
          82:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>>
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          83:  return
dag:132'0     ~~~~~~~~
          84:  }
dag:132'0     ~~~
          85: }
dag:132'0     ~~
          86:
dag:132'0     ~
>>>>>>

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/masked_ldst_2d.mlir (39 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/use_mid_chain.mlir (40 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-02-fused-softmax.mlir (41 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_tensor_reshape.mlir (42 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_extern_elementwise.mlir (43 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_extern_elementwise.mlir (44 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_accumulation.mlir (45 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/dot.mlir (46 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-01-vector-add.mlir (47 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/unsupported_extern_elementwise.mlir (48 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_loopback.mlir (49 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/ridiculously_nested_loops.mlir (50 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_2d_example.mlir (51 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/masked_ldst_1d.mlir (52 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/use_end_chain.mlir (53 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_reshape_broadcast.mlir (54 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_bf16_axis1.mlir (55 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-05-layer-norm-fwd.mlir (56 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-05-layer-norm-dwdb.mlir (57 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/get_num_programs.mlir (58 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_add_value.mlir (59 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_f32_axis0.mlir (60 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_bf16_axis0.mlir (61 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/masked_ldst_1d.mlir (62 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/use_end_chain.mlir (63 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_splat_2d.mlir (64 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_expand_ptr.mlir (65 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_addi_reduce.mlir (66 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/tensor_indices_loop_iterarg_with_masks.mlir (67 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_2d_example.mlir (68 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterargs_not_used_ptranalysis_e2e.mlir (69 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_for.mlir (70 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_more_init_args.mlir (71 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-05-layer-norm-fwd.mlir (72 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_bf16_axis1.mlir (73 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterargs_nested.mlir (74 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_dim1.mlir (75 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_f32_axis0.mlir (76 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_2d_elemwise_arith_ternary.mlir (77 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_nested.mlir (78 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_used_after_update.mlir (79 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/cumsum.mlir (80 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/triton_assert.mlir (81 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/masked_ldst_sitofp_other.mlir (82 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/arith_not_ptr_arith.mlir (83 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_expand_ptr.mlir (84 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_loopback.mlir (85 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_broadcast.mlir (86 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/wraparound_unsupported_add_offset.mlir (87 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/triton_assert.mlir (88 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducemax_32_256_bf16.mlir (89 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/wraparound_stacked.mlir (90 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_used_before_update.mlir (91 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_add_value.mlir (92 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/get_num_programs.mlir (93 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_accumulation.mlir (94 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/masked_ldst_sitofp_other.mlir (95 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_for_2d.mlir (96 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_nested.mlir (97 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducemax_32_256_bf16.mlir (98 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-02-fused-softmax.mlir (99 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_f32_axis1.mlir (100 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_mul_const_const.mlir (101 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_bf16_axis1.mlir (102 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_2d_example.mlir (103 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_argmin_argmax_2d.mlir (104 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_splat.mlir (105 of 215)
XFAIL: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_dim1.mlir (106 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_used_after_update.mlir (107 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_2d_elemwise_arith_unary.mlir (108 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_scalar.mlir (109 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/wraparound_side_by_side.mlir (110 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/use_dot_opc.mlir (111 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_used_before_update.mlir (112 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_minmax_fp_reduce.mlir (113 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-05-layer-norm-dwdb.mlir (114 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/nested_loops.mlir (115 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_2d_elemwise_arith_binary.mlir (116 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/use_mid_chain.mlir (117 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_f32_axis0.mlir (118 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_2d_elemwise_arith_binary.mlir (119 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/dot.mlir (120 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/unsupported_extern_elementwise.mlir (121 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/wraparound_side_by_side.mlir (122 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/block_ptr_advance.mlir (123 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_1d_elemwise_arith_binary.mlir (124 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_mul_const_const.mlir (125 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_splat.mlir (126 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-01-vector-add.mlir (127 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/arith_not_ptr_arith.mlir (128 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/bitcast.mlir (129 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_mul_value_const.mlir (130 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/wraparound_stacked.mlir (131 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_2d_elemwise_arith_ternary.mlir (132 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_mul_const_const.mlir (133 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/masked_ldst_sitofp_other.mlir (134 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/block_ptr_advance.mlir (135 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_middle_dim.mlir (136 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/bitcast.mlir (137 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-03-matrix-multiplication.mlir (138 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_reshape_broadcast.mlir (139 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/block_ptr_advance.mlir (140 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-03-matrix-multiplication.mlir (141 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_expand_ptr.mlir (142 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_minmax_reduce.mlir (143 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_accumulation.mlir (144 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_tensor_reshape.mlir (145 of 215)
XFAIL: TRITON-SHARED :: Conversion/TritonToLinalg/wraparound_unsupported_add_offset.mlir (146 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_nested.mlir (147 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_tensor_reshape.mlir (148 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_f32_axis1.mlir (149 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_reshape_broadcast.mlir (150 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/masked_ldst_1d.mlir (151 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-05-layer-norm-fwd.mlir (152 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_bf16_axis0.mlir (153 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/cumsum.mlir (154 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reduce_extend_fp32_precision.mlir (155 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-02-fused-softmax.mlir (156 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_more_init_args.mlir (157 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_bf16_axis0.mlir (158 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_more_init_args.mlir (159 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_1d_elemwise_arith_ternary.mlir (160 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_addi_reduce.mlir (161 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_used_before_update.mlir (162 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/dot.mlir (163 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/early_return.mlir (164 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_argmin_argmax.mlir (165 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_1d_elemwise_arith_unary.mlir (166 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_minmax_fp_reduce.mlir (167 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_1d_elemwise_arith_binary.mlir (168 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_loopback.mlir (169 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/bitcast.mlir (170 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterargs_not_used_ptranalysis_prepass.mlir (171 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_minmax_reduce.mlir (172 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_argmin_argmax_2d.mlir (173 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_nested.mlir (174 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_argmin_argmax.mlir (175 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_splat_2d.mlir (176 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/use_dot_opc.mlir (177 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/masked_ldst_2d.mlir (178 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/dot.mlir (179 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_extern_elementwise.mlir (180 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_minmax.mlir (181 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/cumsum.mlir (182 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_1d_elemwise_arith_unary.mlir (183 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_add_value.mlir (184 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_splat_float.mlir (185 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_for.mlir (186 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_splat_2d.mlir (187 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_splat_float.mlir (188 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_mul_value_const.mlir (189 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_for_2d.mlir (190 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/triton_assert.mlir (191 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/sign_extend_i32_to_i64.mlir (192 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/use_mid_chain.mlir (193 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_nested.mlir (194 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_1d_elemwise_arith_ternary.mlir (195 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterarg_with_masks.mlir (196 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_nested.mlir (197 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_splat.mlir (198 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/bitcast.mlir (199 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_mul_value_const.mlir (200 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/use_end_chain.mlir (201 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_scalar.mlir (202 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_broadcast.mlir (203 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/masked_ldst_2d.mlir (204 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/unsupported_extern_elementwise.mlir (205 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_2d_elemwise_arith_unary.mlir (206 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_f32_axis1.mlir (207 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_middle_dim.mlir (208 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_broadcast.mlir (209 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_loopback.mlir (210 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/use_dot_opc.mlir (211 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-01-vector-add.mlir (212 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/arith_not_ptr_arith.mlir (213 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_used_after_update.mlir (214 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_loopback.mlir (215 of 215)
********************
Failed Tests (27):
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_chain.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_addi_reduce.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_reduce.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_splat_float.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/nested_loops.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_middle_dim.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_scalar.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/ridiculously_nested_loops.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_side_by_side.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_stacked.mlir


Testing Time: 2.80s

Total Discovered Tests: 215
  Passed           : 185 (86.05%)
  Expectedly Failed:   3 (1.40%)
  Failed           :  27 (12.56%)
