-- Testing: 215 tests, 8 workers --
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/masked_ldst_sitofp_other.mlir (1 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-02-fused-softmax.mlir (2 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/masked_ldst_2d.mlir (3 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-05-layer-norm-fwd.mlir (4 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-03-matrix-multiplication.mlir (5 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-05-layer-norm-dwdb.mlir (6 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/masked_ldst_1d.mlir (7 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/tensor_indices_loop_iterarg_with_masks.mlir (8 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-01-vector-add.mlir (9 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_stacked.mlir (10 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_stacked.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir:1 offset :47:13: warning: PtrAnalysis: allowing adding pointer state with modulo in dim 0 to another pointer state with offset in dim 0.
Please verify the operand that contains a scalar is meant to increment pointers in dim1. If that is not the case it WILL LEAD TO WRONG COMPILATION RESULTS.

To avoid this warning, use expand_dims (instead of splat) to explicitly specify which dimension contains the scalar.
      %33 = tt.addptr %arg9, %30 : tensor<4x4x!tt.ptr<f32>>, tensor<4x4xi32>
            ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir:1 offset :47:13: note: see current operation: %48 = tt.addptr %arg9, %42 : tensor<4x4x!tt.ptr<f32>>, tensor<4x4xi32>
module {
  tt.func public @wrap_stacked_masked_loop_01234567(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
    %cst = arith.constant -9.900000e+01 : f32
    %c0 = arith.constant 0 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %c4_i32 = arith.constant 4 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg4 : i32 to index
    %2 = arith.muli %1, %c2 : index
    %3 = arith.muli %0, %1 : index
    %4 = arith.index_cast %arg5 : i32 to index
    %5 = arith.muli %4, %c3 : index
    %6 = arith.index_cast %arg6 : i32 to index
    %7 = arith.index_cast %arg7 : i32 to index
    %8 = arith.muli %arg5, %c4_i32 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10:2 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %2, %arg10 = %c0) -> (index, index)  : i32 {
      %11 = tts.make_tptr %arg1 to sizes: [4, 4], strides: [%6, %7], offsets: [%arg10, %c0], shape: [0, 0], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %12 = tts.make_tptr %arg0 to sizes: [4, 4], strides: [%1, %4], offsets: [%arg9, %5], shape: [%3, 0], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %13 = "tts.load"(%12, %cst) <{operandSegmentSizes = array<i32: 1, 0, 1>, static_mask_dims = array<i64: 4, 3>}> : (tensor<4x4x!tt.ptr<f32>>, f32) -> tensor<4x4xf32>
      "tts.store"(%11, %13) <{static_mask_dims = array<i64>}> : (tensor<4x4x!tt.ptr<f32>>, tensor<4x4xf32>) -> ()
      %14 = arith.addi %arg9, %9 : index
      %15 = arith.addi %arg10, %9 : index
      scf.yield %14, %15 : index, index
    }
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir:1 offset :44:13: error: failed to legalize operation 'tts.make_tptr' that was explicitly marked illegal
    %31:2 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %15, %arg10 = %26) -> (tensor<4x4x!tt.ptr<f32>>, tensor<4x4x!tt.ptr<f32>>)  : i32 {
            ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir:1 offset :44:13: note: see current operation: %24 = "tts.make_tptr"(%1, %11, %14, %arg15, %15, %13) <{operandSegmentSizes = array<i32: 1, 2, 2, 1>, order = array<i32>, sizes = array<i64: 4, 4>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: -9223372036854775808, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index, index) -> tensor<4x4x!tt.ptr<f32>>
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_addi_reduce.mlir (11 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_addi_reduce.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
module {
  tt.func public @addi(%arg0: !tt.ptr<i32>) {
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %1 = arith.addi %arg1, %arg2 : i32
      tt.reduce.return %1 : i32
    }) : (tensor<4096xi32>) -> i32
    tt.store %arg0, %0 : !tt.ptr<i32>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:19:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:2:113: note: scanning from here
 func.func @addi(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                ^
<stdin>:2:113: note: with "PARAM_0_" equal to "%arg0"
 func.func @addi(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                ^
<stdin>:15:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @addi(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:19'0                                                                                                                     X error: no match found
dag:19'1                                                                                                                       with "PARAM_0_" equal to "%arg0"
          3:  %c0 = arith.constant 0 : index 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c0_i32 = arith.constant 0 : i32 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %0 = tensor.empty() : tensor<4096xi32> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %2 = bufferization.alloc_tensor() : tensor<i32> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         10:  (%in: i32, %init: i32) { 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
         11:  %3 = arith.addi %in, %init : i32 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  linalg.yield %3 : i32 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~
         13:  } 
dag:19'0     ~~~
         14:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         15:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:19'2                  ?                                                                                                                                           possible intended match
         16:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         17:  return 
dag:19'0     ~~~~~~~~
         18:  } 
dag:19'0     ~~~
         19: } 
dag:19'0     ~~
         20:  
dag:19'0     ~
>>>>>>

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_argmin_argmax_2d.mlir (12 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir (13 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
module {
  tt.func public @maxnumf(%arg0: !tt.ptr<f32>) {
    %cst = arith.constant dense<0.000000e+00> : tensor<4096xf32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32, %arg2: f32):
      %1 = arith.maxnumf %arg1, %arg2 : f32
      tt.reduce.return %1 : f32
    }) : (tensor<4096xf32>) -> f32
    tt.store %arg0, %0 : !tt.ptr<f32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
module {
  tt.func public @minnumf(%arg0: !tt.ptr<f32>) {
    %cst = arith.constant dense<0.000000e+00> : tensor<4096xf32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32, %arg2: f32):
      %1 = arith.minnumf %arg1, %arg2 : f32
      tt.reduce.return %1 : f32
    }) : (tensor<4096xf32>) -> f32
    tt.store %arg0, %0 : !tt.ptr<f32>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:20:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:2:116: note: scanning from here
 func.func @maxnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:2:116: note: with "PARAM_0_" equal to "%arg0"
 func.func @maxnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:16:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:57:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:24:116: note: scanning from here
 func.func @minnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:24:116: note: with "PARAM_0_" equal to "%arg0"
 func.func @minnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:38:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @maxnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:20'0                                                                                                                        X error: no match found
dag:20'1                                                                                                                          with "PARAM_0_" equal to "%arg0"
          3:  %c0 = arith.constant 0 : index 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %cst = arith.constant 0xFF800000 : f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %cst_0 = arith.constant 0.000000e+00 : f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %0 = tensor.empty() : tensor<4096xf32> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<4096xf32>) -> tensor<4096xf32> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         11:  (%in: f32, %init: f32) { 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  %3 = arith.maxnumf %in, %init : f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         13:  linalg.yield %3 : f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~
         14:  } 
dag:20'0     ~~~
         15:  %extracted = tensor.extract %reduced[] : tensor<f32> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         16:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:20'2                  ?                                                                                                                                           possible intended match
         17:  affine.store %extracted, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         18:  return 
dag:20'0     ~~~~~~~~
         19:  } 
dag:20'0     ~~~
         20: } 
dag:20'0     ~~
         21:  
dag:20'0     ~
         22: // ----- 
dag:20'0     ~~~~~~~~~
         23: module { 
dag:20'0     ~~~~~~~~~
         24:  func.func @minnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:20'0     ~~~~~~~~~~~~~~~~~~~
dag:57'0                                                                                                                        X error: no match found
dag:57'1                                                                                                                          with "PARAM_0_" equal to "%arg0"
         25:  %c0 = arith.constant 0 : index 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         26:  %cst = arith.constant 0x7F800000 : f32 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         27:  %cst_0 = arith.constant 0.000000e+00 : f32 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         28:  %0 = tensor.empty() : tensor<4096xf32> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         29:  %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<4096xf32>) -> tensor<4096xf32> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         33:  (%in: f32, %init: f32) { 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
         34:  %3 = arith.minnumf %in, %init : f32 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         35:  linalg.yield %3 : f32 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~
         36:  } 
dag:57'0     ~~~
         37:  %extracted = tensor.extract %reduced[] : tensor<f32> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         38:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:57'2                  ?                                                                                                                                           possible intended match
         39:  affine.store %extracted, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         40:  return 
dag:57'0     ~~~~~~~~
         41:  } 
dag:57'0     ~~~
         42: } 
dag:57'0     ~~
         43:  
dag:57'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax.mlir (14 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
module {
  tt.func public @minmax_olt(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32) {
    %0 = arith.cmpf olt, %arg1, %arg2 : f32
    %1 = arith.select %0, %arg1, %arg2 : f32
    tt.store %arg0, %1 : !tt.ptr<f32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
module {
  tt.func public @minmax_ole(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32) {
    %0 = arith.cmpf ole, %arg1, %arg2 : f32
    %1 = arith.select %0, %arg1, %arg2 : f32
    tt.store %arg0, %1 : !tt.ptr<f32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
module {
  tt.func public @minmax_ogt(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32) {
    %0 = arith.cmpf ogt, %arg1, %arg2 : f32
    %1 = arith.select %0, %arg1, %arg2 : f32
    tt.store %arg0, %1 : !tt.ptr<f32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
module {
  tt.func public @minmax_oge(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32) {
    %0 = arith.cmpf oge, %arg1, %arg2 : f32
    %1 = arith.select %0, %arg1, %arg2 : f32
    tt.store %arg0, %1 : !tt.ptr<f32>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:46:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:2:143: note: scanning from here
 func.func @minmax_olt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:2:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_olt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:5:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:53:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:13:143: note: scanning from here
 func.func @minmax_ole(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:13:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ole(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:16:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:60:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:24:143: note: scanning from here
 func.func @minmax_ogt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:24:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ogt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:27:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:67:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:35:143: note: scanning from here
 func.func @minmax_oge(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:35:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_oge(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:38:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @minmax_olt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
dag:46'0                                                                                                                                                   X error: no match found
dag:46'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
          3:  %c0 = arith.constant 0 : index 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %0 = arith.minimumf %arg1, %arg2 : f32 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:46'2                  ?                                                                                                                                           possible intended match
          6:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  return 
dag:46'0     ~~~~~~~~
          8:  } 
dag:46'0     ~~~
          9: } 
dag:46'0     ~~
         10:  
dag:46'0     ~
         11: // ----- 
dag:46'0     ~~~~~~~~~
         12: module { 
dag:46'0     ~~~~~~~~~
         13:  func.func @minmax_ole(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~
dag:53'0                                                                                                                                                   X error: no match found
dag:53'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
         14:  %c0 = arith.constant 0 : index 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         15:  %0 = arith.minimumf %arg1, %arg2 : f32 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         16:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:53'2                  ?                                                                                                                                           possible intended match
         17:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         18:  return 
dag:53'0     ~~~~~~~~
         19:  } 
dag:53'0     ~~~
         20: } 
dag:53'0     ~~
         21:  
dag:53'0     ~
         22: // ----- 
dag:53'0     ~~~~~~~~~
         23: module { 
dag:53'0     ~~~~~~~~~
         24:  func.func @minmax_ogt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~
dag:60'0                                                                                                                                                   X error: no match found
dag:60'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
         25:  %c0 = arith.constant 0 : index 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         26:  %0 = arith.maximumf %arg1, %arg2 : f32 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         27:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:60'2                  ?                                                                                                                                           possible intended match
         28:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         29:  return 
dag:60'0     ~~~~~~~~
         30:  } 
dag:60'0     ~~~
         31: } 
dag:60'0     ~~
         32:  
dag:60'0     ~
         33: // ----- 
dag:60'0     ~~~~~~~~~
         34: module { 
dag:60'0     ~~~~~~~~~
         35:  func.func @minmax_oge(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~
dag:67'0                                                                                                                                                   X error: no match found
dag:67'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
         36:  %c0 = arith.constant 0 : index 
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         37:  %0 = arith.maximumf %arg1, %arg2 : f32 
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         38:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:67'2                  ?                                                                                                                                           possible intended match
         39:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         40:  return 
dag:67'0     ~~~~~~~~
         41:  } 
dag:67'0     ~~~
         42: } 
dag:67'0     ~~
         43:  
dag:67'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_chain.mlir (15 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_chain.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: remark: PtrAnalysis: scalar loadOp will not be rewritten
      %6 = tt.load %2 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: note: see current operation: %16 = tt.load %8 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: remark: PtrAnalysis: Failed to rewrite LoadOp
      %6 = tt.load %2 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: note: see current operation: %16 = tt.load %8 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: remark: PtrAnalysis: scalar loadOp will not be rewritten
      %7 = tt.load %3 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: note: see current operation: %17 = tt.load %10 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: remark: PtrAnalysis: Failed to rewrite LoadOp
      %7 = tt.load %3 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: note: see current operation: %17 = tt.load %10 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: remark: PtrAnalysis: scalar storeOp will not be rewritten
      tt.store %4, %6 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: note: see current operation: tt.store %13, %16 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: remark: PtrAnalysis: Failed to rewrite StoreOp
      tt.store %4, %6 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: note: see current operation: tt.store %13, %16 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: remark: PtrAnalysis: scalar storeOp will not be rewritten
      tt.store %5, %7 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: note: see current operation: tt.store %15, %17 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: remark: PtrAnalysis: Failed to rewrite StoreOp
      tt.store %5, %7 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: note: see current operation: tt.store %15, %17 : !tt.ptr<f32>
%14 = unrealized_conversion_cast %13 : i64 to !tt.ptr<f32> {"reconvert-offset-to-ptr"}
%8 = unrealized_conversion_cast %7 : i64 to !tt.ptr<f32> {"reconvert-offset-to-ptr"}
%19 = unrealized_conversion_cast %18 : i64 to !tt.ptr<f32> {"reconvert-offset-to-ptr"}
%12 = unrealized_conversion_cast %11 : i64 to !tt.ptr<f32> {"reconvert-offset-to-ptr"}
module {
  tt.func public @addptr(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>) attributes {noinline = false} {
    %c0_i64 = arith.constant 0 : i64
    %c0_i64_0 = arith.constant 0 : i64
    %c2_i32 = arith.constant 2 : i32
    %c10_i32 = arith.constant 10 : i32
    %c0_i32 = arith.constant 0 : i32
    %c1_i32 = arith.constant 1 : i32
    %0 = arith.extsi %c1_i32 : i32 to i64
    %1 = arith.addi %c0_i64_0, %0 : i64
    %2 = arith.extsi %c1_i32 : i32 to i64
    %3 = arith.addi %c0_i64, %2 : i64
    scf.for %arg2 = %c0_i32 to %c10_i32 step %c2_i32  : i32 {
      %4 = arith.extsi %arg2 : i32 to i64
      %5 = arith.addi %1, %4 : i64
      %6 = "tts.create_ptr"(%arg0, %5) : (!tt.ptr<f32>, i64) -> !tt.ptr<f32>
      %7 = builtin.unrealized_conversion_cast %5 : i64 to !tt.ptr<f32> {"reconvert-offset-to-ptr"}
      %8 = arith.extsi %c1_i32 : i32 to i64
      %9 = arith.addi %5, %8 : i64
      %10 = "tts.create_ptr"(%arg0, %9) : (!tt.ptr<f32>, i64) -> !tt.ptr<f32>
      %11 = builtin.unrealized_conversion_cast %9 : i64 to !tt.ptr<f32> {"reconvert-offset-to-ptr"}
      %12 = arith.extsi %arg2 : i32 to i64
      %13 = arith.addi %3, %12 : i64
      %14 = "tts.create_ptr"(%arg1, %13) : (!tt.ptr<f32>, i64) -> !tt.ptr<f32>
      %15 = builtin.unrealized_conversion_cast %13 : i64 to !tt.ptr<f32> {"reconvert-offset-to-ptr"}
      %16 = arith.extsi %c1_i32 : i32 to i64
      %17 = arith.addi %13, %16 : i64
      %18 = "tts.create_ptr"(%arg1, %17) : (!tt.ptr<f32>, i64) -> !tt.ptr<f32>
      %19 = builtin.unrealized_conversion_cast %17 : i64 to !tt.ptr<f32> {"reconvert-offset-to-ptr"}
      %20 = tt.load %6 : !tt.ptr<f32>
      %21 = tt.load %10 : !tt.ptr<f32>
      tt.store %14, %20 : !tt.ptr<f32>
      tt.store %18, %21 : !tt.ptr<f32>
    }
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:27:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: %c2 = arith.constant 2 : index
              ^
<stdin>:2:137: note: scanning from here
 func.func @addptr(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
                                                                                                                                        ^
<stdin>:7:6: note: possible intended match here
 %c2_i32 = arith.constant 2 : i32
     ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @addptr(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) { 
dag:27'0                                                                                                                                             X error: no match found
          3:  %c2_i64 = arith.constant 2 : i64 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c1_i64 = arith.constant 1 : i64 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %c0_i32 = arith.constant 0 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %c10_i32 = arith.constant 10 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %c2_i32 = arith.constant 2 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:27'1          ?                             possible intended match
          8:  scf.for %arg8 = %c0_i32 to %c10_i32 step %c2_i32 : i32 { 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          9:  %0 = arith.extsi %arg8 : i32 to i64 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         10:  %1 = arith.addi %0, %c1_i64 : i64 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         11:  %2 = arith.addi %0, %c2_i64 : i64 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  %3 = arith.index_cast %1 : i64 to index 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/ridiculously_nested_loops.mlir (16 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/ridiculously_nested_loops.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir:32:13: error: failed to legalize unresolved materialization from ('tensor<2x2x!tt.ptr<f32>>') to 'tensor<2x2xi64>' that remained live after conversion
    %24:2 = scf.for %arg4 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg5 = %11, %arg6 = %15) -> (tensor<2x2x!tt.ptr<f32>>, tensor<2x2x!tt.ptr<f32>>)  : i32 {
            ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir:32:13: note: see current operation: %7 = "builtin.unrealized_conversion_cast"(%6) : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xi64>
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir:32:13: note: see existing live user here: 
%6:3 = scf.for %arg4 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %3, %arg7 = %c0) -> (index, tensor<2x2xi64>, index)  : i32 {
  %7 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg5, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
  %8 = "tts.load"(%7) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %9:4 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5, %arg10 = %arg6, %arg11 = %arg7, %arg12 = %8) -> (index, tensor<2x2xi64>, index, tensor<2x2xf32>)  : i32 {
    %12 = arith.addi %arg9, %5 : index
    %13 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%12, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %14 = "tts.load"(%13) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    %15:5 = scf.for %arg13 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg14 = %12, %arg15 = %arg10, %arg16 = %arg11, %arg17 = %arg12, %arg18 = %14) -> (index, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
      %17 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg16, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %18 = arith.addi %arg14, %5 : index
      %19 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%18, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %20 = builtin.unrealized_conversion_cast %19 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
      %21 = "tts.load"(%19) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%17, %arg17) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %22 = arith.addi %arg16, %5 : index
      %23 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%23, %arg18) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %24 = arith.addi %22, %5 : index
      %25 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%24, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%25, %21) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %26 = arith.addi %24, %5 : index
      %27 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%26, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %28 = builtin.unrealized_conversion_cast %27 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
      %29:7 = scf.for %arg19 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg20 = %arg17, %arg21 = %20, %arg22 = %18, %arg23 = %arg18, %arg24 = %21, %arg25 = %28, %arg26 = %26) -> (tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
        %31 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %32 = "tts.load"(%31) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %33:7 = scf.for %arg27 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26, %arg34 = %32) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>)  : i32 {
          %34 = arith.addi %arg29, %5 : index
          %35 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%34, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %36 = builtin.unrealized_conversion_cast %35 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
          %37 = "tts.load"(%35) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          %38:7 = scf.for %arg35 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg36 = %36, %arg37 = %34, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %arg33, %arg41 = %arg34, %arg42 = %37) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
            %39 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %40 = arith.addi %arg37, %5 : index
            %41 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %42 = builtin.unrealized_conversion_cast %41 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
            %43 = "tts.load"(%41) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            "tts.store"(%39, %arg41) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %44 = arith.addi %arg40, %5 : index
            %45 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%44, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%45, %arg42) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %46 = arith.addi %44, %5 : index
            %47 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%47, %43) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %48 = arith.addi %46, %5 : index
            %49 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%48, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %50 = builtin.unrealized_conversion_cast %49 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
            %51:7 = scf.for %arg43 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg44 = %arg41, %arg45 = %42, %arg46 = %40, %arg47 = %arg42, %arg48 = %43, %arg49 = %50, %arg50 = %48) -> (tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
              %52 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %53 = "tts.load"(%52) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %54:7 = scf.for %arg51 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg52 = %arg45, %arg53 = %arg46, %arg54 = %arg47, %arg55 = %arg48, %arg56 = %arg49, %arg57 = %arg50, %arg58 = %53) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>)  : i32 {
                %55 = arith.addi %arg53, %5 : index
                %56 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%55, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %57 = builtin.unrealized_conversion_cast %56 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                %58 = "tts.load"(%56) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                %59:7 = scf.for %arg59 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg60 = %57, %arg61 = %55, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %arg57, %arg65 = %arg58, %arg66 = %58) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
                  %60 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg64, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %61 = arith.addi %arg61, %5 : index
                  %62 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %63 = builtin.unrealized_conversion_cast %62 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                  %64 = "tts.load"(%62) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  "tts.store"(%60, %arg65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %65 = arith.addi %arg64, %5 : index
                  %66 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%65, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%66, %arg66) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %67 = arith.addi %65, %5 : index
                  %68 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%68, %64) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %69 = arith.addi %67, %5 : index
                  %70 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%69, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %71 = builtin.unrealized_conversion_cast %70 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                  %72:7 = scf.for %arg67 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg68 = %arg65, %arg69 = %63, %arg70 = %61, %arg71 = %arg66, %arg72 = %64, %arg73 = %71, %arg74 = %69) -> (tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
                    %73 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg70, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                    %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                    %75:6 = scf.for %arg75 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg76 = %arg69, %arg77 = %arg70, %arg78 = %arg71, %arg79 = %arg72, %arg80 = %arg73, %arg81 = %arg74) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
                      %76 = arith.addi %arg77, %5 : index
                      %77 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%76, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      %78 = builtin.unrealized_conversion_cast %77 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                      %79 = "tts.load"(%77) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                      %80:5 = scf.for %arg82 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg83 = %78, %arg84 = %76, %arg85 = %arg79, %arg86 = %arg80, %arg87 = %arg81) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
                        %81 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg87, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                        %82 = arith.addi %arg84, %5 : index
                        %83 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%82, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                        %84 = builtin.unrealized_conversion_cast %83 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                        %85 = "tts.load"(%83) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                        "tts.store"(%81, %74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                        %86 = arith.addi %arg87, %5 : index
                        %87 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%86, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                        "tts.store"(%87, %79) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                        %88 = arith.addi %86, %5 : index
                        %89 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%88, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                        "tts.store"(%89, %85) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                        %90 = arith.addi %88, %5 : index
                        %91 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%90, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                        %92 = builtin.unrealized_conversion_cast %91 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                        scf.yield %84, %82, %85, %92, %90 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index
                      }
                      scf.yield %80#0, %80#1, %79, %80#2, %80#3, %80#4 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index
                    }
                    scf.yield %74, %75#0, %75#1, %75#2, %75#3, %75#4, %75#5 : tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index
                  }
                  scf.yield %72#1, %72#2, %72#4, %72#5, %72#6, %72#0, %72#3 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>
                }
                scf.yield %59#0, %59#1, %59#6, %59#2, %59#3, %59#4, %59#5 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>
              }
              scf.yield %54#6, %54#0, %54#1, %54#2, %54#3, %54#4, %54#5 : tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index
            }
            scf.yield %51#1, %51#2, %51#4, %51#5, %51#6, %51#0, %51#3 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>
          }
          scf.yield %38#0, %38#1, %38#6, %38#2, %38#3, %38#4, %38#5 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>
        }
        scf.yield %33#6, %33#0, %33#1, %33#2, %33#3, %33#4, %33#5 : tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index
      }
      %30:7 = scf.for %arg19 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg20 = %29#0, %arg21 = %29#1, %arg22 = %29#2, %arg23 = %29#3, %arg24 = %29#4, %arg25 = %29#5, %arg26 = %29#6) -> (tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
        %31 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %32 = "tts.load"(%31) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %33:6 = scf.for %arg27 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
          %34 = arith.addi %arg29, %5 : index
          %35 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%34, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %36 = builtin.unrealized_conversion_cast %35 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
          %37 = "tts.load"(%35) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          %38:5 = scf.for %arg34 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg35 = %36, %arg36 = %34, %arg37 = %arg31, %arg38 = %arg32, %arg39 = %arg33) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
            %39 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %40 = arith.addi %arg36, %5 : index
            %41 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %42 = builtin.unrealized_conversion_cast %41 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
            %43 = "tts.load"(%41) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            "tts.store"(%39, %32) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %44 = arith.addi %arg39, %5 : index
            %45 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%44, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%45, %37) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %46 = arith.addi %44, %5 : index
            %47 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%47, %43) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %48 = arith.addi %46, %5 : index
            %49 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%48, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %50 = builtin.unrealized_conversion_cast %49 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
            scf.yield %42, %40, %43, %50, %48 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index
          }
          scf.yield %38#0, %38#1, %37, %38#2, %38#3, %38#4 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index
        }
        scf.yield %32, %33#0, %33#1, %33#2, %33#3, %33#4, %33#5 : tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index
      }
      scf.yield %30#2, %30#5, %30#6, %30#0, %30#3 : index, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>
    }
    %16 = arith.addi %15#0, %5 : index
    scf.yield %16, %15#1, %15#2, %15#3 : index, tensor<2x2xi64>, index, tensor<2x2xf32>
  }
  %10:3 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %9#0, %arg10 = %9#1, %arg11 = %9#2) -> (index, tensor<2x2xi64>, index)  : i32 {
    %12 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    %14:3 = scf.for %arg12 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg13 = %arg9, %arg14 = %arg10, %arg15 = %arg11) -> (index, tensor<2x2xi64>, index)  : i32 {
      %16 = arith.addi %arg13, %5 : index
      %17 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%16, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %18 = "tts.load"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %19:3 = scf.for %arg16 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg17 = %16, %arg18 = %arg14, %arg19 = %arg15) -> (index, tensor<2x2xi64>, index)  : i32 {
        %20 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg19, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %21 = arith.addi %arg17, %5 : index
        %22 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%21, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %23 = "tts.load"(%22) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%20, %13) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %24 = arith.addi %arg19, %5 : index
        %25 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%24, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        "tts.store"(%25, %18) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %26 = arith.addi %24, %5 : index
        %27 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%26, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        "tts.store"(%27, %23) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %28 = arith.addi %26, %5 : index
        %29 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%28, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %30 = builtin.unrealized_conversion_cast %29 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
        scf.yield %21, %30, %28 : index, tensor<2x2xi64>, index
      }
      scf.yield %19#0, %19#1, %19#2 : index, tensor<2x2xi64>, index
    }
    %15 = arith.addi %14#0, %5 : index
    scf.yield %15, %14#1, %14#2 : index, tensor<2x2xi64>, index
  }
  %11 = arith.addi %10#0, %5 : index
  scf.yield %11, %10#1, %10#2 : index, tensor<2x2xi64>, index
}
module {
  tt.func public @nested_who_knows_how_many_levels(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %3 = builtin.unrealized_conversion_cast %2 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
    %4 = arith.muli %arg3, %c2_i32 : i32
    %5 = arith.index_cast %4 : i32 to index
    %6:3 = scf.for %arg4 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %3, %arg7 = %c0) -> (index, tensor<2x2xi64>, index)  : i32 {
      %7 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg5, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %8 = "tts.load"(%7) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %9:4 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5, %arg10 = %arg6, %arg11 = %arg7, %arg12 = %8) -> (index, tensor<2x2xi64>, index, tensor<2x2xf32>)  : i32 {
        %12 = arith.addi %arg9, %5 : index
        %13 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%12, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %14 = "tts.load"(%13) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %15:5 = scf.for %arg13 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg14 = %12, %arg15 = %arg10, %arg16 = %arg11, %arg17 = %arg12, %arg18 = %14) -> (index, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
          %17 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg16, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %18 = arith.addi %arg14, %5 : index
          %19 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%18, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %20 = builtin.unrealized_conversion_cast %19 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
          %21 = "tts.load"(%19) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          "tts.store"(%17, %arg17) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %22 = arith.addi %arg16, %5 : index
          %23 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%23, %arg18) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %24 = arith.addi %22, %5 : index
          %25 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%24, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%25, %21) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %26 = arith.addi %24, %5 : index
          %27 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%26, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %28 = builtin.unrealized_conversion_cast %27 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
          %29:7 = scf.for %arg19 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg20 = %arg17, %arg21 = %20, %arg22 = %18, %arg23 = %arg18, %arg24 = %21, %arg25 = %28, %arg26 = %26) -> (tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
            %31 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %32 = "tts.load"(%31) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            %33:7 = scf.for %arg27 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26, %arg34 = %32) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>)  : i32 {
              %34 = arith.addi %arg29, %5 : index
              %35 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%34, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %36 = builtin.unrealized_conversion_cast %35 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
              %37 = "tts.load"(%35) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %38:7 = scf.for %arg35 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg36 = %36, %arg37 = %34, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %arg33, %arg41 = %arg34, %arg42 = %37) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
                %39 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %40 = arith.addi %arg37, %5 : index
                %41 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %42 = builtin.unrealized_conversion_cast %41 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                %43 = "tts.load"(%41) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                "tts.store"(%39, %arg41) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %44 = arith.addi %arg40, %5 : index
                %45 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%44, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%45, %arg42) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %46 = arith.addi %44, %5 : index
                %47 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%47, %43) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %48 = arith.addi %46, %5 : index
                %49 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%48, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %50 = builtin.unrealized_conversion_cast %49 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                %51:7 = scf.for %arg43 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg44 = %arg41, %arg45 = %42, %arg46 = %40, %arg47 = %arg42, %arg48 = %43, %arg49 = %50, %arg50 = %48) -> (tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
                  %52 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %53 = "tts.load"(%52) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  %54:7 = scf.for %arg51 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg52 = %arg45, %arg53 = %arg46, %arg54 = %arg47, %arg55 = %arg48, %arg56 = %arg49, %arg57 = %arg50, %arg58 = %53) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>)  : i32 {
                    %55 = arith.addi %arg53, %5 : index
                    %56 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%55, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                    %57 = builtin.unrealized_conversion_cast %56 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                    %58 = "tts.load"(%56) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                    %59:7 = scf.for %arg59 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg60 = %57, %arg61 = %55, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %arg57, %arg65 = %arg58, %arg66 = %58) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
                      %60 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg64, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      %61 = arith.addi %arg61, %5 : index
                      %62 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      %63 = builtin.unrealized_conversion_cast %62 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                      %64 = "tts.load"(%62) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                      "tts.store"(%60, %arg65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %65 = arith.addi %arg64, %5 : index
                      %66 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%65, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      "tts.store"(%66, %arg66) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %67 = arith.addi %65, %5 : index
                      %68 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      "tts.store"(%68, %64) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %69 = arith.addi %67, %5 : index
                      %70 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%69, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      %71 = builtin.unrealized_conversion_cast %70 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                      %72:7 = scf.for %arg67 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg68 = %arg65, %arg69 = %63, %arg70 = %61, %arg71 = %arg66, %arg72 = %64, %arg73 = %71, %arg74 = %69) -> (tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
                        %73 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg70, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                        %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                        %75:6 = scf.for %arg75 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg76 = %arg69, %arg77 = %arg70, %arg78 = %arg71, %arg79 = %arg72, %arg80 = %arg73, %arg81 = %arg74) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
                          %76 = arith.addi %arg77, %5 : index
                          %77 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%76, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                          %78 = builtin.unrealized_conversion_cast %77 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                          %79 = "tts.load"(%77) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                          %80:5 = scf.for %arg82 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg83 = %78, %arg84 = %76, %arg85 = %arg79, %arg86 = %arg80, %arg87 = %arg81) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
                            %81 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg87, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                            %82 = arith.addi %arg84, %5 : index
                            %83 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%82, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                            %84 = builtin.unrealized_conversion_cast %83 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                            %85 = "tts.load"(%83) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                            "tts.store"(%81, %74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                            %86 = arith.addi %arg87, %5 : index
                            %87 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%86, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                            "tts.store"(%87, %79) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                            %88 = arith.addi %86, %5 : index
                            %89 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%88, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                            "tts.store"(%89, %85) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                            %90 = arith.addi %88, %5 : index
                            %91 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%90, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                            %92 = builtin.unrealized_conversion_cast %91 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                            scf.yield %84, %82, %85, %92, %90 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index
                          }
                          scf.yield %80#0, %80#1, %79, %80#2, %80#3, %80#4 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index
                        }
                        scf.yield %74, %75#0, %75#1, %75#2, %75#3, %75#4, %75#5 : tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index
                      }
                      scf.yield %72#1, %72#2, %72#4, %72#5, %72#6, %72#0, %72#3 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>
                    }
                    scf.yield %59#0, %59#1, %59#6, %59#2, %59#3, %59#4, %59#5 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>
                  }
                  scf.yield %54#6, %54#0, %54#1, %54#2, %54#3, %54#4, %54#5 : tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index
                }
                scf.yield %51#1, %51#2, %51#4, %51#5, %51#6, %51#0, %51#3 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>
              }
              scf.yield %38#0, %38#1, %38#6, %38#2, %38#3, %38#4, %38#5 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>
            }
            scf.yield %33#6, %33#0, %33#1, %33#2, %33#3, %33#4, %33#5 : tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index
          }
          %30:7 = scf.for %arg19 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg20 = %29#0, %arg21 = %29#1, %arg22 = %29#2, %arg23 = %29#3, %arg24 = %29#4, %arg25 = %29#5, %arg26 = %29#6) -> (tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
            %31 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %32 = "tts.load"(%31) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            %33:6 = scf.for %arg27 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
              %34 = arith.addi %arg29, %5 : index
              %35 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%34, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %36 = builtin.unrealized_conversion_cast %35 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
              %37 = "tts.load"(%35) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %38:5 = scf.for %arg34 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg35 = %36, %arg36 = %34, %arg37 = %arg31, %arg38 = %arg32, %arg39 = %arg33) -> (tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index)  : i32 {
                %39 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %40 = arith.addi %arg36, %5 : index
                %41 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %42 = builtin.unrealized_conversion_cast %41 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                %43 = "tts.load"(%41) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                "tts.store"(%39, %32) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %44 = arith.addi %arg39, %5 : index
                %45 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%44, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%45, %37) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %46 = arith.addi %44, %5 : index
                %47 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%47, %43) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %48 = arith.addi %46, %5 : index
                %49 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%48, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %50 = builtin.unrealized_conversion_cast %49 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
                scf.yield %42, %40, %43, %50, %48 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xi64>, index
              }
              scf.yield %38#0, %38#1, %37, %38#2, %38#3, %38#4 : tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index
            }
            scf.yield %32, %33#0, %33#1, %33#2, %33#3, %33#4, %33#5 : tensor<2x2xf32>, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2xi64>, index
          }
          scf.yield %30#2, %30#5, %30#6, %30#0, %30#3 : index, tensor<2x2xi64>, index, tensor<2x2xf32>, tensor<2x2xf32>
        }
        %16 = arith.addi %15#0, %5 : index
        scf.yield %16, %15#1, %15#2, %15#3 : index, tensor<2x2xi64>, index, tensor<2x2xf32>
      }
      %10:3 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %9#0, %arg10 = %9#1, %arg11 = %9#2) -> (index, tensor<2x2xi64>, index)  : i32 {
        %12 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %14:3 = scf.for %arg12 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg13 = %arg9, %arg14 = %arg10, %arg15 = %arg11) -> (index, tensor<2x2xi64>, index)  : i32 {
          %16 = arith.addi %arg13, %5 : index
          %17 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%16, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %18 = "tts.load"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          %19:3 = scf.for %arg16 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg17 = %16, %arg18 = %arg14, %arg19 = %arg15) -> (index, tensor<2x2xi64>, index)  : i32 {
            %20 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg19, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %21 = arith.addi %arg17, %5 : index
            %22 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%21, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %23 = "tts.load"(%22) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            "tts.store"(%20, %13) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %24 = arith.addi %arg19, %5 : index
            %25 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%24, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%25, %18) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %26 = arith.addi %24, %5 : index
            %27 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%26, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%27, %23) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %28 = arith.addi %26, %5 : index
            %29 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%28, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %30 = builtin.unrealized_conversion_cast %29 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
            scf.yield %21, %30, %28 : index, tensor<2x2xi64>, index
          }
          scf.yield %19#0, %19#1, %19#2 : index, tensor<2x2xi64>, index
        }
        %15 = arith.addi %14#0, %5 : index
        scf.yield %15, %14#1, %14#2 : index, tensor<2x2xi64>, index
      }
      %11 = arith.addi %10#0, %5 : index
      scf.yield %11, %10#1, %10#2 : index, tensor<2x2xi64>, index
    }
    tt.return
  }
}
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_reduce.mlir (17 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_reduce.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
module {
  tt.func public @minmax_sgt(%arg0: !tt.ptr<i32>) {
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %1 = arith.cmpi sgt, %arg1, %arg2 : i32
      %2 = arith.select %1, %arg1, %arg2 : i32
      tt.reduce.return %2 : i32
    }) : (tensor<4096xi32>) -> i32
    tt.store %arg0, %0 : !tt.ptr<i32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
module {
  tt.func public @minmax_ugt(%arg0: !tt.ptr<i32>) {
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %1 = arith.cmpi ugt, %arg1, %arg2 : i32
      %2 = arith.select %1, %arg1, %arg2 : i32
      tt.reduce.return %2 : i32
    }) : (tensor<4096xi32>) -> i32
    tt.store %arg0, %0 : !tt.ptr<i32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
module {
  tt.func public @minmax_slt(%arg0: !tt.ptr<i32>) {
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %1 = arith.cmpi slt, %arg1, %arg2 : i32
      %2 = arith.select %1, %arg1, %arg2 : i32
      tt.reduce.return %2 : i32
    }) : (tensor<4096xi32>) -> i32
    tt.store %arg0, %0 : !tt.ptr<i32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
module {
  tt.func public @minmax_ult(%arg0: !tt.ptr<i32>) {
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %1 = arith.cmpi ult, %arg1, %arg2 : i32
      %2 = arith.select %1, %arg1, %arg2 : i32
      tt.reduce.return %2 : i32
    }) : (tensor<4096xi32>) -> i32
    tt.store %arg0, %0 : !tt.ptr<i32>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:20:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:2:119: note: scanning from here
 func.func @minmax_sgt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:2:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_sgt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:16:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:57:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:24:119: note: scanning from here
 func.func @minmax_ugt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:24:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ugt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:37:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:94:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:45:119: note: scanning from here
 func.func @minmax_slt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:45:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_slt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:59:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:132:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:67:119: note: scanning from here
 func.func @minmax_ult(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:67:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ult(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:81:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
           1: module { 
           2:  func.func @minmax_sgt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:20'0                                                                                                                            X error: no match found
dag:20'1                                                                                                                              with "PARAM_0_" equal to "%arg0"
           3:  %c0 = arith.constant 0 : index 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           4:  %c-2147483648_i32 = arith.constant -2147483648 : i32 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           5:  %c0_i32 = arith.constant 0 : i32 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           6:  %0 = tensor.empty() : tensor<4096xi32> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           7:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          11:  (%in: i32, %init: i32) { 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~
          12:  %3 = arith.maxsi %in, %init : i32 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          13:  linalg.yield %3 : i32 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~
          14:  } 
dag:20'0      ~~~
          15:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          16:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:20'2                   ?                                                                                                                                           possible intended match
          17:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          18:  return 
dag:20'0      ~~~~~~~~
          19:  } 
dag:20'0      ~~~
          20: } 
dag:20'0      ~~
          21:  
dag:20'0      ~
          22: // ----- 
dag:20'0      ~~~~~~~~~
          23: module { 
dag:20'0      ~~~~~~~~~
          24:  func.func @minmax_ugt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~
dag:57'0                                                                                                                            X error: no match found
dag:57'1                                                                                                                              with "PARAM_0_" equal to "%arg0"
          25:  %c0 = arith.constant 0 : index 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          26:  %c0_i32 = arith.constant 0 : i32 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          27:  %0 = tensor.empty() : tensor<4096xi32> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          28:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          29:  %2 = bufferization.alloc_tensor() : tensor<i32> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          32:  (%in: i32, %init: i32) { 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~
          33:  %3 = arith.maxui %in, %init : i32 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          34:  linalg.yield %3 : i32 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~
          35:  } 
dag:57'0      ~~~
          36:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          37:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:57'2                   ?                                                                                                                                           possible intended match
          38:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          39:  return 
dag:57'0      ~~~~~~~~
          40:  } 
dag:57'0      ~~~
          41: } 
dag:57'0      ~~
          42:  
dag:57'0      ~
          43: // ----- 
dag:57'0      ~~~~~~~~~
          44: module { 
dag:57'0      ~~~~~~~~~
          45:  func.func @minmax_slt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~
dag:94'0                                                                                                                            X error: no match found
dag:94'1                                                                                                                              with "PARAM_0_" equal to "%arg0"
          46:  %c0 = arith.constant 0 : index 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          47:  %c2147483647_i32 = arith.constant 2147483647 : i32 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          48:  %c0_i32 = arith.constant 0 : i32 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          49:  %0 = tensor.empty() : tensor<4096xi32> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          50:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          54:  (%in: i32, %init: i32) { 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~
          55:  %3 = arith.minsi %in, %init : i32 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          56:  linalg.yield %3 : i32 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~
          57:  } 
dag:94'0      ~~~
          58:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          59:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:94'2                   ?                                                                                                                                           possible intended match
          60:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          61:  return 
dag:94'0      ~~~~~~~~
          62:  } 
dag:94'0      ~~~
          63: } 
dag:94'0      ~~
          64:  
dag:94'0      ~
          65: // ----- 
dag:94'0      ~~~~~~~~~
          66: module { 
dag:94'0      ~~~~~~~~~
          67:  func.func @minmax_ult(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~
dag:132'0                                                                                                                           X error: no match found
dag:132'1                                                                                                                             with "PARAM_0_" equal to "%arg0"
          68:  %c0 = arith.constant 0 : index 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          69:  %c-1_i32 = arith.constant -1 : i32 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          70:  %c0_i32 = arith.constant 0 : i32 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          71:  %0 = tensor.empty() : tensor<4096xi32> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          72:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          76:  (%in: i32, %init: i32) { 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
          77:  %3 = arith.minui %in, %init : i32 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          78:  linalg.yield %3 : i32 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~
          79:  } 
dag:132'0     ~~~
          80:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          81:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:132'2                  ?                                                                                                                                           possible intended match
          82:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          83:  return 
dag:132'0     ~~~~~~~~
          84:  } 
dag:132'0     ~~~
          85: } 
dag:132'0     ~~
          86:  
dag:132'0     ~
>>>>>>

--

********************
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/tensor_indices_loop_iterargs_nested.mlir (18 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_dim1.mlir (19 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_loopback.mlir (20 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_mul_const_const.mlir (21 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_argmin_argmax.mlir (22 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_advance.mlir (23 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_nested_loop.mlir (24 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_nested_loop.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir:26:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[CST_1_:%.+]] = arith.constant 1 : index
              ^
<stdin>:2:232: note: scanning from here
 func.func @reduce_kernel_2d_0d(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
                                                                                                                                                                                                                                       ^
<stdin>:7:4: note: possible intended match here
 %c1_i32 = arith.constant 1 : i32
   ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @reduce_kernel_2d_0d(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) { 
dag:26'0                                                                                                                                                                                                                                            X error: no match found
          3:  %0 = builtin.unrealized_conversion_cast %arg0 : memref<*xf32> to !tt.ptr<f32> 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c2_i32 = arith.constant 2 : i32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %c8_i32 = arith.constant 8 : i32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %c0_i32 = arith.constant 0 : i32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %c1_i32 = arith.constant 1 : i32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:26'1        ?                               possible intended match
          8:  %1 = tt.addptr %0, %arg4 : !tt.ptr<f32>, i32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          9:  %2 = scf.for %arg13 = %c0_i32 to %c8_i32 step %c1_i32 iter_args(%arg14 = %1) -> (!tt.ptr<f32>) : i32 { 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         10:  %3 = scf.for %arg15 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg16 = %arg14) -> (!tt.ptr<f32>) : i32 { 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         11:  %4 = arith.muli %arg13, %arg15 : i32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  %5 = arith.sitofp %4 : i32 to f32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_side_by_side.mlir (25 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_side_by_side.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir
module {
  tt.func public @wrap_side_by_side_masked_loop_01234567(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
    %cst = arith.constant -9.900000e+01 : f32
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c2 = arith.constant 2 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %c4_i32 = arith.constant 4 : i32
    %0 = arith.index_cast %arg4 : i32 to index
    %1 = arith.muli %0, %c2 : index
    %2 = arith.index_cast %arg3 : i32 to index
    %3 = arith.index_cast %arg5 : i32 to index
    %4 = arith.muli %3, %c6 : index
    %5 = arith.muli %2, %3 : index
    %6 = arith.index_cast %arg6 : i32 to index
    %7 = arith.index_cast %arg7 : i32 to index
    %8 = arith.muli %arg4, %c4_i32 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.muli %arg5, %c4_i32 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12:2 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %1, %arg10 = %c0) -> (index, index)  : i32 {
      %13 = tts.make_tptr %arg1 to sizes: [4, 4], strides: [%6, %7], offsets: [%arg10, %c0], shape: [0, 0], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %14 = tts.make_tptr %arg0 to sizes: [4, 4], strides: [%0, %3], offsets: [%arg9, %4], shape: [0, %5], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %15 = "tts.load"(%14, %cst) <{operandSegmentSizes = array<i32: 1, 0, 1>, static_mask_dims = array<i64: 2, 4>}> : (tensor<4x4x!tt.ptr<f32>>, f32) -> tensor<4x4xf32>
      "tts.store"(%13, %15) <{static_mask_dims = array<i64>}> : (tensor<4x4x!tt.ptr<f32>>, tensor<4x4xf32>) -> ()
      %16 = arith.addi %arg9, %9 : index
      %17 = arith.addi %arg10, %11 : index
      scf.yield %16, %17 : index, index
    }
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir:1 offset :46:13: error: failed to legalize operation 'tts.make_tptr' that was explicitly marked illegal
    %33:2 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %15, %arg10 = %26) -> (tensor<4x4x!tt.ptr<f32>>, tensor<4x4x!tt.ptr<f32>>)  : i32 {
            ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir:1 offset :46:13: note: see current operation: %26 = "tts.make_tptr"(%1, %10, %13, %arg15, %14, %15) <{operandSegmentSizes = array<i32: 1, 2, 2, 1>, order = array<i32>, sizes = array<i64: 4, 4>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, -9223372036854775808>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index, index) -> tensor<4x4x!tt.ptr<f32>>
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/nested_loops.mlir (26 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/nested_loops.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir:1 offset :109:13: error: failed to legalize unresolved materialization from ('tensor<2x2x!tt.ptr<f32>>') to 'tensor<2x2xi64>' that remained live after conversion
    %20:2 = scf.for %arg4 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg5 = %11, %arg6 = %15) -> (tensor<2x2x!tt.ptr<f32>>, tensor<2x2x!tt.ptr<f32>>)  : i32 {
            ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir:1 offset :109:13: note: see current operation: %7 = "builtin.unrealized_conversion_cast"(%6) : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xi64>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir:1 offset :109:13: note: see existing live user here: 
%6:3 = scf.for %arg4 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %3, %arg7 = %c0) -> (index, tensor<2x2xi64>, index)  : i32 {
  %7 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg5, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
  %8 = "tts.load"(%7) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %9:3 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5, %arg10 = %arg6, %arg11 = %arg7) -> (index, tensor<2x2xi64>, index)  : i32 {
    %11 = arith.addi %arg9, %5 : index
    %12 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%11, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    %14:3 = scf.for %arg12 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg13 = %11, %arg14 = %arg10, %arg15 = %arg11) -> (index, tensor<2x2xi64>, index)  : i32 {
      %15 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg15, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %16 = arith.addi %arg13, %5 : index
      %17 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%16, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %18 = "tts.load"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%15, %8) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %19 = arith.addi %arg15, %5 : index
      %20 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%19, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%20, %13) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %21 = arith.addi %19, %5 : index
      %22 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%21, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%22, %18) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %23 = arith.addi %21, %5 : index
      %24 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%23, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %25 = builtin.unrealized_conversion_cast %24 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
      scf.yield %16, %25, %23 : index, tensor<2x2xi64>, index
    }
    scf.yield %14#0, %14#1, %14#2 : index, tensor<2x2xi64>, index
  }
  %10 = arith.addi %9#0, %5 : index
  scf.yield %10, %9#1, %9#2 : index, tensor<2x2xi64>, index
}
module {
  tt.func public @nested2_complex_body(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c3 = arith.constant 3 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = arith.muli %arg2, %c2_i32 : i32
    %3 = arith.index_cast %2 : i32 to index
    %4:2 = scf.for %arg4 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %c0) -> (index, index)  : i32 {
      %5 = arith.addi %arg5, %c1 : index
      %6 = arith.addi %arg6, %c1 : index
      %7:2 = scf.for %arg7 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg8 = %5, %arg9 = %6) -> (index, index)  : i32 {
        %12 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %13 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg8, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %14 = "tts.load"(%13) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%12, %14) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %15 = arith.addi %arg8, %c3 : index
        %16 = arith.addi %arg9, %c3 : index
        scf.yield %15, %16 : index, index
      }
      %8 = arith.addi %arg5, %3 : index
      %9 = arith.addi %8, %c1 : index
      %10 = arith.addi %arg6, %3 : index
      %11 = arith.addi %10, %c1 : index
      scf.yield %9, %11 : index, index
    }
    tt.return
  }
  tt.func public @nested2_use_loop_results(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c2_i32 = arith.constant 2 : i32
    %c0_i32 = arith.constant 0 : i32
    %c4_i32 = arith.constant 4 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = arith.muli %arg3, %c4_i32 : i32
    %3 = arith.index_cast %2 : i32 to index
    %4:2 = scf.for %arg4 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %c0) -> (index, index)  : i32 {
      %5 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg6, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %6 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg5, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %7 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%5, %7) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %8 = arith.addi %arg5, %3 : index
      %9 = arith.addi %arg6, %3 : index
      %10:2 = scf.for %arg7 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg8 = %8, %arg9 = %9) -> (index, index)  : i32 {
        %11 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %12 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg8, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%11, %13) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %14 = arith.addi %arg8, %3 : index
        %15 = arith.addi %arg9, %3 : index
        scf.yield %14, %15 : index, index
      }
      scf.yield %10#0, %10#1 : index, index
    }
    tt.return
  }
  tt.func public @nested3(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %3 = builtin.unrealized_conversion_cast %2 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
    %4 = arith.muli %arg3, %c2_i32 : i32
    %5 = arith.index_cast %4 : i32 to index
    %6:3 = scf.for %arg4 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %3, %arg7 = %c0) -> (index, tensor<2x2xi64>, index)  : i32 {
      %7 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg5, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %8 = "tts.load"(%7) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %9:3 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5, %arg10 = %arg6, %arg11 = %arg7) -> (index, tensor<2x2xi64>, index)  : i32 {
        %11 = arith.addi %arg9, %5 : index
        %12 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%11, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %14:3 = scf.for %arg12 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg13 = %11, %arg14 = %arg10, %arg15 = %arg11) -> (index, tensor<2x2xi64>, index)  : i32 {
          %15 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg15, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %16 = arith.addi %arg13, %5 : index
          %17 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%16, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %18 = "tts.load"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          "tts.store"(%15, %8) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %19 = arith.addi %arg15, %5 : index
          %20 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%19, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%20, %13) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %21 = arith.addi %19, %5 : index
          %22 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%21, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%22, %18) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %23 = arith.addi %21, %5 : index
          %24 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%23, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %25 = builtin.unrealized_conversion_cast %24 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
          scf.yield %16, %25, %23 : index, tensor<2x2xi64>, index
        }
        scf.yield %14#0, %14#1, %14#2 : index, tensor<2x2xi64>, index
      }
      %10 = arith.addi %9#0, %5 : index
      scf.yield %10, %9#1, %9#2 : index, tensor<2x2xi64>, index
    }
    tt.return
  }
  tt.func public @nested_use_same_level_loop_result(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %3 = builtin.unrealized_conversion_cast %2 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
    %4 = arith.muli %arg3, %c2_i32 : i32
    %5 = arith.index_cast %4 : i32 to index
    %6:3 = scf.for %arg4 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %3, %arg7 = %c0) -> (index, tensor<2x2xi64>, index)  : i32 {
      %7 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5) -> (index)  : i32 {
        %10 = arith.addi %arg9, %5 : index
        scf.yield %10 : index
      }
      %8:3 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %7, %arg10 = %arg6, %arg11 = %arg7) -> (index, tensor<2x2xi64>, index)  : i32 {
        %10 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg11, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %11 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %12 = "tts.load"(%11) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %13 = arith.addi %arg9, %5 : index
        %14 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%13, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %15 = "tts.load"(%14) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%10, %12) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %16 = arith.addi %arg11, %5 : index
        %17 = arith.addi %16, %5 : index
        %18 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%17, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        "tts.store"(%18, %15) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %19 = arith.addi %17, %5 : index
        %20 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%19, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %21 = builtin.unrealized_conversion_cast %20 : tensor<2x2x!tt.ptr<f32>> to tensor<2x2xi64>
        %22 = arith.addi %13, %5 : index
        scf.yield %22, %21, %19 : index, tensor<2x2xi64>, index
      }
      %9 = arith.addi %8#0, %5 : index
      scf.yield %9, %8#1, %8#2 : index, tensor<2x2xi64>, index
    }
    tt.return
  }
}
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_accumulation.mlir (27 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop.mlir (28 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir:20:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[CST_0_:%.+]] = arith.constant 0 : index
              ^
<stdin>:2:232: note: scanning from here
 func.func @reduce_kernel_2d_0d(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
                                                                                                                                                                                                                                       ^
<stdin>:5:4: note: possible intended match here
 %c0_i32 = arith.constant 0 : i32
   ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @reduce_kernel_2d_0d(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) { 
dag:20'0                                                                                                                                                                                                                                            X error: no match found
          3:  %0 = builtin.unrealized_conversion_cast %arg0 : memref<*xf32> to !tt.ptr<f32> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c8_i32 = arith.constant 8 : i32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %c0_i32 = arith.constant 0 : i32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:20'1        ?                               possible intended match
          6:  %c1_i32 = arith.constant 1 : i32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %1 = scf.for %arg13 = %c0_i32 to %c8_i32 step %c1_i32 iter_args(%arg14 = %0) -> (!tt.ptr<f32>) : i32 { 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          8:  %2 = arith.sitofp %arg13 : i32 to f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          9:  tt.store %arg14, %2 : !tt.ptr<f32> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         10:  %3 = tt.addptr %arg14, %c1_i32 : !tt.ptr<f32>, i32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_f32_axis0.mlir (29 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_used_after_update.mlir (30 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir (31 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
      tt.store %arg11, %2 : !tt.ptr<f32>
      ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: note: see current operation: tt.store %arg11, %3 : !tt.ptr<f32>
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: remark: PtrAnalysis: Failed to rewrite StoreOp
      tt.store %arg11, %2 : !tt.ptr<f32>
      ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: note: see current operation: tt.store %arg11, %3 : !tt.ptr<f32>
%6 = unrealized_conversion_cast %arg11 : i64 to !tt.ptr<f32> {"reconvert-offset-to-ptr"}
module {
  tt.func @reduce_kernel_2d_0d1d2de3de(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) {
    %c0_i64 = arith.constant 0 : i64
    %c1_i32 = arith.constant 1 : i32
    %c5_i32 = arith.constant 5 : i32
    %c0_i32 = arith.constant 0 : i32
    %0 = arith.index_cast %arg7 : i32 to index
    %1 = arith.extsi %arg7 : i32 to i64
    %2 = arith.addi %c0_i64, %1 : i64
    %3 = arith.sitofp %arg7 : i32 to f32
    %4:3 = scf.for %arg10 = %c0_i32 to %c5_i32 step %c1_i32 iter_args(%arg11 = %2, %arg12 = %0, %arg13 = %0) -> (i64, index, index)  : i32 {
      %5 = "tts.create_ptr"(%arg1, %arg11) : (!tt.ptr<f32>, i64) -> !tt.ptr<f32>
      %6 = builtin.unrealized_conversion_cast %arg11 : i64 to !tt.ptr<f32> {"reconvert-offset-to-ptr"}
      tt.store %5, %3 : !tt.ptr<f32>
      %7 = arith.index_cast %arg10 : i32 to index
      %8 = arith.addi %arg12, %7 : index
      %9 = arith.extsi %arg10 : i32 to i64
      %10 = arith.addi %arg11, %9 : i64
      %11 = arith.addi %arg13, %7 : index
      scf.yield %10, %8, %11 : i64, index, index
    }
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:27:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_0_:%.+]] = arith.index_cast [[PARAM_7_]] : i32 to index
              ^
<stdin>:2:440: note: scanning from here
 func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) {
                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
<stdin>:2:440: note: with "PARAM_7_" equal to "%arg13"
 func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) {
                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
<stdin>:6:2: note: possible intended match here
 %0 = arith.index_cast %arg7 : i32 to index
 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) { 
dag:27'0                                                                                                                                                                                                                                                                                                                                                                                                                                                            X error: no match found
dag:27'1                                                                                                                                                                                                                                                                                                                                                                                                                                                              with "PARAM_7_" equal to "%arg13"
          3:  %c1_i32 = arith.constant 1 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c5_i32 = arith.constant 5 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %c0_i32 = arith.constant 0 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %0 = arith.index_cast %arg7 : i32 to index 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:27'2      ?                                           possible intended match
          7:  %1 = arith.extsi %arg7 : i32 to i64 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          8:  %2 = arith.sitofp %arg7 : i32 to f32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          9:  %3:3 = scf.for %arg16 = %c0_i32 to %c5_i32 step %c1_i32 iter_args(%arg17 = %1, %arg18 = %0, %arg19 = %0) -> (i64, index, index) : i32 { 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         10:  %4 = arith.index_cast %arg17 : i64 to index 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         11:  %reinterpret_cast = memref.reinterpret_cast %arg1 to offset: [%4], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_nested.mlir (32 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_bf16_axis1.mlir (33 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir (34 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir:23:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_0_:%.+]] = arith.index_cast [[PARAM_7_]] : i32 to index
              ^
<stdin>:2:440: note: scanning from here
 func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) {
                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
<stdin>:2:440: note: with "PARAM_7_" equal to "%arg13"
 func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) {
                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
<stdin>:8:2: note: possible intended match here
 %2 = arith.sitofp %arg7 : i32 to f32
 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) { 
dag:23'0                                                                                                                                                                                                                                                                                                                                                                                                                                                            X error: no match found
dag:23'1                                                                                                                                                                                                                                                                                                                                                                                                                                                              with "PARAM_7_" equal to "%arg13"
          3:  %0 = builtin.unrealized_conversion_cast %arg1 : memref<*xf32> to !tt.ptr<f32> 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c1_i32 = arith.constant 1 : i32 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %c5_i32 = arith.constant 5 : i32 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %c0_i32 = arith.constant 0 : i32 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %1 = tt.addptr %0, %arg7 : !tt.ptr<f32>, i32 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          8:  %2 = arith.sitofp %arg7 : i32 to f32 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:23'2      ?                                     possible intended match
          9:  scf.for %arg16 = %c0_i32 to %c5_i32 step %c1_i32 : i32 { 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         10:  %3 = tt.addptr %1, %arg16 : !tt.ptr<f32>, i32 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         11:  tt.store %3, %2 : !tt.ptr<f32> 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  } 
dag:23'0     ~~~
         13:  return 
dag:23'0     ~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_extern_elementwise.mlir (35 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_mul_value_const.mlir (36 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/unsupported_extern_elementwise.mlir (37 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_broadcast.mlir (38 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/use_dot_opc.mlir (39 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/cumsum.mlir (40 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_loopback.mlir (41 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_loopback.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: remark: PtrAnalysis: scalar loadOp will not be rewritten
    %10 = tt.load %0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false}: !tt.ptr<bf16>
          ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: note: see current operation: %4 = tt.load %1 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: remark: PtrAnalysis: Failed to rewrite LoadOp
    %10 = tt.load %0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false}: !tt.ptr<bf16>
          ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: note: see current operation: %4 = tt.load %1 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: remark: PtrAnalysis: scalar storeOp will not be rewritten
    tt.store %1, %10 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: note: see current operation: tt.store %3, %4 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %1, %10 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: note: see current operation: tt.store %3, %4 : !tt.ptr<bf16>
%7 = unrealized_conversion_cast %6 : i64 to !tt.ptr<bf16> {"reconvert-offset-to-ptr"}
%4 = unrealized_conversion_cast %3 : i64 to !tt.ptr<bf16> {"reconvert-offset-to-ptr"}
module {
  tt.func @kernel(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: i32) {
    %c0_i64 = arith.constant 0 : i64
    %c0_i64_0 = arith.constant 0 : i64
    %0 = arith.extsi %arg2 : i32 to i64
    %1 = arith.addi %c0_i64_0, %0 : i64
    %2 = "tts.create_ptr"(%arg0, %1) : (!tt.ptr<bf16>, i64) -> !tt.ptr<bf16>
    %3 = builtin.unrealized_conversion_cast %1 : i64 to !tt.ptr<bf16> {"reconvert-offset-to-ptr"}
    %4 = arith.extsi %arg2 : i32 to i64
    %5 = arith.addi %c0_i64, %4 : i64
    %6 = "tts.create_ptr"(%arg1, %5) : (!tt.ptr<bf16>, i64) -> !tt.ptr<bf16>
    %7 = builtin.unrealized_conversion_cast %5 : i64 to !tt.ptr<bf16> {"reconvert-offset-to-ptr"}
    %8 = tt.load %2 : !tt.ptr<bf16>
    tt.store %6, %8 : !tt.ptr<bf16>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:22:11: error: CHECK: expected string not found in input
// CHECK: [[LOAD_VAR_reinterpret_cast_MEM_:%.+]] = affine.load [[VAR_reinterpret_cast_]][0] : memref<1xbf16, strided<[1], offset: ?>>
          ^
<stdin>:6:155: note: scanning from here
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
                                                                                                                                                          ^
<stdin>:6:155: note: with "VAR_reinterpret_cast_" equal to "%reinterpret_cast"
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
                                                                                                                                                          ^
<stdin>:7:19: note: possible intended match here
 affine.store %1, %reinterpret_cast_0[0] : memref<1xbf16, strided<[1], offset: ?>>
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            1: module { 
            2:  func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
            3:  %0 = arith.index_cast %arg2 : i32 to index 
            4:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>> 
            5:  %1 = affine.load %reinterpret_cast[0] : memref<1xbf16, strided<[1], offset: ?>> 
            6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>> 
check:22'0                                                                                                                                                               X error: no match found
check:22'1                                                                                                                                                                 with "VAR_reinterpret_cast_" equal to "%reinterpret_cast"
            7:  affine.store %1, %reinterpret_cast_0[0] : memref<1xbf16, strided<[1], offset: ?>> 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:22'2                       ?                                                                 possible intended match
            8:  return 
check:22'0     ~~~~~~~~
            9:  } 
check:22'0     ~~~
           10: } 
check:22'0     ~~
           11:  
check:22'0     ~
>>>>>>

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/bitcast.mlir (42 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_reshape_broadcast.mlir (43 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/early_return.mlir (44 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_tensor_reshape.mlir (45 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_more_init_args.mlir (46 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/dot.mlir (47 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_2d_example.mlir (48 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_nested.mlir (49 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/get_num_programs.mlir (50 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_splat_float.mlir (51 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_splat_float.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %save0, %0 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: note: see current operation: tt.store %arg2, %0 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %save0, %0 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: note: see current operation: tt.store %arg2, %0 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %save1, %1 : tensor<128x256x!tt.ptr<bf16>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: note: see current operation: tt.store %arg3, %1 : tensor<128x256x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %save1, %1 : tensor<128x256x!tt.ptr<bf16>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: note: see current operation: tt.store %arg3, %1 : tensor<128x256x!tt.ptr<bf16>>
module {
  tt.func @kernel(%arg0: f32, %arg1: bf16, %arg2: tensor<1024x!tt.ptr<f32>>, %arg3: tensor<128x256x!tt.ptr<bf16>>) {
    %0 = tt.splat %arg0 : f32 -> tensor<1024xf32>
    %1 = tt.splat %arg1 : bf16 -> tensor<128x256xbf16>
    tt.store %arg2, %0 : tensor<1024x!tt.ptr<f32>>
    tt.store %arg3, %1 : tensor<128x256x!tt.ptr<bf16>>
    tt.return
  }
}
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir
 #0 0x0000559af4449317 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x255c317)
 #1 0x0000559af4446e3e llvm::sys::RunSignalHandlers() (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2559e3e)
 #2 0x0000559af44499cf SignalHandler(int) Signals.cpp:0:0
 #3 0x00007fb303b6a420 __restore_rt (/lib/x86_64-linux-gnu/libpthread.so.0+0x14420)
 #4 0x0000559af2492024 mlir::Operation::getResults() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:411:12
 #5 0x0000559af2492024 mlir::Operation::getResultTypes() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:423:47
 #6 0x0000559af2492024 (anonymous namespace)::StoreOpConverter::matchAndRewrite(mlir::triton::StoreOp, mlir::triton::StoreOpAdaptor, mlir::ConversionPatternRewriter&) const /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:306:24
 #7 0x0000559af23ad81f mlir::OpConversionPattern<mlir::triton::StoreOp>::matchAndRewrite(mlir::Operation*, llvm::ArrayRef<mlir::Value>, mlir::ConversionPatternRewriter&) const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/Transforms/DialectConversion.h:545:3
 #8 0x0000559af4059210 mlir::ConversionPattern::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c210)
 #9 0x0000559af409e03b mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>)::$_2::operator()() const PatternApplicator.cpp:0:0
#10 0x0000559af409abbf mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x21adbbf)
#11 0x0000559af405a1a1 (anonymous namespace)::OperationLegalizer::legalize(mlir::Operation*, mlir::ConversionPatternRewriter&) DialectConversion.cpp:0:0
#12 0x0000559af40592b4 mlir::OperationConverter::convert(mlir::ConversionPatternRewriter&, mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c2b4)
#13 0x0000559af405a6bf mlir::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216d6bf)
#14 0x0000559af4060dfb mlir::applyPartialConversion(mlir::Operation*, mlir::ConversionTarget const&, mlir::FrozenRewritePatternSet const&, mlir::ConversionConfig) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2173dfb)
#15 0x0000559af24907ed (anonymous namespace)::TritonLoadStoreToMemrefPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:410:16
#16 0x0000559af39b3d86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#17 0x0000559af39b4530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#18 0x0000559af39b8a7f llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (mlir::OpPassManager&, mlir::Operation*)>::callback_fn<mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::$_6>(long, mlir::OpPassManager&, mlir::Operation*) Pass.cpp:0:0
#19 0x0000559af246eac5 llvm::LogicalResult::failed() const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:43:43
#20 0x0000559af246eac5 llvm::failed(llvm::LogicalResult) /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:71:58
#21 0x0000559af246eac5 (anonymous namespace)::TritonToLinalgExperimentalPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonToLinalgExperimental/TritonToLinalgExperimentalPass.cpp:63:9
#22 0x0000559af39b3d86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#23 0x0000559af39b4530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#24 0x0000559af39b69e5 mlir::PassManager::run(mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac99e5)
#25 0x0000559af39b00bf performActions(llvm::raw_ostream&, std::shared_ptr<llvm::SourceMgr> const&, mlir::MLIRContext*, mlir::MlirOptMainConfig const&) MlirOptMain.cpp:0:0
#26 0x0000559af39afced llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>::callback_fn<mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&)::$_2>(long, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) MlirOptMain.cpp:0:0
#27 0x0000559af43dc9c4 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef)::$_0::operator()(llvm::StringRef) const ToolUtilities.cpp:0:0
#28 0x0000559af43dc5a0 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x24ef5a0)
#29 0x0000559af39aab11 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abdb11)
#30 0x0000559af39aadc3 mlir::MlirOptMain(int, char**, llvm::StringRef, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abddc3)
#31 0x0000559af39ab196 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abe196)
#32 0x0000559af24bc7eb main /home/nhat/github/triton_shared/tools/triton-shared-opt/triton-shared-opt.cpp:16:33
#33 0x00007fb30360e083 __libc_start_main /build/glibc-LcI20x/glibc-2.31/csu/../csu/libc-start.c:342:3
#34 0x0000559af217f92e _start (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x29292e)
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_splat_2d.mlir (52 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir (53 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save0, %5 : tensor<128x128x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save0, %5 : tensor<128x128x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save1, %6 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: note: see current operation: tt.store %arg4, %20 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save1, %6 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: note: see current operation: tt.store %arg4, %20 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save2, %7 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: note: see current operation: tt.store %arg5, %21 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save2, %7 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: note: see current operation: tt.store %arg5, %21 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save3, %10 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: note: see current operation: tt.store %arg6, %22 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save3, %10 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: note: see current operation: tt.store %arg6, %22 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save4, %11 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: note: see current operation: tt.store %arg7, %23 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save4, %11 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: note: see current operation: tt.store %arg7, %23 : tensor<128x128x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<i32>, %arg2: !tt.ptr<f16>, %arg3: tensor<128x128x!tt.ptr<bf16>>, %arg4: tensor<128x128x!tt.ptr<f32>>, %arg5: tensor<128x128x!tt.ptr<f32>>, %arg6: tensor<128x128x!tt.ptr<f32>>, %arg7: tensor<128x128x!tt.ptr<f32>>) {
    %0 = tts.make_tptr %arg0 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %1 = tts.make_tptr %arg1 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <i32> to tensor<128x128x!tt.ptr<i32>>
    %2 = tts.make_tptr %arg2 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f16> to tensor<128x128x!tt.ptr<f16>>
    %3 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %4 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<i32>>) -> tensor<128x128xi32>
    %5 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f16>>) -> tensor<128x128xf16>
    %6 = arith.truncf %3 : tensor<128x128xf32> to tensor<128x128xbf16>
    %7 = math.exp %3 : tensor<128x128xf32>
    %8 = arith.sitofp %4 : tensor<128x128xi32> to tensor<128x128xf32>
    %9 = arith.extf %5 : tensor<128x128xf16> to tensor<128x128xf32>
    %10 = math.sqrt %3 : tensor<128x128xf32>
    tt.store %arg3, %6 : tensor<128x128x!tt.ptr<bf16>>
    tt.store %arg4, %7 : tensor<128x128x!tt.ptr<f32>>
    tt.store %arg5, %8 : tensor<128x128x!tt.ptr<f32>>
    tt.store %arg6, %9 : tensor<128x128x!tt.ptr<f32>>
    tt.store %arg7, %10 : tensor<128x128x!tt.ptr<f32>>
    tt.return
  }
}
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
 #0 0x0000558cb7962317 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x255c317)
 #1 0x0000558cb795fe3e llvm::sys::RunSignalHandlers() (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2559e3e)
 #2 0x0000558cb79629cf SignalHandler(int) Signals.cpp:0:0
 #3 0x00007f38a1144420 __restore_rt (/lib/x86_64-linux-gnu/libpthread.so.0+0x14420)
 #4 0x0000558cb59ab024 mlir::Operation::getResults() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:411:12
 #5 0x0000558cb59ab024 mlir::Operation::getResultTypes() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:423:47
 #6 0x0000558cb59ab024 (anonymous namespace)::StoreOpConverter::matchAndRewrite(mlir::triton::StoreOp, mlir::triton::StoreOpAdaptor, mlir::ConversionPatternRewriter&) const /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:306:24
 #7 0x0000558cb58c681f mlir::OpConversionPattern<mlir::triton::StoreOp>::matchAndRewrite(mlir::Operation*, llvm::ArrayRef<mlir::Value>, mlir::ConversionPatternRewriter&) const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/Transforms/DialectConversion.h:545:3
 #8 0x0000558cb7572210 mlir::ConversionPattern::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c210)
 #9 0x0000558cb75b703b mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>)::$_2::operator()() const PatternApplicator.cpp:0:0
#10 0x0000558cb75b3bbf mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x21adbbf)
#11 0x0000558cb75731a1 (anonymous namespace)::OperationLegalizer::legalize(mlir::Operation*, mlir::ConversionPatternRewriter&) DialectConversion.cpp:0:0
#12 0x0000558cb75722b4 mlir::OperationConverter::convert(mlir::ConversionPatternRewriter&, mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c2b4)
#13 0x0000558cb75736bf mlir::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216d6bf)
#14 0x0000558cb7579dfb mlir::applyPartialConversion(mlir::Operation*, mlir::ConversionTarget const&, mlir::FrozenRewritePatternSet const&, mlir::ConversionConfig) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2173dfb)
#15 0x0000558cb59a97ed (anonymous namespace)::TritonLoadStoreToMemrefPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:410:16
#16 0x0000558cb6eccd86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#17 0x0000558cb6ecd530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#18 0x0000558cb6ed1a7f llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (mlir::OpPassManager&, mlir::Operation*)>::callback_fn<mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::$_6>(long, mlir::OpPassManager&, mlir::Operation*) Pass.cpp:0:0
#19 0x0000558cb5987ac5 llvm::LogicalResult::failed() const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:43:43
#20 0x0000558cb5987ac5 llvm::failed(llvm::LogicalResult) /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:71:58
#21 0x0000558cb5987ac5 (anonymous namespace)::TritonToLinalgExperimentalPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonToLinalgExperimental/TritonToLinalgExperimentalPass.cpp:63:9
#22 0x0000558cb6eccd86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#23 0x0000558cb6ecd530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#24 0x0000558cb6ecf9e5 mlir::PassManager::run(mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac99e5)
#25 0x0000558cb6ec90bf performActions(llvm::raw_ostream&, std::shared_ptr<llvm::SourceMgr> const&, mlir::MLIRContext*, mlir::MlirOptMainConfig const&) MlirOptMain.cpp:0:0
#26 0x0000558cb6ec8ced llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>::callback_fn<mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&)::$_2>(long, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) MlirOptMain.cpp:0:0
#27 0x0000558cb78f59c4 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef)::$_0::operator()(llvm::StringRef) const ToolUtilities.cpp:0:0
#28 0x0000558cb78f55a0 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x24ef5a0)
#29 0x0000558cb6ec3b11 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abdb11)
#30 0x0000558cb6ec3dc3 mlir::MlirOptMain(int, char**, llvm::StringRef, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abddc3)
#31 0x0000558cb6ec4196 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abe196)
#32 0x0000558cb59d57eb main /home/nhat/github/triton_shared/tools/triton-shared-opt/triton-shared-opt.cpp:16:33
#33 0x00007f38a0be8083 __libc_start_main /build/glibc-LcI20x/glibc-2.31/csu/../csu/libc-start.c:342:3
#34 0x0000558cb569892e _start (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x29292e)
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_splat.mlir (54 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir (55 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %d, %100 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %d, %100 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<i1>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: tensor<128x128x!tt.ptr<f32>>) {
    %0 = tts.make_tptr %arg0 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <i1> to tensor<128x128x!tt.ptr<i1>>
    %1 = tts.make_tptr %arg1 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %2 = tts.make_tptr %arg2 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %3 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<i1>>) -> tensor<128x128xi1>
    %4 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %5 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %6 = arith.select %3, %4, %5 : tensor<128x128xi1>, tensor<128x128xf32>
    tt.store %arg3, %6 : tensor<128x128x!tt.ptr<f32>>
    tt.return
  }
}
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
 #0 0x0000562eee156317 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x255c317)
 #1 0x0000562eee153e3e llvm::sys::RunSignalHandlers() (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2559e3e)
 #2 0x0000562eee1569cf SignalHandler(int) Signals.cpp:0:0
 #3 0x00007f81df73d420 __restore_rt (/lib/x86_64-linux-gnu/libpthread.so.0+0x14420)
 #4 0x0000562eec19f024 mlir::Operation::getResults() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:411:12
 #5 0x0000562eec19f024 mlir::Operation::getResultTypes() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:423:47
 #6 0x0000562eec19f024 (anonymous namespace)::StoreOpConverter::matchAndRewrite(mlir::triton::StoreOp, mlir::triton::StoreOpAdaptor, mlir::ConversionPatternRewriter&) const /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:306:24
 #7 0x0000562eec0ba81f mlir::OpConversionPattern<mlir::triton::StoreOp>::matchAndRewrite(mlir::Operation*, llvm::ArrayRef<mlir::Value>, mlir::ConversionPatternRewriter&) const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/Transforms/DialectConversion.h:545:3
 #8 0x0000562eedd66210 mlir::ConversionPattern::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c210)
 #9 0x0000562eeddab03b mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>)::$_2::operator()() const PatternApplicator.cpp:0:0
#10 0x0000562eedda7bbf mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x21adbbf)
#11 0x0000562eedd671a1 (anonymous namespace)::OperationLegalizer::legalize(mlir::Operation*, mlir::ConversionPatternRewriter&) DialectConversion.cpp:0:0
#12 0x0000562eedd662b4 mlir::OperationConverter::convert(mlir::ConversionPatternRewriter&, mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c2b4)
#13 0x0000562eedd676bf mlir::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216d6bf)
#14 0x0000562eedd6ddfb mlir::applyPartialConversion(mlir::Operation*, mlir::ConversionTarget const&, mlir::FrozenRewritePatternSet const&, mlir::ConversionConfig) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2173dfb)
#15 0x0000562eec19d7ed (anonymous namespace)::TritonLoadStoreToMemrefPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:410:16
#16 0x0000562eed6c0d86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#17 0x0000562eed6c1530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#18 0x0000562eed6c5a7f llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (mlir::OpPassManager&, mlir::Operation*)>::callback_fn<mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::$_6>(long, mlir::OpPassManager&, mlir::Operation*) Pass.cpp:0:0
#19 0x0000562eec17bac5 llvm::LogicalResult::failed() const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:43:43
#20 0x0000562eec17bac5 llvm::failed(llvm::LogicalResult) /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:71:58
#21 0x0000562eec17bac5 (anonymous namespace)::TritonToLinalgExperimentalPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonToLinalgExperimental/TritonToLinalgExperimentalPass.cpp:63:9
#22 0x0000562eed6c0d86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#23 0x0000562eed6c1530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#24 0x0000562eed6c39e5 mlir::PassManager::run(mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac99e5)
#25 0x0000562eed6bd0bf performActions(llvm::raw_ostream&, std::shared_ptr<llvm::SourceMgr> const&, mlir::MLIRContext*, mlir::MlirOptMainConfig const&) MlirOptMain.cpp:0:0
#26 0x0000562eed6bcced llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>::callback_fn<mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&)::$_2>(long, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) MlirOptMain.cpp:0:0
#27 0x0000562eee0e99c4 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef)::$_0::operator()(llvm::StringRef) const ToolUtilities.cpp:0:0
#28 0x0000562eee0e95a0 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x24ef5a0)
#29 0x0000562eed6b7b11 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abdb11)
#30 0x0000562eed6b7dc3 mlir::MlirOptMain(int, char**, llvm::StringRef, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abddc3)
#31 0x0000562eed6b8196 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abe196)
#32 0x0000562eec1c97eb main /home/nhat/github/triton_shared/tools/triton-shared-opt/triton-shared-opt.cpp:16:33
#33 0x00007f81df1e1083 __libc_start_main /build/glibc-LcI20x/glibc-2.31/csu/../csu/libc-start.c:342:3
#34 0x0000562eebe8c92e _start (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x29292e)
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir (56 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save0, %5 : tensor<1024x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save0, %5 : tensor<1024x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save1, %6 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: note: see current operation: tt.store %arg4, %14 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save1, %6 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: note: see current operation: tt.store %arg4, %14 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save2, %7 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: note: see current operation: tt.store %arg5, %15 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save2, %7 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: note: see current operation: tt.store %arg5, %15 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save3, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: note: see current operation: tt.store %arg6, %16 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save3, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: note: see current operation: tt.store %arg6, %16 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save4, %11 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: note: see current operation: tt.store %arg7, %17 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save4, %11 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: note: see current operation: tt.store %arg7, %17 : tensor<1024x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<i32>, %arg2: !tt.ptr<f16>, %arg3: tensor<1024x!tt.ptr<bf16>>, %arg4: tensor<1024x!tt.ptr<f32>>, %arg5: tensor<1024x!tt.ptr<f32>>, %arg6: tensor<1024x!tt.ptr<f32>>, %arg7: tensor<1024x!tt.ptr<f32>>) {
    %0 = tts.make_tptr %arg0 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %1 = tts.make_tptr %arg1 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <i32> to tensor<1024x!tt.ptr<i32>>
    %2 = tts.make_tptr %arg2 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f16> to tensor<1024x!tt.ptr<f16>>
    %3 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %4 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<i32>>) -> tensor<1024xi32>
    %5 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f16>>) -> tensor<1024xf16>
    %6 = arith.truncf %3 : tensor<1024xf32> to tensor<1024xbf16>
    %7 = math.exp %3 : tensor<1024xf32>
    %8 = arith.sitofp %4 : tensor<1024xi32> to tensor<1024xf32>
    %9 = arith.extf %5 : tensor<1024xf16> to tensor<1024xf32>
    %10 = math.sqrt %3 : tensor<1024xf32>
    tt.store %arg3, %6 : tensor<1024x!tt.ptr<bf16>>
    tt.store %arg4, %7 : tensor<1024x!tt.ptr<f32>>
    tt.store %arg5, %8 : tensor<1024x!tt.ptr<f32>>
    tt.store %arg6, %9 : tensor<1024x!tt.ptr<f32>>
    tt.store %arg7, %10 : tensor<1024x!tt.ptr<f32>>
    tt.return
  }
}
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
 #0 0x000055913db64317 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x255c317)
 #1 0x000055913db61e3e llvm::sys::RunSignalHandlers() (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2559e3e)
 #2 0x000055913db649cf SignalHandler(int) Signals.cpp:0:0
 #3 0x00007ff1c5416420 __restore_rt (/lib/x86_64-linux-gnu/libpthread.so.0+0x14420)
 #4 0x000055913bbad024 mlir::Operation::getResults() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:411:12
 #5 0x000055913bbad024 mlir::Operation::getResultTypes() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:423:47
 #6 0x000055913bbad024 (anonymous namespace)::StoreOpConverter::matchAndRewrite(mlir::triton::StoreOp, mlir::triton::StoreOpAdaptor, mlir::ConversionPatternRewriter&) const /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:306:24
 #7 0x000055913bac881f mlir::OpConversionPattern<mlir::triton::StoreOp>::matchAndRewrite(mlir::Operation*, llvm::ArrayRef<mlir::Value>, mlir::ConversionPatternRewriter&) const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/Transforms/DialectConversion.h:545:3
 #8 0x000055913d774210 mlir::ConversionPattern::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c210)
 #9 0x000055913d7b903b mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>)::$_2::operator()() const PatternApplicator.cpp:0:0
#10 0x000055913d7b5bbf mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x21adbbf)
#11 0x000055913d7751a1 (anonymous namespace)::OperationLegalizer::legalize(mlir::Operation*, mlir::ConversionPatternRewriter&) DialectConversion.cpp:0:0
#12 0x000055913d7742b4 mlir::OperationConverter::convert(mlir::ConversionPatternRewriter&, mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c2b4)
#13 0x000055913d7756bf mlir::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216d6bf)
#14 0x000055913d77bdfb mlir::applyPartialConversion(mlir::Operation*, mlir::ConversionTarget const&, mlir::FrozenRewritePatternSet const&, mlir::ConversionConfig) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2173dfb)
#15 0x000055913bbab7ed (anonymous namespace)::TritonLoadStoreToMemrefPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:410:16
#16 0x000055913d0ced86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#17 0x000055913d0cf530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#18 0x000055913d0d3a7f llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (mlir::OpPassManager&, mlir::Operation*)>::callback_fn<mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::$_6>(long, mlir::OpPassManager&, mlir::Operation*) Pass.cpp:0:0
#19 0x000055913bb89ac5 llvm::LogicalResult::failed() const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:43:43
#20 0x000055913bb89ac5 llvm::failed(llvm::LogicalResult) /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:71:58
#21 0x000055913bb89ac5 (anonymous namespace)::TritonToLinalgExperimentalPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonToLinalgExperimental/TritonToLinalgExperimentalPass.cpp:63:9
#22 0x000055913d0ced86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#23 0x000055913d0cf530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#24 0x000055913d0d19e5 mlir::PassManager::run(mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac99e5)
#25 0x000055913d0cb0bf performActions(llvm::raw_ostream&, std::shared_ptr<llvm::SourceMgr> const&, mlir::MLIRContext*, mlir::MlirOptMainConfig const&) MlirOptMain.cpp:0:0
#26 0x000055913d0caced llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>::callback_fn<mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&)::$_2>(long, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) MlirOptMain.cpp:0:0
#27 0x000055913daf79c4 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef)::$_0::operator()(llvm::StringRef) const ToolUtilities.cpp:0:0
#28 0x000055913daf75a0 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x24ef5a0)
#29 0x000055913d0c5b11 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abdb11)
#30 0x000055913d0c5dc3 mlir::MlirOptMain(int, char**, llvm::StringRef, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abddc3)
#31 0x000055913d0c6196 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abe196)
#32 0x000055913bbd77eb main /home/nhat/github/triton_shared/tools/triton-shared-opt/triton-shared-opt.cpp:16:33
#33 0x00007ff1c4eba083 __libc_start_main /build/glibc-LcI20x/glibc-2.31/csu/../csu/libc-start.c:342:3
#34 0x000055913b89a92e _start (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x29292e)
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/arith_not_ptr_arith.mlir (57 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir (58 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %c, %res0 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: note: see current operation: tt.store %arg2, %15 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %c, %res0 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: note: see current operation: tt.store %arg2, %15 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %d, %res1 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: note: see current operation: tt.store %arg3, %16 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %d, %res1 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: note: see current operation: tt.store %arg3, %16 : tensor<128x128x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: tensor<128x128x!tt.ptr<f32>>, %arg3: tensor<128x128x!tt.ptr<f32>>) {
    %0 = tts.make_tptr %arg0 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %1 = tts.make_tptr %arg1 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %2 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %3 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %4 = arith.addf %2, %3 : tensor<128x128xf32>
    %5 = arith.subf %2, %3 : tensor<128x128xf32>
    tt.store %arg2, %4 : tensor<128x128x!tt.ptr<f32>>
    tt.store %arg3, %5 : tensor<128x128x!tt.ptr<f32>>
    tt.return
  }
}
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
 #0 0x000056542b199317 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x255c317)
 #1 0x000056542b196e3e llvm::sys::RunSignalHandlers() (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2559e3e)
 #2 0x000056542b1999cf SignalHandler(int) Signals.cpp:0:0
 #3 0x00007fe5077bc420 __restore_rt (/lib/x86_64-linux-gnu/libpthread.so.0+0x14420)
 #4 0x00005654291e2024 mlir::Operation::getResults() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:411:12
 #5 0x00005654291e2024 mlir::Operation::getResultTypes() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:423:47
 #6 0x00005654291e2024 (anonymous namespace)::StoreOpConverter::matchAndRewrite(mlir::triton::StoreOp, mlir::triton::StoreOpAdaptor, mlir::ConversionPatternRewriter&) const /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:306:24
 #7 0x00005654290fd81f mlir::OpConversionPattern<mlir::triton::StoreOp>::matchAndRewrite(mlir::Operation*, llvm::ArrayRef<mlir::Value>, mlir::ConversionPatternRewriter&) const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/Transforms/DialectConversion.h:545:3
 #8 0x000056542ada9210 mlir::ConversionPattern::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c210)
 #9 0x000056542adee03b mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>)::$_2::operator()() const PatternApplicator.cpp:0:0
#10 0x000056542adeabbf mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x21adbbf)
#11 0x000056542adaa1a1 (anonymous namespace)::OperationLegalizer::legalize(mlir::Operation*, mlir::ConversionPatternRewriter&) DialectConversion.cpp:0:0
#12 0x000056542ada92b4 mlir::OperationConverter::convert(mlir::ConversionPatternRewriter&, mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c2b4)
#13 0x000056542adaa6bf mlir::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216d6bf)
#14 0x000056542adb0dfb mlir::applyPartialConversion(mlir::Operation*, mlir::ConversionTarget const&, mlir::FrozenRewritePatternSet const&, mlir::ConversionConfig) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2173dfb)
#15 0x00005654291e07ed (anonymous namespace)::TritonLoadStoreToMemrefPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:410:16
#16 0x000056542a703d86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#17 0x000056542a704530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#18 0x000056542a708a7f llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (mlir::OpPassManager&, mlir::Operation*)>::callback_fn<mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::$_6>(long, mlir::OpPassManager&, mlir::Operation*) Pass.cpp:0:0
#19 0x00005654291beac5 llvm::LogicalResult::failed() const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:43:43
#20 0x00005654291beac5 llvm::failed(llvm::LogicalResult) /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:71:58
#21 0x00005654291beac5 (anonymous namespace)::TritonToLinalgExperimentalPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonToLinalgExperimental/TritonToLinalgExperimentalPass.cpp:63:9
#22 0x000056542a703d86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#23 0x000056542a704530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#24 0x000056542a7069e5 mlir::PassManager::run(mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac99e5)
#25 0x000056542a7000bf performActions(llvm::raw_ostream&, std::shared_ptr<llvm::SourceMgr> const&, mlir::MLIRContext*, mlir::MlirOptMainConfig const&) MlirOptMain.cpp:0:0
#26 0x000056542a6ffced llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>::callback_fn<mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&)::$_2>(long, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) MlirOptMain.cpp:0:0
#27 0x000056542b12c9c4 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef)::$_0::operator()(llvm::StringRef) const ToolUtilities.cpp:0:0
#28 0x000056542b12c5a0 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x24ef5a0)
#29 0x000056542a6fab11 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abdb11)
#30 0x000056542a6fadc3 mlir::MlirOptMain(int, char**, llvm::StringRef, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abddc3)
#31 0x000056542a6fb196 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abe196)
#32 0x000056542920c7eb main /home/nhat/github/triton_shared/tools/triton-shared-opt/triton-shared-opt.cpp:16:33
#33 0x00007fe507260083 __libc_start_main /build/glibc-LcI20x/glibc-2.31/csu/../csu/libc-start.c:342:3
#34 0x0000565428ecf92e _start (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x29292e)
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_f32_axis1.mlir (59 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/use_end_chain.mlir (60 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir (61 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
module {
  tt.func @kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: i32, %arg3: i32, %arg4: i32) {
    %c0_i64 = arith.constant 0 : i64
    %c128 = arith.constant 128 : index
    %cst = arith.constant dense<0.000000e+00> : tensor<128x128xf32>
    %c3 = arith.constant 3 : index
    %c12 = arith.constant 12 : index
    %c0 = arith.constant 0 : index
    %0 = tt.get_program_id x : i32
    %1 = arith.muli %0, %arg2 : i32
    %2 = arith.index_cast %1 : i32 to index
    %3 = arith.extsi %1 : i32 to i64
    %4 = arith.addi %c0_i64, %3 : i64
    %5:3 = scf.for %arg5 = %c0 to %c12 step %c3 iter_args(%arg6 = %cst, %arg7 = %4, %arg8 = %2) -> (tensor<128x128xf32>, i64, index) {
      %10 = arith.addi %arg8, %c128 : index
      %11 = tts.make_tptr %arg1 to sizes: [128, 128], strides: [1, 1], offsets: [%10, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
      %12 = "tts.load"(%11) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
      %13 = math.exp %12 : tensor<128x128xf32>
      %14 = arith.addf %arg6, %13 : tensor<128x128xf32>
      %15 = arith.index_cast %arg5 : index to i32
      %16 = arith.addi %arg8, %arg5 : index
      %17 = arith.extsi %15 : i32 to i64
      %18 = arith.addi %arg7, %17 : i64
      scf.yield %14, %18, %16 : tensor<128x128xf32>, i64, index
    }
    %6 = arith.muli %0, %arg3 : i32
    %7 = arith.index_cast %6 : i32 to index
    %8 = arith.addi %7, %c128 : index
    %9 = tts.make_tptr %arg0 to sizes: [128, 128], strides: [1, 1], offsets: [%8, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    "tts.store"(%9, %5#0) <{static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xf32>) -> ()
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir:70:11: error: CHECK: expected string not found in input
// CHECK: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_1_]] to offset: {{.}}[[VAR_3_]]{{.}}, sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
          ^
<stdin>:12:41: note: scanning from here
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:12:41: note: with "PARAM_1_" equal to "%arg1"
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:12:41: note: with "VAR_3_" equal to "%3"
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:16:18: note: possible intended match here
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%9], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1], offset: ?>>
                 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            .
            .
            .
            7:  %c3 = arith.constant 3 : index 
            8:  %cst = arith.constant 0.000000e+00 : f32 
            9:  %0 = tensor.empty() : tensor<128x128xf32> 
           10:  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<128x128xf32>) -> tensor<128x128xf32> 
           11:  %2 = arith.muli %arg8, %arg2 : i32 
           12:  %3 = arith.index_cast %2 : i32 to index 
check:70'0                                             X error: no match found
check:70'1                                               with "PARAM_1_" equal to "%arg1"
check:70'2                                               with "VAR_3_" equal to "%3"
           13:  %4 = arith.extsi %2 : i32 to i64 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           14:  %5:3 = scf.for %arg11 = %c0 to %c12 step %c3 iter_args(%arg12 = %1, %arg13 = %4, %arg14 = %3) -> (tensor<128x128xf32>, i64, index) { 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           15:  %9 = arith.addi %arg14, %c128 : index 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           16:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%9], sizes: [128, 128], strides: [1, 1] : memref<*xf32> to memref<128x128xf32, strided<[1, 1], offset: ?>> 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:70'3                      ?                                                                                                                                                           possible intended match
           17:  %alloc = memref.alloc() : memref<128x128xf32> 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           18:  memref.copy %reinterpret_cast_0, %alloc : memref<128x128xf32, strided<[1, 1], offset: ?>> to memref<128x128xf32> 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           19:  %10 = bufferization.to_tensor %alloc restrict writable : memref<128x128xf32> 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           20:  %11 = linalg.generic {indexing_maps = [#map, #map], iterator_types = ["parallel", "parallel"]} ins(%10 : tensor<128x128xf32>) outs(%10 : tensor<128x128xf32>) { 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           21:  ^bb0(%in: f32, %out: f32): 
check:70'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            .
            .
            .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir (62 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %d, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %d, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<i1>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: tensor<1024x!tt.ptr<f32>>) {
    %0 = tts.make_tptr %arg0 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <i1> to tensor<1024x!tt.ptr<i1>>
    %1 = tts.make_tptr %arg1 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %2 = tts.make_tptr %arg2 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %3 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<i1>>) -> tensor<1024xi1>
    %4 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %5 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %6 = arith.select %3, %4, %5 : tensor<1024xi1>, tensor<1024xf32>
    tt.store %arg3, %6 : tensor<1024x!tt.ptr<f32>>
    tt.return
  }
}
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
 #0 0x00005615e9a69317 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x255c317)
 #1 0x00005615e9a66e3e llvm::sys::RunSignalHandlers() (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2559e3e)
 #2 0x00005615e9a699cf SignalHandler(int) Signals.cpp:0:0
 #3 0x00007f7635a5a420 __restore_rt (/lib/x86_64-linux-gnu/libpthread.so.0+0x14420)
 #4 0x00005615e7ab2024 mlir::Operation::getResults() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:411:12
 #5 0x00005615e7ab2024 mlir::Operation::getResultTypes() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:423:47
 #6 0x00005615e7ab2024 (anonymous namespace)::StoreOpConverter::matchAndRewrite(mlir::triton::StoreOp, mlir::triton::StoreOpAdaptor, mlir::ConversionPatternRewriter&) const /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:306:24
 #7 0x00005615e79cd81f mlir::OpConversionPattern<mlir::triton::StoreOp>::matchAndRewrite(mlir::Operation*, llvm::ArrayRef<mlir::Value>, mlir::ConversionPatternRewriter&) const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/Transforms/DialectConversion.h:545:3
 #8 0x00005615e9679210 mlir::ConversionPattern::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c210)
 #9 0x00005615e96be03b mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>)::$_2::operator()() const PatternApplicator.cpp:0:0
#10 0x00005615e96babbf mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x21adbbf)
#11 0x00005615e967a1a1 (anonymous namespace)::OperationLegalizer::legalize(mlir::Operation*, mlir::ConversionPatternRewriter&) DialectConversion.cpp:0:0
#12 0x00005615e96792b4 mlir::OperationConverter::convert(mlir::ConversionPatternRewriter&, mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c2b4)
#13 0x00005615e967a6bf mlir::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216d6bf)
#14 0x00005615e9680dfb mlir::applyPartialConversion(mlir::Operation*, mlir::ConversionTarget const&, mlir::FrozenRewritePatternSet const&, mlir::ConversionConfig) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2173dfb)
#15 0x00005615e7ab07ed (anonymous namespace)::TritonLoadStoreToMemrefPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:410:16
#16 0x00005615e8fd3d86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#17 0x00005615e8fd4530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#18 0x00005615e8fd8a7f llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (mlir::OpPassManager&, mlir::Operation*)>::callback_fn<mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::$_6>(long, mlir::OpPassManager&, mlir::Operation*) Pass.cpp:0:0
#19 0x00005615e7a8eac5 llvm::LogicalResult::failed() const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:43:43
#20 0x00005615e7a8eac5 llvm::failed(llvm::LogicalResult) /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:71:58
#21 0x00005615e7a8eac5 (anonymous namespace)::TritonToLinalgExperimentalPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonToLinalgExperimental/TritonToLinalgExperimentalPass.cpp:63:9
#22 0x00005615e8fd3d86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#23 0x00005615e8fd4530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#24 0x00005615e8fd69e5 mlir::PassManager::run(mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac99e5)
#25 0x00005615e8fd00bf performActions(llvm::raw_ostream&, std::shared_ptr<llvm::SourceMgr> const&, mlir::MLIRContext*, mlir::MlirOptMainConfig const&) MlirOptMain.cpp:0:0
#26 0x00005615e8fcfced llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>::callback_fn<mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&)::$_2>(long, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) MlirOptMain.cpp:0:0
#27 0x00005615e99fc9c4 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef)::$_0::operator()(llvm::StringRef) const ToolUtilities.cpp:0:0
#28 0x00005615e99fc5a0 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x24ef5a0)
#29 0x00005615e8fcab11 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abdb11)
#30 0x00005615e8fcadc3 mlir::MlirOptMain(int, char**, llvm::StringRef, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abddc3)
#31 0x00005615e8fcb196 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abe196)
#32 0x00005615e7adc7eb main /home/nhat/github/triton_shared/tools/triton-shared-opt/triton-shared-opt.cpp:16:33
#33 0x00007f76354fe083 __libc_start_main /build/glibc-LcI20x/glibc-2.31/csu/../csu/libc-start.c:342:3
#34 0x00005615e779f92e _start (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x29292e)
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_expand_ptr.mlir (63 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_used_before_update.mlir (64 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_bf16_axis0.mlir (65 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_add_value.mlir (66 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir (67 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %c, %6 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: note: see current operation: tt.store %arg2, %14 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %c, %6 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: note: see current operation: tt.store %arg2, %14 : tensor<1024x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: tensor<1024x!tt.ptr<f32>>) {
    %0 = tts.make_tptr %arg0 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %1 = tts.make_tptr %arg1 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %2 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %3 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
1024xf32>
    %4 = arith.addf %2, %3 : tensor<1024xf32>
    %5 = arith.subf %4, %3 : tensor<1024xf32>
    %6 = arith.mulf %5, %3 : tensor<1024xf32>
    %7 = arith.divf %6, %3 : tensor<1024xf32>
    %8 = arith.cmpf oeq, %7, %3 : tensor<1024xf32>
    %9 = arith.select %8, %2, %3 : tensor<1024xi1>, tensor<1024xf32>
    tt.store %arg2, %9 : tensor<1024x!tt.ptr<f32>>
    tt.return
  }
}
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
 #0 0x0000563709a9b317 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x255c317)
 #1 0x0000563709a98e3e llvm::sys::RunSignalHandlers() (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2559e3e)
 #2 0x0000563709a9b9cf SignalHandler(int) Signals.cpp:0:0
 #3 0x00007f79e4e89420 __restore_rt (/lib/x86_64-linux-gnu/libpthread.so.0+0x14420)
 #4 0x0000563707ae4024 mlir::Operation::getResults() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:411:12
 #5 0x0000563707ae4024 mlir::Operation::getResultTypes() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:423:47
 #6 0x0000563707ae4024 (anonymous namespace)::StoreOpConverter::matchAndRewrite(mlir::triton::StoreOp, mlir::triton::StoreOpAdaptor, mlir::ConversionPatternRewriter&) const /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:306:24
 #7 0x00005637079ff81f mlir::OpConversionPattern<mlir::triton::StoreOp>::matchAndRewrite(mlir::Operation*, llvm::ArrayRef<mlir::Value>, mlir::ConversionPatternRewriter&) const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/Transforms/DialectConversion.h:545:3
 #8 0x00005637096ab210 mlir::ConversionPattern::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c210)
 #9 0x00005637096f003b mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>)::$_2::operator()() const PatternApplicator.cpp:0:0
#10 0x00005637096ecbbf mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x21adbbf)
#11 0x00005637096ac1a1 (anonymous namespace)::OperationLegalizer::legalize(mlir::Operation*, mlir::ConversionPatternRewriter&) DialectConversion.cpp:0:0
#12 0x00005637096ab2b4 mlir::OperationConverter::convert(mlir::ConversionPatternRewriter&, mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c2b4)
#13 0x00005637096ac6bf mlir::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216d6bf)
#14 0x00005637096b2dfb mlir::applyPartialConversion(mlir::Operation*, mlir::ConversionTarget const&, mlir::FrozenRewritePatternSet const&, mlir::ConversionConfig) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2173dfb)
#15 0x0000563707ae27ed (anonymous namespace)::TritonLoadStoreToMemrefPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:410:16
#16 0x0000563709005d86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#17 0x0000563709006530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#18 0x000056370900aa7f llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (mlir::OpPassManager&, mlir::Operation*)>::callback_fn<mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::$_6>(long, mlir::OpPassManager&, mlir::Operation*) Pass.cpp:0:0
#19 0x0000563707ac0ac5 llvm::LogicalResult::failed() const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:43:43
#20 0x0000563707ac0ac5 llvm::failed(llvm::LogicalResult) /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:71:58
#21 0x0000563707ac0ac5 (anonymous namespace)::TritonToLinalgExperimentalPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonToLinalgExperimental/TritonToLinalgExperimentalPass.cpp:63:9
#22 0x0000563709005d86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#23 0x0000563709006530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#24 0x00005637090089e5 mlir::PassManager::run(mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac99e5)
#25 0x00005637090020bf performActions(llvm::raw_ostream&, std::shared_ptr<llvm::SourceMgr> const&, mlir::MLIRContext*, mlir::MlirOptMainConfig const&) MlirOptMain.cpp:0:0
#26 0x0000563709001ced llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>::callback_fn<mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&)::$_2>(long, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) MlirOptMain.cpp:0:0
#27 0x0000563709a2e9c4 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef)::$_0::operator()(llvm::StringRef) const ToolUtilities.cpp:0:0
#28 0x0000563709a2e5a0 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x24ef5a0)
#29 0x0000563708ffcb11 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abdb11)
#30 0x0000563708ffcdc3 mlir::MlirOptMain(int, char**, llvm::StringRef, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abddc3)
#31 0x0000563708ffd196 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abe196)
#32 0x0000563707b0e7eb main /home/nhat/github/triton_shared/tools/triton-shared-opt/triton-shared-opt.cpp:16:33
#33 0x00007f79e492d083 __libc_start_main /build/glibc-LcI20x/glibc-2.31/csu/../csu/libc-start.c:342:3
#34 0x00005637077d192e _start (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x29292e)
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/use_mid_chain.mlir (68 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_scalar.mlir (69 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_scalar.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %res, %3 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: note: see current operation: tt.store %arg1, %5 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %res, %3 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: note: see current operation: tt.store %arg1, %5 : !tt.ptr<bf16>
module {
  tt.func @kernel(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>) {
    %0 = tts.make_tptr %arg0 to sizes: [128], strides: [1], offsets: [0], shape: [0], order: [] : <bf16> to tensor<128x!tt.ptr<bf16>>
    %1 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x!tt.ptr<bf16>>) -> tensor<128xbf16>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg2: bf16, %arg3: bf16):
      %3 = arith.addf %arg2, %arg3 : bf16
      tt.reduce.return %3 : bf16
    }) : (tensor<128xbf16>) -> bf16
    tt.store %arg1, %2 : !tt.ptr<bf16>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:22:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_1_]] to offset: [0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
              ^
<stdin>:2:139: note: scanning from here
 func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
                                                                                                                                          ^
<stdin>:2:139: note: with "PARAM_1_" equal to "%arg1"
 func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
                                                                                                                                          ^
<stdin>:19:16: note: possible intended match here
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%c0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
               ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) { 
dag:22'0                                                                                                                                               X error: no match found
dag:22'1                                                                                                                                                 with "PARAM_1_" equal to "%arg1"
          3:  %c0 = arith.constant 0 : index 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %cst = arith.constant 0.000000e+00 : f32 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [128], strides: [1] : memref<*xbf16> to memref<128xbf16, strided<[1]>> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %alloc = memref.alloc() : memref<128xbf16> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  memref.copy %reinterpret_cast, %alloc : memref<128xbf16, strided<[1]>> to memref<128xbf16> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         14:  %4 = arith.addf %3, %init : f32 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         15:  linalg.yield %4 : f32 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~
         16:  } 
dag:22'0     ~~~
         17:  %extracted = tensor.extract %reduced[] : tensor<f32> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         18:  %2 = arith.truncf %extracted : f32 to bf16 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         19:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%c0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:22'2                    ?                                                                                                                                             possible intended match
         20:  affine.store %2, %reinterpret_cast_0[0] : memref<1xbf16, strided<[1], offset: ?>> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         21:  return 
dag:22'0     ~~~~~~~~
         22:  } 
dag:22'0     ~~~
         23: } 
dag:22'0     ~~
         24:  
dag:22'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir (70 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %res, %6 : tensor<256x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: note: see current operation: tt.store %arg1, %19 : tensor<256x16x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %res, %6 : tensor<256x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: note: see current operation: tt.store %arg1, %19 : tensor<256x16x!tt.ptr<bf16>>
module {
  tt.func @kernel(%arg0: !tt.ptr<bf16>, %arg1: tensor<256x16x!tt.ptr<bf16>>) {
    %c256 = arith.constant 256 : index
    %0 = tts.make_tptr %arg0 to sizes: [32, 256, 16], strides: [%c256, 1, 1], offsets: [0, 0, 0], shape: [0, 0, 0], order: [] : <bf16> to tensor<32x256x16x!tt.ptr<bf16>>
    %1 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<32x256x16x!tt.ptr<bf16>>) -> tensor<32x256x16xbf16>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg2: bf16, %arg3: bf16):
      %3 = arith.cmpf ogt, %arg2, %arg3 : bf16
      %4 = arith.select %3, %arg2, %arg3 : bf16
      tt.reduce.return %4 : bf16
    }) : (tensor<32x256x16xbf16>) -> tensor<256x16xbf16>
    tt.store %arg1, %2 : tensor<256x16x!tt.ptr<bf16>>
    tt.return
  }
}
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
 #0 0x00005645ec2ec317 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x255c317)
 #1 0x00005645ec2e9e3e llvm::sys::RunSignalHandlers() (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2559e3e)
 #2 0x00005645ec2ec9cf SignalHandler(int) Signals.cpp:0:0
 #3 0x00007fd22eddc420 __restore_rt (/lib/x86_64-linux-gnu/libpthread.so.0+0x14420)
 #4 0x00005645ea335024 mlir::Operation::getResults() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:411:12
 #5 0x00005645ea335024 mlir::Operation::getResultTypes() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:423:47
 #6 0x00005645ea335024 (anonymous namespace)::StoreOpConverter::matchAndRewrite(mlir::triton::StoreOp, mlir::triton::StoreOpAdaptor, mlir::ConversionPatternRewriter&) const /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:306:24
 #7 0x00005645ea25081f mlir::OpConversionPattern<mlir::triton::StoreOp>::matchAndRewrite(mlir::Operation*, llvm::ArrayRef<mlir::Value>, mlir::ConversionPatternRewriter&) const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/Transforms/DialectConversion.h:545:3
 #8 0x00005645ebefc210 mlir::ConversionPattern::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c210)
 #9 0x00005645ebf4103b mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>)::$_2::operator()() const PatternApplicator.cpp:0:0
#10 0x00005645ebf3dbbf mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x21adbbf)
#11 0x00005645ebefd1a1 (anonymous namespace)::OperationLegalizer::legalize(mlir::Operation*, mlir::ConversionPatternRewriter&) DialectConversion.cpp:0:0
#12 0x00005645ebefc2b4 mlir::OperationConverter::convert(mlir::ConversionPatternRewriter&, mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c2b4)
#13 0x00005645ebefd6bf mlir::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216d6bf)
#14 0x00005645ebf03dfb mlir::applyPartialConversion(mlir::Operation*, mlir::ConversionTarget const&, mlir::FrozenRewritePatternSet const&, mlir::ConversionConfig) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2173dfb)
#15 0x00005645ea3337ed (anonymous namespace)::TritonLoadStoreToMemrefPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:410:16
#16 0x00005645eb856d86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#17 0x00005645eb857530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#18 0x00005645eb85ba7f llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (mlir::OpPassManager&, mlir::Operation*)>::callback_fn<mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::$_6>(long, mlir::OpPassManager&, mlir::Operation*) Pass.cpp:0:0
#19 0x00005645ea311ac5 llvm::LogicalResult::failed() const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:43:43
#20 0x00005645ea311ac5 llvm::failed(llvm::LogicalResult) /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:71:58
#21 0x00005645ea311ac5 (anonymous namespace)::TritonToLinalgExperimentalPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonToLinalgExperimental/TritonToLinalgExperimentalPass.cpp:63:9
#22 0x00005645eb856d86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#23 0x00005645eb857530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#24 0x00005645eb8599e5 mlir::PassManager::run(mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac99e5)
#25 0x00005645eb8530bf performActions(llvm::raw_ostream&, std::shared_ptr<llvm::SourceMgr> const&, mlir::MLIRContext*, mlir::MlirOptMainConfig const&) MlirOptMain.cpp:0:0
#26 0x00005645eb852ced llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>::callback_fn<mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&)::$_2>(long, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) MlirOptMain.cpp:0:0
#27 0x00005645ec27f9c4 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef)::$_0::operator()(llvm::StringRef) const ToolUtilities.cpp:0:0
#28 0x00005645ec27f5a0 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x24ef5a0)
#29 0x00005645eb84db11 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abdb11)
#30 0x00005645eb84ddc3 mlir::MlirOptMain(int, char**, llvm::StringRef, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abddc3)
#31 0x00005645eb84e196 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abe196)
#32 0x00005645ea35f7eb main /home/nhat/github/triton_shared/tools/triton-shared-opt/triton-shared-opt.cpp:16:33
#33 0x00007fd22e880083 __libc_start_main /build/glibc-LcI20x/glibc-2.31/csu/../csu/libc-start.c:342:3
#34 0x00005645ea02292e _start (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x29292e)
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_complex_offset.mlir (71 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_complex_offset.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --structured-to-memref --split-input-file /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --structured-to-memref --split-input-file /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir:22:11: error: CHECK: expected string not found in input
// CHECK: %0 = arith.remsi %arg8, %arg3 : i32
          ^
<stdin>:6:36: note: scanning from here
 %c128 = arith.constant 128 : index
                                   ^
<stdin>:7:2: note: possible intended match here
 %1 = arith.remsi %arg8, %arg3 : i32
 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            1: module { 
            2:  func.func @fused_attention_fwd_kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i64, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) -> tensor<128x128xbf16> { 
            3:  %0 = builtin.unrealized_conversion_cast %arg0 : memref<*xbf16> to !tt.ptr<bf16> 
            4:  %c1 = arith.constant 1 : index 
            5:  %c0 = arith.constant 0 : index 
            6:  %c128 = arith.constant 128 : index 
check:22'0                                        X error: no match found
            7:  %1 = arith.remsi %arg8, %arg3 : i32 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:22'1      ?                                    possible intended match
            8:  %2 = arith.extsi %1 : i32 to i64 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            9:  %3 = arith.muli %2, %arg2 : i64 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           10:  %4 = tt.addptr %0, %3 : !tt.ptr<bf16>, i64 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           11:  %5 = arith.addi %c0, %c0 : index 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           12:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%5], sizes: [128, 128], strides: [%c128, %c1] : memref<*xbf16> to memref<128x128xbf16, strided<[?, ?], offset: ?>> 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            .
            .
            .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for.mlir (72 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir
module {
  tt.func @kernel(%arg0: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg1: !tt.ptr<f32> {tt.divisibility = 16 : i32}, %arg2: i32, %arg3: i32, %arg4: i32) {
    + FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir
%c0_i64 = arith.constant 0 : i64
    %cst = arith.constant dense<0.000000e+00> : tensor<1024xf32>
    %c3 = arith.constant 3 : index
    %c12 = arith.constant 12 : index
    %c0 = arith.constant 0 : index
    %0 = tt.get_program_id x : i32
    %1 = arith.muli %0, %arg2 : i32
    %2 = arith.index_cast %1 : i32 to index
    %3 = arith.extsi %1 : i32 to i64
    %4 = arith.addi %c0_i64, %3 : i64
    %5:3 = scf.for %arg5 = %c0 to %c12 step %c3 iter_args(%arg6 = %4, %arg7 = %2, %arg8 = %cst) -> (i64, index, tensor<1024xf32>) {
      %9 = tts.make_tptr %arg1 to sizes: [1024], strides: [1], offsets: [%arg7], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
      %10 = "tts.load"(%9) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
      %11 = math.exp %10 : tensor<1024xf32>
      %12 = arith.addf %arg8, %11 : tensor<1024xf32>
      %13 = arith.index_cast %arg5 : index to i32
      %14 = arith.addi %arg7, %arg5 : index
      %15 = arith.extsi %13 : i32 to i64
      %16 = arith.addi %arg6, %15 : i64
      scf.yield %16, %14, %12 : i64, index, tensor<1024xf32>
    }
    %6 = arith.muli %0, %arg3 : i32
    %7 = arith.index_cast %6 : i32 to index
    %8 = tts.make_tptr %arg0 to sizes: [1024], strides: [1], offsets: [%7], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    "tts.store"(%8, %5#2) <{static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>, tensor<1024xf32>) -> ()
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir:50:11: error: CHECK: expected string not found in input
// CHECK: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_1_]] to offset: {{.}}[[VAR_3_]]{{.}}, sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
          ^
<stdin>:11:41: note: scanning from here
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:11:41: note: with "PARAM_1_" equal to "%arg1"
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:11:41: note: with "VAR_3_" equal to "%3"
 %3 = arith.index_cast %2 : i32 to index
                                        ^
<stdin>:36:18: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%7], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1], offset: ?>>
                 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            .
            .
            .
            6:  %c3 = arith.constant 3 : index 
            7:  %cst = arith.constant 0.000000e+00 : f32 
            8:  %0 = tensor.empty() : tensor<1024xf32> 
            9:  %1 = linalg.fill ins(%cst : f32) outs(%0 : tensor<1024xf32>) -> tensor<1024xf32> 
           10:  %2 = arith.muli %arg8, %arg2 : i32 
           11:  %3 = arith.index_cast %2 : i32 to index 
check:50'0                                             X error: no match found
check:50'1                                               with "PARAM_1_" equal to "%arg1"
check:50'2                                               with "VAR_3_" equal to "%3"
           12:  %4 = arith.extsi %2 : i32 to i64 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           13:  %5:3 = scf.for %arg11 = %c0 to %c12 step %c3 iter_args(%arg12 = %4, %arg13 = %3, %arg14 = %1) -> (i64, index, tensor<1024xf32>) { 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           14:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%arg13], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1], offset: ?>> 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           15:  %alloc = memref.alloc() : memref<1024xf32> 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           16:  memref.copy %reinterpret_cast_0, %alloc : memref<1024xf32, strided<[1], offset: ?>> to memref<1024xf32> 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            .
            .
            .
           31:  %14 = arith.addi %arg12, %13 : i64 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           32:  scf.yield %14, %12, %10 : i64, index, tensor<1024xf32> 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           33:  } 
check:50'0     ~~~
           34:  %6 = arith.muli %arg8, %arg3 : i32 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           35:  %7 = arith.index_cast %6 : i32 to index 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           36:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%7], sizes: [1024], strides: [1] : memref<*xf32> to memref<1024xf32, strided<[1], offset: ?>> 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:50'3                      ?                                                                                                                                            possible intended match
           37:  bufferization.materialize_in_destination %5#2 in writable %reinterpret_cast : (tensor<1024xf32>, memref<1024xf32, strided<[1], offset: ?>>) -> () 
check:50'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           38:  return 
check:50'0     ~~~~~~~~
           39:  } 
check:50'0     ~~~
           40: } 
check:50'0     ~~
           41:  
check:50'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_middle_dim.mlir (73 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_middle_dim.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %out, %5 : tensor<32x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: note: see current operation: tt.store %arg2, %19 : tensor<32x16x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %out, %5 : tensor<32x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: note: see current operation: tt.store %arg2, %19 : tensor<32x16x!tt.ptr<bf16>>
module {
  tt.func @kernel(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: tensor<32x16x!tt.ptr<bf16>>) {
    %c256 = arith.constant 256 : index
    %0 = tts.make_tptr %arg0 to sizes: [32, 256, 16], strides: [%c256, 1, 1], offsets: [0, 0, 0], shape: [0, 0, 0], order: [] : <bf16> to tensor<32x256x16x!tt.ptr<bf16>>
    %1 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<32x256x16x!tt.ptr<bf16>>) -> tensor<32x256x16xbf16>
    %2 = "tt.reduce"(%1) <{axis = 1 : i32}> ({
    ^bb0(%arg3: bf16, %arg4: bf16):
      %3 = arith.addf %arg3, %arg4 : bf16
      tt.reduce.return %3 : bf16
    }) : (tensor<32x256x16xbf16>) -> tensor<32x16xbf16>
    tt.store %arg2, %2 : tensor<32x16x!tt.ptr<bf16>>
    tt.return
  }
}
PLEASE submit a bug report to https://github.com/llvm/llvm-project/issues/ and include the crash backtrace.
Stack dump:
0.	Program arguments: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir
 #0 0x000055ffeca75317 llvm::sys::PrintStackTrace(llvm::raw_ostream&, int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x255c317)
 #1 0x000055ffeca72e3e llvm::sys::RunSignalHandlers() (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2559e3e)
 #2 0x000055ffeca759cf SignalHandler(int) Signals.cpp:0:0
 #3 0x00007f9d8fa59420 __restore_rt (/lib/x86_64-linux-gnu/libpthread.so.0+0x14420)
 #4 0x000055ffeaabe024 mlir::Operation::getResults() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:411:12
 #5 0x000055ffeaabe024 mlir::Operation::getResultTypes() /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/IR/Operation.h:423:47
 #6 0x000055ffeaabe024 (anonymous namespace)::StoreOpConverter::matchAndRewrite(mlir::triton::StoreOp, mlir::triton::StoreOpAdaptor, mlir::ConversionPatternRewriter&) const /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:306:24
 #7 0x000055ffea9d981f mlir::OpConversionPattern<mlir::triton::StoreOp>::matchAndRewrite(mlir::Operation*, llvm::ArrayRef<mlir::Value>, mlir::ConversionPatternRewriter&) const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/mlir/Transforms/DialectConversion.h:545:3
 #8 0x000055ffec685210 mlir::ConversionPattern::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&) const (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c210)
 #9 0x000055ffec6ca03b mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>)::$_2::operator()() const PatternApplicator.cpp:0:0
#10 0x000055ffec6c6bbf mlir::PatternApplicator::matchAndRewrite(mlir::Operation*, mlir::PatternRewriter&, llvm::function_ref<bool (mlir::Pattern const&)>, llvm::function_ref<void (mlir::Pattern const&)>, llvm::function_ref<llvm::LogicalResult (mlir::Pattern const&)>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x21adbbf)
#11 0x000055ffec6861a1 (anonymous namespace)::OperationLegalizer::legalize(mlir::Operation*, mlir::ConversionPatternRewriter&) DialectConversion.cpp:0:0
#12 0x000055ffec6852b4 mlir::OperationConverter::convert(mlir::ConversionPatternRewriter&, mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216c2b4)
#13 0x000055ffec6866bf mlir::OperationConverter::convertOperations(llvm::ArrayRef<mlir::Operation*>) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x216d6bf)
#14 0x000055ffec68cdfb mlir::applyPartialConversion(mlir::Operation*, mlir::ConversionTarget const&, mlir::FrozenRewritePatternSet const&, mlir::ConversionConfig) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x2173dfb)
#15 0x000055ffeaabc7ed (anonymous namespace)::TritonLoadStoreToMemrefPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonLoadStoreToMemref/TritonLoadStoreToMemrefPass.cpp:410:16
#16 0x000055ffebfdfd86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#17 0x000055ffebfe0530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#18 0x000055ffebfe4a7f llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (mlir::OpPassManager&, mlir::Operation*)>::callback_fn<mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int)::$_6>(long, mlir::OpPassManager&, mlir::Operation*) Pass.cpp:0:0
#19 0x000055ffeaa9aac5 llvm::LogicalResult::failed() const /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:43:43
#20 0x000055ffeaa9aac5 llvm::failed(llvm::LogicalResult) /home/nhat/.triton/llvm/llvm-c08c6a71-ubuntu-x64/include/llvm/Support/LogicalResult.h:71:58
#21 0x000055ffeaa9aac5 (anonymous namespace)::TritonToLinalgExperimentalPass::runOnOperation() /home/nhat/github/triton_shared/lib/Conversion/TritonToLinalgExperimental/TritonToLinalgExperimentalPass.cpp:63:9
#22 0x000055ffebfdfd86 mlir::detail::OpToOpPassAdaptor::run(mlir::Pass*, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac6d86)
#23 0x000055ffebfe0530 mlir::detail::OpToOpPassAdaptor::runPipeline(mlir::OpPassManager&, mlir::Operation*, mlir::AnalysisManager, bool, unsigned int, mlir::PassInstrumentor*, mlir::PassInstrumentation::PipelineParentInfo const*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac7530)
#24 0x000055ffebfe29e5 mlir::PassManager::run(mlir::Operation*) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1ac99e5)
#25 0x000055ffebfdc0bf performActions(llvm::raw_ostream&, std::shared_ptr<llvm::SourceMgr> const&, mlir::MLIRContext*, mlir::MlirOptMainConfig const&) MlirOptMain.cpp:0:0
#26 0x000055ffebfdbced llvm::LogicalResult llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>::callback_fn<mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&)::$_2>(long, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&) MlirOptMain.cpp:0:0
#27 0x000055ffeca089c4 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef)::$_0::operator()(llvm::StringRef) const ToolUtilities.cpp:0:0
#28 0x000055ffeca085a0 mlir::splitAndProcessBuffer(std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::function_ref<llvm::LogicalResult (std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, llvm::raw_ostream&)>, llvm::raw_ostream&, llvm::StringRef, llvm::StringRef) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x24ef5a0)
#29 0x000055ffebfd6b11 mlir::MlirOptMain(llvm::raw_ostream&, std::unique_ptr<llvm::MemoryBuffer, std::default_delete<llvm::MemoryBuffer>>, mlir::DialectRegistry&, mlir::MlirOptMainConfig const&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abdb11)
#30 0x000055ffebfd6dc3 mlir::MlirOptMain(int, char**, llvm::StringRef, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abddc3)
#31 0x000055ffebfd7196 mlir::MlirOptMain(int, char**, llvm::StringRef, mlir::DialectRegistry&) (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x1abe196)
#32 0x000055ffeaae87eb main /home/nhat/github/triton_shared/tools/triton-shared-opt/triton-shared-opt.cpp:16:33
#33 0x00007f9d8f4fd083 __libc_start_main /build/glibc-LcI20x/glibc-2.31/csu/../csu/libc-start.c:342:3
#34 0x000055ffea7ab92e _start (/home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt+0x29292e)
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir

--

********************
XFAIL: TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_unsupported_add_offset.mlir (74 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/ridiculously_nested_loops.mlir (75 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/nested_loops.mlir (76 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_extern_elementwise.mlir (77 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/wraparound_unsupported_add_offset.mlir (78 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/triton-to-structured-prepass.mlir (79 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_extern_elementwise.mlir (80 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-05-layer-norm-fwd.mlir (81 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_bf16_axis0.mlir (82 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/cumsum.mlir (83 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/block_ptr_advance.mlir (84 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-03-matrix-multiplication.mlir (85 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/masked_ldst_1d.mlir (86 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/wraparound_side_by_side.mlir (87 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_loopback.mlir (88 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-05-layer-norm-dwdb.mlir (89 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_nested.mlir (90 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_mul_value_const.mlir (91 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_splat_float.mlir (92 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_1d_elemwise_arith_unary.mlir (93 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_loopback.mlir (94 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_1d_elemwise_arith_ternary.mlir (95 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_1d_elemwise_arith_ternary.mlir (96 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_argmin_argmax_2d.mlir (97 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_splat_float.mlir (98 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_broadcast.mlir (99 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_bf16_axis0.mlir (100 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_f32_axis1.mlir (101 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/use_mid_chain.mlir (102 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_loopback.mlir (103 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_f32_axis0.mlir (104 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/early_return.mlir (105 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_2d_elemwise_arith_unary.mlir (106 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_more_init_args.mlir (107 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/dot.mlir (108 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/wraparound_stacked.mlir (109 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reduce_extend_fp32_precision.mlir (110 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_splat_2d.mlir (111 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterargs_not_used_ptranalysis_prepass.mlir (112 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_argmin_argmax.mlir (113 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/unsupported_extern_elementwise.mlir (114 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/make_tensor_ptr_ordering_error.mlir (115 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_tensor_reshape.mlir (116 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_mul_const_const.mlir (117 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_reshape_broadcast.mlir (118 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/unsupported_extern_elementwise.mlir (119 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_2d_elemwise_arith_ternary.mlir (120 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-03-matrix-multiplication.mlir (121 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducemax_32_256_bf16.mlir (122 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_argmin_argmax_2d.mlir (123 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/bitcast.mlir (124 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-01-vector-add.mlir (125 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_tensor_reshape.mlir (126 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_minmax_reduce.mlir (127 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_2d_elemwise_arith_binary.mlir (128 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/use_dot_opc.mlir (129 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_add_value.mlir (130 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_argmin_argmax.mlir (131 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/triton_assert.mlir (132 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_for_2d.mlir (133 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/wraparound_stacked.mlir (134 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_used_before_update.mlir (135 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-05-layer-norm-dwdb.mlir (136 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_nested.mlir (137 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_minmax_fp_reduce.mlir (138 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_2d_elemwise_arith_unary.mlir (139 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-05-layer-norm-fwd.mlir (140 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterarg_with_masks.mlir (141 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/get_num_programs.mlir (142 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/dot.mlir (143 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducemax_32_256_bf16.mlir (144 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_minmax_fp_reduce.mlir (145 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_scalar.mlir (146 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_scalar.mlir (147 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_2d_elemwise_arith_ternary.mlir (148 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-02-fused-softmax.mlir (149 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/cumsum.mlir (150 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_1d_elemwise_arith_unary.mlir (151 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_reshape_broadcast.mlir (152 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_middle_dim.mlir (153 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_minmax.mlir (154 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/use_end_chain.mlir (155 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_for.mlir (156 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_f32_axis0.mlir (157 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_middle_dim.mlir (158 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_used_before_update.mlir (159 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/block_ptr_advance.mlir (160 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_used_after_update.mlir (161 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_2d_elemwise_arith_binary.mlir (162 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/bitcast.mlir (163 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/triton_assert.mlir (164 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_broadcast.mlir (165 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_used_after_update.mlir (166 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/use_mid_chain.mlir (167 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/sign_extend_i32_to_i64.mlir (168 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/triton_assert.mlir (169 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_1d_elemwise_arith_binary.mlir (170 of 215)
XFAIL: TRITON-SHARED :: Conversion/TritonToLinalg/wraparound_unsupported_add_offset.mlir (171 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_for.mlir (172 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_loopback.mlir (173 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_accumulation.mlir (174 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/masked_ldst_sitofp_other.mlir (175 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_nested.mlir (176 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_accumulation.mlir (177 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_minmax_reduce.mlir (178 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_splat.mlir (179 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_mul_value_const.mlir (180 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-01-vector-add.mlir (181 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_expand_ptr.mlir (182 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_nested.mlir (183 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/masked_ldst_2d.mlir (184 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterargs_not_used_ptranalysis_e2e.mlir (185 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/use_dot_opc.mlir (186 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/use_end_chain.mlir (187 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_addi_reduce.mlir (188 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_bf16_axis1.mlir (189 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/bitcast.mlir (190 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_expand_ptr.mlir (191 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_bf16_axis1.mlir (192 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_splat_2d.mlir (193 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_for_2d.mlir (194 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/wraparound_side_by_side.mlir (195 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/arith_not_ptr_arith.mlir (196 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_splat.mlir (197 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_f32_axis1.mlir (198 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/arith_not_ptr_arith.mlir (199 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_dim1.mlir (200 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_more_init_args.mlir (201 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_2d_example.mlir (202 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/masked_ldst_sitofp_other.mlir (203 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_mul_const_const.mlir (204 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/masked_ldst_2d.mlir (205 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_1d_elemwise_arith_binary.mlir (206 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/block_ptr_advance.mlir (207 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/dot.mlir (208 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-02-fused-softmax.mlir (209 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/masked_ldst_1d.mlir (210 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_addi_reduce.mlir (211 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterargs_nested.mlir (212 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_add_value.mlir (213 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_2d_example.mlir (214 of 215)
XFAIL: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_dim1.mlir (215 of 215)
********************
Failed Tests (27):
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_chain.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_addi_reduce.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_reduce.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_splat_float.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/nested_loops.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_middle_dim.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_scalar.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/ridiculously_nested_loops.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_side_by_side.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_stacked.mlir


Testing Time: 1.72s

Total Discovered Tests: 215
  Passed           : 185 (86.05%)
  Expectedly Failed:   3 (1.40%)
  Failed           :  27 (12.56%)
