-- Testing: 215 tests, 16 workers --
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir (1 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %c, %res0 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: note: see current operation: tt.store %arg2, %15 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %c, %res0 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: note: see current operation: tt.store %arg2, %15 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %d, %res1 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: note: see current operation: tt.store %arg3, %16 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %d, %res1 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :28:9: note: see current operation: tt.store %arg3, %16 : tensor<128x128x!tt.ptr<f32>>
processing val
%3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%1, %8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %9) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: tensor<128x128x!tt.ptr<f32>>, %arg3: tensor<128x128x!tt.ptr<f32>>) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c0_i32_2 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %1 = tts.make_tptr %arg1 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %2 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %3 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %4 = arith.addf %2, %3 : tensor<128x128xf32>
    %5 = arith.subf %2, %3 : tensor<128x128xf32>
    %6 = "tts.create_ptr"(%arg2, %c0_i32_0) : (tensor<128x128x!tt.ptr<f32>>, i32) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %6, %4 : tensor<128x128x!tt.ptr<f32>>
    %7 = "tts.create_ptr"(%arg3, %c0_i32) : (tensor<128x128x!tt.ptr<f32>>, i32) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %7, %5 : tensor<128x128x!tt.ptr<f32>>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: error: failed to legalize operation 'tt.store' that was explicitly marked illegal
        tt.store %c, %res0 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir:1 offset :27:9: note: see current operation: "tt.store"(%13, %11) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xf32>) -> ()
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_side_by_side.mlir (2 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_side_by_side.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir
processing val
%c0_i32_0 = arith.constant 0 : i32
processing val
%c0_i32 = arith.constant 0 : i32
for op
%1 = arith.muli %0, %c2 : index
%c0 = arith.constant 0 : index
module {
  tt.func public @wrap_side_by_side_masked_loop_01234567(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %cst = arith.constant -9.900000e+01 : f32
    %c0 = arith.constant 0 : index
    %c6 = arith.constant 6 : index
    %c2 = arith.constant 2 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %c4_i32 = arith.constant 4 : i32
    %0 = arith.index_cast %arg4 : i32 to index
    %1 = arith.muli %0, %c2 : index
    %2 = arith.index_cast %arg3 : i32 to index
    %3 = arith.index_cast %arg5 : i32 to index
    %4 = arith.muli %3, %c6 : index
    %5 = arith.muli %2, %3 : index
    %6 = arith.index_cast %arg6 : i32 to index
    %7 = arith.index_cast %arg7 : i32 to index
    %8 = arith.muli %arg4, %c4_i32 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10 = arith.muli %arg5, %c4_i32 : i32
    %11 = arith.index_cast %10 : i32 to index
    %12:2 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %1, %arg10 = %c0) -> (index, index)  : i32 {
      %13 = tts.make_tptr %arg1 to sizes: [4, 4], strides: [%6, %7], offsets: [%arg10, %c0], shape: [0, 0], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %14 = tts.make_tptr %arg0 to sizes: [4, 4], strides: [%0, %3], offsets: [%arg9, %4], shape: [0, %5], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %15 = "tts.load"(%14, %cst) <{operandSegmentSizes = array<i32: 1, 0, 1>, static_mask_dims = array<i64: 2, 4>}> : (tensor<4x4x!tt.ptr<f32>>, f32) -> tensor<4x4xf32>
      "tts.store"(%13, %15) <{static_mask_dims = array<i64>}> : (tensor<4x4x!tt.ptr<f32>>, tensor<4x4xf32>) -> ()
      %16 = arith.addi %arg9, %9 : index
      %17 = arith.addi %arg10, %11 : index
      scf.yield %16, %17 : index, index
    }
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir:1 offset :46:13: error: failed to legalize operation 'tts.make_tptr' that was explicitly marked illegal
    %33:2 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %15, %arg10 = %26) -> (tensor<4x4x!tt.ptr<f32>>, tensor<4x4x!tt.ptr<f32>>)  : i32 {
            ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir:1 offset :46:13: note: see current operation: %26 = "tts.make_tptr"(%1, %10, %13, %arg15, %14, %15) <{operandSegmentSizes = array<i32: 1, 2, 2, 1>, order = array<i32>, sizes = array<i64: 4, 4>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, -9223372036854775808>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index, index) -> tensor<4x4x!tt.ptr<f32>>
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_side_by_side.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir (3 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save0, %5 : tensor<1024x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save0, %5 : tensor<1024x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save1, %6 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: note: see current operation: tt.store %arg4, %14 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save1, %6 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :33:5: note: see current operation: tt.store %arg4, %14 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save2, %7 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: note: see current operation: tt.store %arg5, %15 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save2, %7 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :34:5: note: see current operation: tt.store %arg5, %15 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save3, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: note: see current operation: tt.store %arg6, %16 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save3, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :35:5: note: see current operation: tt.store %arg6, %16 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save4, %11 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: note: see current operation: tt.store %arg7, %17 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save4, %11 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :36:5: note: see current operation: tt.store %arg7, %17 : tensor<1024x!tt.ptr<f32>>
processing val
%7 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%5 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%4 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%4, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<1024xbf16>) -> ()
tensor<1024x!tt.ptr<bf16>>
processing val
%3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%3, %15) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
processing val
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%2, %16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%1, %17) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<i32>, %arg2: !tt.ptr<f16>, %arg3: tensor<1024x!tt.ptr<bf16>>, %arg4: tensor<1024x!tt.ptr<f32>>, %arg5: tensor<1024x!tt.ptr<f32>>, %arg6: tensor<1024x!tt.ptr<f32>>, %arg7: tensor<1024x!tt.ptr<f32>>) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c0_i32_2 = arith.constant 0 : i32
    %c0_i32_3 = arith.constant 0 : i32
    %c0_i32_4 = arith.constant 0 : i32
    %c0_i32_5 = arith.constant 0 : i32
    %c0_i32_6 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %1 = tts.make_tptr %arg1 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <i32> to tensor<1024x!tt.ptr<i32>>
    %2 = tts.make_tptr %arg2 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f16> to tensor<1024x!tt.ptr<f16>>
    %3 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %4 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<i32>>) -> tensor<1024xi32>
    %5 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f16>>) -> tensor<1024xf16>
    %6 = arith.truncf %3 : tensor<1024xf32> to tensor<1024xbf16>
    %7 = math.exp %3 : tensor<1024xf32>
    %8 = arith.sitofp %4 : tensor<1024xi32> to tensor<1024xf32>
    %9 = arith.extf %5 : tensor<1024xf16> to tensor<1024xf32>
    %10 = math.sqrt %3 : tensor<1024xf32>
    %11 = "tts.create_ptr"(%arg3, %c0_i32_3) : (tensor<1024x!tt.ptr<bf16>>, i32) -> tensor<1024x!tt.ptr<bf16>>
    tt.store %11, %6 : tensor<1024x!tt.ptr<bf16>>
    %12 = "tts.create_ptr"(%arg4, %c0_i32_2) : (tensor<1024x!tt.ptr<f32>>, i32) -> tensor<1024x!tt.ptr<f32>>
    tt.store %12, %7 : tensor<1024x!tt.ptr<f32>>
    %13 = "tts.create_ptr"(%arg5, %c0_i32_1) : (tensor<1024x!tt.ptr<f32>>, i32) -> tensor<1024x!tt.ptr<f32>>
    tt.store %13, %8 : tensor<1024x!tt.ptr<f32>>
    %14 = "tts.create_ptr"(%arg6, %c0_i32_0) : (tensor<1024x!tt.ptr<f32>>, i32) -> tensor<1024x!tt.ptr<f32>>
    tt.store %14, %9 : tensor<1024x!tt.ptr<f32>>
    %15 = "tts.create_ptr"(%arg7, %c0_i32) : (tensor<1024x!tt.ptr<f32>>, i32) -> tensor<1024x!tt.ptr<f32>>
    tt.store %15, %10 : tensor<1024x!tt.ptr<f32>>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: error: failed to legalize operation 'tt.store' that was explicitly marked illegal
    tt.store %save0, %5 : tensor<1024x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir:1 offset :32:5: note: see current operation: "tt.store"(%26, %19) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024x!tt.ptr<bf16>>, tensor<1024xbf16>) -> ()
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir (4 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %res, %6 : tensor<256x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: note: see current operation: tt.store %arg1, %19 : tensor<256x16x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %res, %6 : tensor<256x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: note: see current operation: tt.store %arg1, %19 : tensor<256x16x!tt.ptr<bf16>>
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %5) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<256x16xbf16>) -> ()
tensor<256x16x!tt.ptr<bf16>>
module {
  tt.func @kernel(%arg0: !tt.ptr<bf16>, %arg1: tensor<256x16x!tt.ptr<bf16>>) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c256 = arith.constant 256 : index
    %0 = tts.make_tptr %arg0 to sizes: [32, 256, 16], strides: [%c256, 1, 1], offsets: [0, 0, 0], shape: [0, 0, 0], order: [] : <bf16> to tensor<32x256x16x!tt.ptr<bf16>>
    %1 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<32x256x16x!tt.ptr<bf16>>) -> tensor<32x256x16xbf16>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg2: bf16, %arg3: bf16):
      %4 = arith.cmpf ogt, %arg2, %arg3 : bf16
      %5 = arith.select %4, %arg2, %arg3 : bf16
      tt.reduce.return %5 : bf16
    }) : (tensor<32x256x16xbf16>) -> tensor<256x16xbf16>
    %3 = "tts.create_ptr"(%arg1, %c0_i32) : (tensor<256x16x!tt.ptr<bf16>>, i32) -> tensor<256x16x!tt.ptr<bf16>>
    tt.store %3, %2 : tensor<256x16x!tt.ptr<bf16>>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: error: failed to legalize operation 'tt.store' that was explicitly marked illegal
    tt.store %res, %6 : tensor<256x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir:1 offset :37:5: note: see current operation: "tt.store"(%11, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<256x16x!tt.ptr<bf16>>, tensor<256x16xbf16>) -> ()
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop.mlir (5 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir:20:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[CST_0_:%.+]] = arith.constant 0 : index
              ^
<stdin>:2:232: note: scanning from here
 func.func @reduce_kernel_2d_0d(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
                                                                                                                                                                                                                                       ^
<stdin>:5:4: note: possible intended match here
 %c0_i32 = arith.constant 0 : i32
   ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @reduce_kernel_2d_0d(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) { 
dag:20'0                                                                                                                                                                                                                                            X error: no match found
          3:  %0 = builtin.unrealized_conversion_cast %arg0 : memref<*xf32> to !tt.ptr<f32> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c8_i32 = arith.constant 8 : i32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %c0_i32 = arith.constant 0 : i32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:20'1        ?                               possible intended match
          6:  %c1_i32 = arith.constant 1 : i32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %1 = scf.for %arg13 = %c0_i32 to %c8_i32 step %c1_i32 iter_args(%arg14 = %0) -> (!tt.ptr<f32>) : i32 { 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          8:  %2 = arith.sitofp %arg13 : i32 to f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          9:  tt.store %arg14, %2 : !tt.ptr<f32> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         10:  %3 = tt.addptr %arg14, %c1_i32 : !tt.ptr<f32>, i32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_loopback.mlir (6 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_loopback.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: remark: PtrAnalysis: scalar loadOp will not be rewritten
    %10 = tt.load %0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false}: !tt.ptr<bf16>
          ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: note: see current operation: %4 = tt.load %1 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: remark: PtrAnalysis: Failed to rewrite LoadOp
    %10 = tt.load %0 {cache = 1 : i32, evict = 1 : i32, isVolatile = false}: !tt.ptr<bf16>
          ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :11:11: note: see current operation: %4 = tt.load %1 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: remark: PtrAnalysis: scalar storeOp will not be rewritten
    tt.store %1, %10 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: note: see current operation: tt.store %3, %4 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %1, %10 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:1 offset :12:5: note: see current operation: tt.store %3, %4 : !tt.ptr<bf16>
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
%2 = "tt.addptr"(%1, %arg2) : (i32, i32) -> !tt.ptr<bf16>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
%3 = "tt.addptr"(%0, %arg2) : (i32, i32) -> !tt.ptr<bf16>
processing val
%2 = "arith.addi"(%1, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
processing user
%4 = "tt.load"(%2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (i32) -> bf16
!tt.ptr<bf16>
processing val
%3 = "arith.addi"(%0, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
processing user
"tt.store"(%3, %5) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, bf16) -> ()
!tt.ptr<bf16>
module {
  tt.func @kernel(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: i32) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %0 = arith.addi %c0_i32_0, %arg2 : i32
    %1 = arith.addi %c0_i32, %arg2 : i32
    %2 = "tts.create_ptr"(%arg0, %0) : (!tt.ptr<bf16>, i32) -> !tt.ptr<bf16>
    %3 = tt.load %2 : !tt.ptr<bf16>
    %4 = "tts.create_ptr"(%arg1, %1) : (!tt.ptr<bf16>, i32) -> !tt.ptr<bf16>
    tt.store %4, %3 : !tt.ptr<bf16>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir:22:11: error: CHECK: expected string not found in input
// CHECK: [[LOAD_VAR_reinterpret_cast_MEM_:%.+]] = affine.load [[VAR_reinterpret_cast_]][0] : memref<1xbf16, strided<[1], offset: ?>>
          ^
<stdin>:6:155: note: scanning from here
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
                                                                                                                                                          ^
<stdin>:6:155: note: with "VAR_reinterpret_cast_" equal to "%reinterpret_cast"
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
                                                                                                                                                          ^
<stdin>:7:19: note: possible intended match here
 affine.store %1, %reinterpret_cast_0[0] : memref<1xbf16, strided<[1], offset: ?>>
                  ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_loopback.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            1: module { 
            2:  func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
            3:  %0 = arith.index_cast %arg2 : i32 to index 
            4:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>> 
            5:  %1 = affine.load %reinterpret_cast[0] : memref<1xbf16, strided<[1], offset: ?>> 
            6:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>> 
check:22'0                                                                                                                                                               X error: no match found
check:22'1                                                                                                                                                                 with "VAR_reinterpret_cast_" equal to "%reinterpret_cast"
            7:  affine.store %1, %reinterpret_cast_0[0] : memref<1xbf16, strided<[1], offset: ?>> 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:22'2                       ?                                                                 possible intended match
            8:  return 
check:22'0     ~~~~~~~~
            9:  } 
check:22'0     ~~~
           10: } 
check:22'0     ~~
           11:  
check:22'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_chain.mlir (7 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_chain.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: remark: PtrAnalysis: scalar loadOp will not be rewritten
      %6 = tt.load %2 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: note: see current operation: %16 = tt.load %8 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: remark: PtrAnalysis: Failed to rewrite LoadOp
      %6 = tt.load %2 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :16:12: note: see current operation: %16 = tt.load %8 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: remark: PtrAnalysis: scalar loadOp will not be rewritten
      %7 = tt.load %3 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: note: see current operation: %17 = tt.load %10 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: remark: PtrAnalysis: Failed to rewrite LoadOp
      %7 = tt.load %3 : !tt.ptr<f32>
           ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :17:12: note: see current operation: %17 = tt.load %10 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: remark: PtrAnalysis: scalar storeOp will not be rewritten
      tt.store %4, %6 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: note: see current operation: tt.store %13, %16 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: remark: PtrAnalysis: Failed to rewrite StoreOp
      tt.store %4, %6 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :18:7: note: see current operation: tt.store %13, %16 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: remark: PtrAnalysis: scalar storeOp will not be rewritten
      tt.store %5, %7 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: note: see current operation: tt.store %15, %17 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: remark: PtrAnalysis: Failed to rewrite StoreOp
      tt.store %5, %7 : !tt.ptr<f32>
      ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:1 offset :19:7: note: see current operation: tt.store %15, %17 : !tt.ptr<f32>
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
%6 = "tt.addptr"(%1, %5) : (i32, i32) -> !tt.ptr<f32>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
%7 = "tt.addptr"(%0, %5) : (i32, i32) -> !tt.ptr<f32>
processing val
%6 = "arith.addi"(%1, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
processing user
%8 = "tt.addptr"(%6, %arg2) : (i32, i32) -> !tt.ptr<f32>
processing val
%7 = "arith.addi"(%0, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
processing user
%10 = "tt.addptr"(%7, %arg2) : (i32, i32) -> !tt.ptr<f32>
processing val
%8 = "arith.addi"(%6, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
processing user
%9 = "tt.addptr"(%8, %5) : (i32, i32) -> !tt.ptr<f32>
processing user
%12 = "tt.load"(%8) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (i32) -> f32
!tt.ptr<f32>
processing val
%10 = "arith.addi"(%7, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
processing user
%11 = "tt.addptr"(%10, %5) : (i32, i32) -> !tt.ptr<f32>
processing user
"tt.store"(%10, %13) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
processing val
%9 = "arith.addi"(%8, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
processing user
%14 = "tt.load"(%9) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32, isVolatile = false, operandSegmentSizes = array<i32: 1, 0, 0>}> : (i32) -> f32
!tt.ptr<f32>
processing val
%11 = "arith.addi"(%10, %5) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
processing user
"tt.store"(%11, %15) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
for op
module {
  tt.func public @addptr(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %c10_i32 = arith.constant 10 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c1_i32 = arith.constant 1 : i32
    %0 = arith.addi %c0_i32_0, %c1_i32 : i32
    %1 = arith.addi %c0_i32, %c1_i32 : i32
    scf.for %arg2 = %c0_i32_1 to %c10_i32 step %c2_i32  : i32 {
      %2 = arith.addi %0, %arg2 : i32
      %3 = arith.addi %2, %c1_i32 : i32
      %4 = arith.addi %1, %arg2 : i32
      %5 = arith.addi %4, %c1_i32 : i32
      %6 = "tts.create_ptr"(%arg0, %2) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %7 = tt.load %6 : !tt.ptr<f32>
      %8 = "tts.create_ptr"(%arg0, %3) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %9 = tt.load %8 : !tt.ptr<f32>
      %10 = "tts.create_ptr"(%arg1, %4) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      tt.store %10, %7 : !tt.ptr<f32>
      %11 = "tts.create_ptr"(%arg1, %5) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      tt.store %11, %9 : !tt.ptr<f32>
    }
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir:27:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: %c2 = arith.constant 2 : index
              ^
<stdin>:2:137: note: scanning from here
 func.func @addptr(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
                                                                                                                                        ^
<stdin>:5:6: note: possible intended match here
 %c2_i32 = arith.constant 2 : i32
     ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_chain.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @addptr(%arg0: memref<*xf32>, %arg1: memref<*xf32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) { 
dag:27'0                                                                                                                                             X error: no match found
          3:  %c1_i32 = arith.constant 1 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c10_i32 = arith.constant 10 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %c2_i32 = arith.constant 2 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:27'1          ?                             possible intended match
          6:  %c0_i32 = arith.constant 0 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  scf.for %arg8 = %c0_i32 to %c10_i32 step %c2_i32 : i32 { 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          8:  %0 = arith.addi %arg8, %c1_i32 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          9:  %1 = arith.addi %arg8, %c2_i32 : i32 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         10:  %2 = arith.index_cast %0 : i32 to index 
dag:27'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir (8 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir:23:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_0_:%.+]] = arith.index_cast [[PARAM_7_]] : i32 to index
              ^
<stdin>:2:440: note: scanning from here
 func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) {
                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
<stdin>:2:440: note: with "PARAM_7_" equal to "%arg13"
 func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) {
                                                                                                                                                                                                                                                                                                                                                                                                                                                       ^
<stdin>:8:2: note: possible intended match here
 %2 = arith.sitofp %arg7 : i32 to f32
 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @reduce_kernel_2d_0d1d2de3de(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: memref<*xf32> {tt.divisibility = 16 : i32}, %arg2: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg3: i32 {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32, %arg13: i32, %arg14: i32, %arg15: i32) { 
dag:23'0                                                                                                                                                                                                                                                                                                                                                                                                                                                            X error: no match found
dag:23'1                                                                                                                                                                                                                                                                                                                                                                                                                                                              with "PARAM_7_" equal to "%arg13"
          3:  %0 = builtin.unrealized_conversion_cast %arg1 : memref<*xf32> to !tt.ptr<f32> 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c1_i32 = arith.constant 1 : i32 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %c5_i32 = arith.constant 5 : i32 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %c0_i32 = arith.constant 0 : i32 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %1 = tt.addptr %0, %arg7 : !tt.ptr<f32>, i32 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          8:  %2 = arith.sitofp %arg7 : i32 to f32 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:23'2      ?                                     possible intended match
          9:  scf.for %arg16 = %c0_i32 to %c5_i32 step %c1_i32 : i32 { 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         10:  %3 = tt.addptr %1, %arg16 : !tt.ptr<f32>, i32 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         11:  tt.store %3, %2 : !tt.ptr<f32> 
dag:23'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  } 
dag:23'0     ~~~
         13:  return 
dag:23'0     ~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir (9 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save0, %5 : tensor<128x128x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save0, %5 : tensor<128x128x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save1, %6 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: note: see current operation: tt.store %arg4, %20 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save1, %6 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :39:5: note: see current operation: tt.store %arg4, %20 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save2, %7 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: note: see current operation: tt.store %arg5, %21 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save2, %7 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :40:5: note: see current operation: tt.store %arg5, %21 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save3, %10 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: note: see current operation: tt.store %arg6, %22 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save3, %10 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :41:5: note: see current operation: tt.store %arg6, %22 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %save4, %11 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: note: see current operation: tt.store %arg7, %23 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %save4, %11 : tensor<128x128x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :42:5: note: see current operation: tt.store %arg7, %23 : tensor<128x128x!tt.ptr<f32>>
processing val
%7 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%6 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%5 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%4 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%4, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<128x128xbf16>) -> ()
tensor<128x128x!tt.ptr<bf16>>
processing val
%3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%3, %15) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
processing val
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%2, %16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%1, %17) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %18) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<i32>, %arg2: !tt.ptr<f16>, %arg3: tensor<128x128x!tt.ptr<bf16>>, %arg4: tensor<128x128x!tt.ptr<f32>>, %arg5: tensor<128x128x!tt.ptr<f32>>, %arg6: tensor<128x128x!tt.ptr<f32>>, %arg7: tensor<128x128x!tt.ptr<f32>>) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c0_i32_2 = arith.constant 0 : i32
    %c0_i32_3 = arith.constant 0 : i32
    %c0_i32_4 = arith.constant 0 : i32
    %c0_i32_5 = arith.constant 0 : i32
    %c0_i32_6 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %1 = tts.make_tptr %arg1 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <i32> to tensor<128x128x!tt.ptr<i32>>
    %2 = tts.make_tptr %arg2 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f16> to tensor<128x128x!tt.ptr<f16>>
    %3 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %4 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<i32>>) -> tensor<128x128xi32>
    %5 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f16>>) -> tensor<128x128xf16>
    %6 = arith.truncf %3 : tensor<128x128xf32> to tensor<128x128xbf16>
    %7 = math.exp %3 : tensor<128x128xf32>
    %8 = arith.sitofp %4 : tensor<128x128xi32> to tensor<128x128xf32>
    %9 = arith.extf %5 : tensor<128x128xf16> to tensor<128x128xf32>
    %10 = math.sqrt %3 : tensor<128x128xf32>
    %11 = "tts.create_ptr"(%arg3, %c0_i32_3) : (tensor<128x128x!tt.ptr<bf16>>, i32) -> tensor<128x128x!tt.ptr<bf16>>
    tt.store %11, %6 : tensor<128x128x!tt.ptr<bf16>>
    %12 = "tts.create_ptr"(%arg4, %c0_i32_2) : (tensor<128x128x!tt.ptr<f32>>, i32) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %12, %7 : tensor<128x128x!tt.ptr<f32>>
    %13 = "tts.create_ptr"(%arg5, %c0_i32_1) : (tensor<128x128x!tt.ptr<f32>>, i32) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %13, %8 : tensor<128x128x!tt.ptr<f32>>
    %14 = "tts.create_ptr"(%arg6, %c0_i32_0) : (tensor<128x128x!tt.ptr<f32>>, i32) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %14, %9 : tensor<128x128x!tt.ptr<f32>>
    %15 = "tts.create_ptr"(%arg7, %c0_i32) : (tensor<128x128x!tt.ptr<f32>>, i32) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %15, %10 : tensor<128x128x!tt.ptr<f32>>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: error: failed to legalize operation 'tt.store' that was explicitly marked illegal
    tt.store %save0, %5 : tensor<128x128x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir:1 offset :38:5: note: see current operation: "tt.store"(%26, %19) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128x!tt.ptr<bf16>>, tensor<128x128xbf16>) -> ()
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir (10 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
      tt.store %arg11, %2 : !tt.ptr<f32>
      ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: note: see current operation: tt.store %arg11, %3 : !tt.ptr<f32>
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: remark: PtrAnalysis: Failed to rewrite StoreOp
      tt.store %arg11, %2 : !tt.ptr<f32>
      ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:12:7: note: see current operation: tt.store %arg11, %3 : !tt.ptr<f32>
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
%6 = "tt.addptr"(%0, %arg7) : (i32, i32) -> !tt.ptr<f32>
processing val
%6 = "arith.addi"(%0, %arg7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
processing user
%8:3 = "scf.for"(%4, %3, %2, %6, %5, %5) ({
^bb0(%arg10: i32, %arg11: !tt.ptr<f32>, %arg12: index, %arg13: index):
  "tt.store"(%arg11, %7) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
  %9 = "arith.index_cast"(%arg10) : (i32) -> index
  %10 = "arith.addi"(%arg12, %9) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %11 = "tt.addptr"(%arg11, %arg10) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
  %12 = "arith.addi"(%arg13, %9) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  "scf.yield"(%11, %10, %12) : (!tt.ptr<f32>, index, index) -> ()
}) : (i32, i32, i32, i32, index, index) -> (!tt.ptr<f32>, index, index)
arg number: 3
%6 = "arith.addi"(%0, %arg7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
init arg size
3
num region iter-args
3
dump from that index
%6 = "arith.addi"(%0, %arg7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
iter arg
<block argument> of type '!tt.ptr<f32>' at index: 1
init arg
%6 = "arith.addi"(%0, %arg7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%5 = "arith.index_cast"(%arg7) : (i32) -> index
%5 = "arith.index_cast"(%arg7) : (i32) -> index
processing val
<block argument> of type '!tt.ptr<f32>' at index: 1
processing user
"tt.store"(%arg11, %7) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
!tt.ptr<f32>
for op
%6 = "arith.addi"(%0, %arg7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%5 = "arith.index_cast"(%arg7) : (i32) -> index
%5 = "arith.index_cast"(%arg7) : (i32) -> index
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, {tt.divisibility = 16 : i32, tt.max_divisibility = 16 : i32}, {}, {}, {}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32, i32, i32, i32, i32, i32) -> (), sym_name = "reduce_kernel_2d_0d1d2de3de"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 1 : i32}> : () -> i32
    %3 = "arith.constant"() <{value = 5 : i32}> : () -> i32
    %4 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %5 = "arith.index_cast"(%arg7) : (i32) -> index
    %6 = "arith.addi"(%0, %arg7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %7 = "arith.sitofp"(%arg7) : (i32) -> f32
    %8:3 = "scf.for"(%4, %3, %2, %6, %5, %5) ({
    ^bb0(%arg10: i32, %arg11: !tt.ptr<f32>, %arg12: index, %arg13: index):
      %9 = "tts.create_ptr"(%arg1, %arg11) : (!tt.ptr<f32>, !tt.ptr<f32>) -> !tt.ptr<f32>
      "tt.store"(%9, %7) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (!tt.ptr<f32>, f32) -> ()
      %10 = "arith.index_cast"(%arg10) : (i32) -> index
      %11 = "arith.addi"(%arg12, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %12 = "tt.addptr"(%arg11, %arg10) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %13 = "arith.addi"(%arg13, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      "scf.yield"(%12, %11, %13) : (!tt.ptr<f32>, index, index) -> ()
    }) : (i32, i32, i32, i32, index, index) -> (!tt.ptr<f32>, index, index)
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
block count: 1
block arg count: 4
init arg count: 3
reusing type for 0 to
i32
mapping 1 to
i32
%6 = "arith.addi"(%0, %arg7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
reusing type for 2 to
index
reusing type for 3 to
index
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:11:71: error: failed to legalize unresolved materialization from ('i32') to '!tt.ptr<f32>' that remained live after conversion
    %3:2 = scf.for %arg10 = %c0_i32 to %c5_i32 step %c1_i32 iter_args(%arg11 = %1, %arg12 = %0) -> (!tt.ptr<f32>, index)  : i32 {
                                                                      ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:11:71: note: see current operation: %9 = "builtin.unrealized_conversion_cast"(%arg11) : (i32) -> !tt.ptr<f32>
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir:13:12: note: see existing live user here: %13 = "tt.addptr"(%9, %arg10) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %4 = tt.addptr %arg11, %arg10 : !tt.ptr<f32>, i32
           ^
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_scalar.mlir (11 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_scalar.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %res, %3 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: note: see current operation: tt.store %arg1, %5 : !tt.ptr<bf16>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %res, %3 : !tt.ptr<bf16>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:1 offset :14:5: note: see current operation: tt.store %arg1, %5 : !tt.ptr<bf16>
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, bf16) -> ()
!tt.ptr<bf16>
module {
  tt.func @kernel(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [128], strides: [1], offsets: [0], shape: [0], order: [] : <bf16> to tensor<128x!tt.ptr<bf16>>
    %1 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x!tt.ptr<bf16>>) -> tensor<128xbf16>
    %2 = "tt.reduce"(%1) <{axis = 0 : i32}> ({
    ^bb0(%arg2: bf16, %arg3: bf16):
      %4 = arith.addf %arg2, %arg3 : bf16
      tt.reduce.return %4 : bf16
    }) : (tensor<128xbf16>) -> bf16
    %3 = "tts.create_ptr"(%arg1, %c0_i32) : (!tt.ptr<bf16>, i32) -> !tt.ptr<bf16>
    tt.store %3, %2 : !tt.ptr<bf16>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir:22:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_1_]] to offset: [0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
              ^
<stdin>:2:139: note: scanning from here
 func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
                                                                                                                                          ^
<stdin>:2:139: note: with "PARAM_1_" equal to "%arg1"
 func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
                                                                                                                                          ^
<stdin>:19:16: note: possible intended match here
 %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%c0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>>
               ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_scalar.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) { 
dag:22'0                                                                                                                                               X error: no match found
dag:22'1                                                                                                                                                 with "PARAM_1_" equal to "%arg1"
          3:  %c0 = arith.constant 0 : index 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %cst = arith.constant 0.000000e+00 : f32 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [0], sizes: [128], strides: [1] : memref<*xbf16> to memref<128xbf16, strided<[1]>> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %alloc = memref.alloc() : memref<128xbf16> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  memref.copy %reinterpret_cast, %alloc : memref<128xbf16, strided<[1]>> to memref<128xbf16> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         14:  %4 = arith.addf %3, %init : f32 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         15:  linalg.yield %4 : f32 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~
         16:  } 
dag:22'0     ~~~
         17:  %extracted = tensor.extract %reduced[] : tensor<f32> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         18:  %2 = arith.truncf %extracted : f32 to bf16 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         19:  %reinterpret_cast_0 = memref.reinterpret_cast %arg1 to offset: [%c0], sizes: [1], strides: [1] : memref<*xbf16> to memref<1xbf16, strided<[1], offset: ?>> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:22'2                    ?                                                                                                                                             possible intended match
         20:  affine.store %2, %reinterpret_cast_0[0] : memref<1xbf16, strided<[1], offset: ?>> 
dag:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         21:  return 
dag:22'0     ~~~~~~~~
         22:  } 
dag:22'0     ~~~
         23: } 
dag:22'0     ~~
         24:  
dag:22'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_nested_loop.mlir (12 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_nested_loop.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --canonicalize --triton-arith-to-linalg --structured-to-memref /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir:26:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[CST_1_:%.+]] = arith.constant 1 : index
              ^
<stdin>:2:232: note: scanning from here
 func.func @reduce_kernel_2d_0d(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) {
                                                                                                                                                                                                                                       ^
<stdin>:7:4: note: possible intended match here
 %c1_i32 = arith.constant 1 : i32
   ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/scalar_store_nested_loop.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @reduce_kernel_2d_0d(%arg0: memref<*xf32> {tt.divisibility = 16 : i32}, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32, %arg10: i32, %arg11: i32, %arg12: i32) { 
dag:26'0                                                                                                                                                                                                                                            X error: no match found
          3:  %0 = builtin.unrealized_conversion_cast %arg0 : memref<*xf32> to !tt.ptr<f32> 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c2_i32 = arith.constant 2 : i32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %c8_i32 = arith.constant 8 : i32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %c0_i32 = arith.constant 0 : i32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %c1_i32 = arith.constant 1 : i32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:26'1        ?                               possible intended match
          8:  %1 = tt.addptr %0, %arg4 : !tt.ptr<f32>, i32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          9:  %2 = scf.for %arg13 = %c0_i32 to %c8_i32 step %c1_i32 iter_args(%arg14 = %1) -> (!tt.ptr<f32>) : i32 { 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         10:  %3 = scf.for %arg15 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg16 = %arg14) -> (!tt.ptr<f32>) : i32 { 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         11:  %4 = arith.muli %arg13, %arg15 : i32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  %5 = arith.sitofp %4 : i32 to f32 
dag:26'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_addi_reduce.mlir (13 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_addi_reduce.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
!tt.ptr<i32>
module {
  tt.func public @addi(%arg0: !tt.ptr<i32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %2 = arith.addi %arg1, %arg2 : i32
      tt.reduce.return %2 : i32
    }) : (tensor<4096xi32>) -> i32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    tt.store %1, %0 : !tt.ptr<i32>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir:19:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:2:113: note: scanning from here
 func.func @addi(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                ^
<stdin>:2:113: note: with "PARAM_0_" equal to "%arg0"
 func.func @addi(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                ^
<stdin>:15:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_addi_reduce.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @addi(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:19'0                                                                                                                     X error: no match found
dag:19'1                                                                                                                       with "PARAM_0_" equal to "%arg0"
          3:  %c0 = arith.constant 0 : index 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %c0_i32 = arith.constant 0 : i32 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %0 = tensor.empty() : tensor<4096xi32> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %2 = bufferization.alloc_tensor() : tensor<i32> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         10:  (%in: i32, %init: i32) { 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
         11:  %3 = arith.addi %in, %init : i32 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  linalg.yield %3 : i32 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~
         13:  } 
dag:19'0     ~~~
         14:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         15:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:19'2                  ?                                                                                                                                           possible intended match
         16:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:19'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         17:  return 
dag:19'0     ~~~~~~~~
         18:  } 
dag:19'0     ~~~
         19: } 
dag:19'0     ~~
         20:  
dag:19'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_complex_offset.mlir (14 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_complex_offset.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --structured-to-memref --split-input-file /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --structured-to-memref --split-input-file /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir:22:11: error: CHECK: expected string not found in input
// CHECK: %0 = arith.remsi %arg8, %arg3 : i32
          ^
<stdin>:6:36: note: scanning from here
 %c128 = arith.constant 128 : index
                                   ^
<stdin>:7:2: note: possible intended match here
 %1 = arith.remsi %arg8, %arg3 : i32
 ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/block_ptr_complex_offset.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
            1: module { 
            2:  func.func @fused_attention_fwd_kernel(%arg0: memref<*xbf16>, %arg1: memref<*xbf16>, %arg2: i64, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32, %arg9: i32) -> tensor<128x128xbf16> { 
            3:  %0 = builtin.unrealized_conversion_cast %arg0 : memref<*xbf16> to !tt.ptr<bf16> 
            4:  %c1 = arith.constant 1 : index 
            5:  %c0 = arith.constant 0 : index 
            6:  %c128 = arith.constant 128 : index 
check:22'0                                        X error: no match found
            7:  %1 = arith.remsi %arg8, %arg3 : i32 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
check:22'1      ?                                    possible intended match
            8:  %2 = arith.extsi %1 : i32 to i64 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            9:  %3 = arith.muli %2, %arg2 : i64 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           10:  %4 = tt.addptr %0, %3 : !tt.ptr<bf16>, i64 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           11:  %5 = arith.addi %c0, %c0 : index 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           12:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%5], sizes: [128, 128], strides: [%c128, %c1] : memref<*xbf16> to memref<128x128xbf16, strided<[?, ?], offset: ?>> 
check:22'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
            .
            .
            .
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_splat_float.mlir (15 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_splat_float.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %save0, %0 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: note: see current operation: tt.store %arg2, %0 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %save0, %0 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: note: see current operation: tt.store %arg2, %0 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %save1, %1 : tensor<128x256x!tt.ptr<bf16>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: note: see current operation: tt.store %arg3, %1 : tensor<128x256x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %save1, %1 : tensor<128x256x!tt.ptr<bf16>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :10:9: note: see current operation: tt.store %arg3, %1 : tensor<128x256x!tt.ptr<bf16>>
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%1, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %3) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<128x256xbf16>) -> ()
tensor<128x256x!tt.ptr<bf16>>
module {
  tt.func @kernel(%arg0: f32, %arg1: bf16, %arg2: tensor<1024x!tt.ptr<f32>>, %arg3: tensor<128x256x!tt.ptr<bf16>>) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %0 = tt.splat %arg0 : f32 -> tensor<1024xf32>
    %1 = tt.splat %arg1 : bf16 -> tensor<128x256xbf16>
    %2 = "tts.create_ptr"(%arg2, %c0_i32_0) : (tensor<1024x!tt.ptr<f32>>, i32) -> tensor<1024x!tt.ptr<f32>>
    tt.store %2, %0 : tensor<1024x!tt.ptr<f32>>
    %3 = "tts.create_ptr"(%arg3, %c0_i32) : (tensor<128x256x!tt.ptr<bf16>>, i32) -> tensor<128x256x!tt.ptr<bf16>>
    tt.store %3, %1 : tensor<128x256x!tt.ptr<bf16>>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: error: failed to legalize operation 'tt.store' that was explicitly marked illegal
        tt.store %save0, %0 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir:1 offset :9:9: note: see current operation: "tt.store"(%7, %4) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024x!tt.ptr<f32>>, tensor<1024xf32>) -> ()
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_splat_float.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir (16 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
module {
  tt.func public @maxnumf(%arg0: !tt.ptr<f32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0.000000e+00> : tensor<4096xf32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32, %arg2: f32):
      %2 = arith.maxnumf %arg1, %arg2 : f32
      tt.reduce.return %2 : f32
    }) : (tensor<4096xf32>) -> f32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    tt.store %1, %0 : !tt.ptr<f32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<f32>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
module {
  tt.func public @minnumf(%arg0: !tt.ptr<f32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0.000000e+00> : tensor<4096xf32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: f32, %arg2: f32):
      %2 = arith.minnumf %arg1, %arg2 : f32
      tt.reduce.return %2 : f32
    }) : (tensor<4096xf32>) -> f32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    tt.store %1, %0 : !tt.ptr<f32>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:20:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:2:116: note: scanning from here
 func.func @maxnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:2:116: note: with "PARAM_0_" equal to "%arg0"
 func.func @maxnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:16:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir:57:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:24:116: note: scanning from here
 func.func @minnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:24:116: note: with "PARAM_0_" equal to "%arg0"
 func.func @minnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                   ^
<stdin>:38:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @maxnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:20'0                                                                                                                        X error: no match found
dag:20'1                                                                                                                          with "PARAM_0_" equal to "%arg0"
          3:  %c0 = arith.constant 0 : index 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %cst = arith.constant 0xFF800000 : f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %cst_0 = arith.constant 0.000000e+00 : f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          6:  %0 = tensor.empty() : tensor<4096xf32> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<4096xf32>) -> tensor<4096xf32> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         11:  (%in: f32, %init: f32) { 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
         12:  %3 = arith.maxnumf %in, %init : f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         13:  linalg.yield %3 : f32 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~
         14:  } 
dag:20'0     ~~~
         15:  %extracted = tensor.extract %reduced[] : tensor<f32> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         16:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:20'2                  ?                                                                                                                                           possible intended match
         17:  affine.store %extracted, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:20'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         18:  return 
dag:20'0     ~~~~~~~~
         19:  } 
dag:20'0     ~~~
         20: } 
dag:20'0     ~~
         21:  
dag:20'0     ~
         22: // ----- 
dag:20'0     ~~~~~~~~~
         23: module { 
dag:20'0     ~~~~~~~~~
         24:  func.func @minnumf(%arg0: memref<*xf32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:20'0     ~~~~~~~~~~~~~~~~~~~
dag:57'0                                                                                                                        X error: no match found
dag:57'1                                                                                                                          with "PARAM_0_" equal to "%arg0"
         25:  %c0 = arith.constant 0 : index 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         26:  %cst = arith.constant 0x7F800000 : f32 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         27:  %cst_0 = arith.constant 0.000000e+00 : f32 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         28:  %0 = tensor.empty() : tensor<4096xf32> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         29:  %1 = linalg.fill ins(%cst_0 : f32) outs(%0 : tensor<4096xf32>) -> tensor<4096xf32> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          .
          .
          .
         33:  (%in: f32, %init: f32) { 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
         34:  %3 = arith.minnumf %in, %init : f32 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         35:  linalg.yield %3 : f32 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~
         36:  } 
dag:57'0     ~~~
         37:  %extracted = tensor.extract %reduced[] : tensor<f32> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         38:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:57'2                  ?                                                                                                                                           possible intended match
         39:  affine.store %extracted, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:57'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         40:  return 
dag:57'0     ~~~~~~~~
         41:  } 
dag:57'0     ~~~
         42: } 
dag:57'0     ~~
         43:  
dag:57'0     ~
>>>>>>

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir (17 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %d, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %d, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: note: see current operation: tt.store %arg3, %13 : tensor<1024x!tt.ptr<f32>>
processing val
%3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<i1>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: tensor<1024x!tt.ptr<f32>>) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c0_i32_2 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <i1> to tensor<1024x!tt.ptr<i1>>
    %1 = tts.make_tptr %arg1 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %2 = tts.make_tptr %arg2 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %3 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<i1>>) -> tensor<1024xi1>
    %4 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %5 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %6 = arith.select %3, %4, %5 : tensor<1024xi1>, tensor<1024xf32>
    %7 = "tts.create_ptr"(%arg3, %c0_i32) : (tensor<1024x!tt.ptr<f32>>, i32) -> tensor<1024x!tt.ptr<f32>>
    tt.store %7, %6 : tensor<1024x!tt.ptr<f32>>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: error: failed to legalize operation 'tt.store' that was explicitly marked illegal
    tt.store %d, %10 : tensor<1024x!tt.ptr<f32>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir:1 offset :24:5: note: see current operation: "tt.store"(%15, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024x!tt.ptr<f32>>, tensor<1024xf32>) -> ()
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_stacked.mlir (18 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_stacked.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir:1 offset :47:13: warning: PtrAnalysis: allowing adding pointer state with modulo in dim 0 to another pointer state with offset in dim 0.
Please verify the operand that contains a scalar is meant to increment pointers in dim1. If that is not the case it WILL LEAD TO WRONG COMPILATION RESULTS.

To avoid this warning, use expand_dims (instead of splat) to explicitly specify which dimension contains the scalar.
      %33 = tt.addptr %arg9, %30 : tensor<4x4x!tt.ptr<f32>>, tensor<4x4xi32>
            ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir:1 offset :47:13: note: see current operation: %48 = tt.addptr %arg9, %42 : tensor<4x4x!tt.ptr<f32>>, tensor<4x4xi32>
processing val
%c0_i32_0 = arith.constant 0 : i32
processing val
%c0_i32 = arith.constant 0 : i32
for op
%2 = arith.muli %1, %c2 : index
%c0 = arith.constant 0 : index
module {
  tt.func public @wrap_stacked_masked_loop_01234567(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %cst = arith.constant -9.900000e+01 : f32
    %c0 = arith.constant 0 : index
    %c3 = arith.constant 3 : index
    %c2 = arith.constant 2 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %c4_i32 = arith.constant 4 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg4 : i32 to index
    %2 = arith.muli %1, %c2 : index
    %3 = arith.muli %0, %1 : index
    %4 = arith.index_cast %arg5 : i32 to index
    %5 = arith.muli %4, %c3 : index
    %6 = arith.index_cast %arg6 : i32 to index
    %7 = arith.index_cast %arg7 : i32 to index
    %8 = arith.muli %arg5, %c4_i32 : i32
    %9 = arith.index_cast %8 : i32 to index
    %10:2 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %2, %arg10 = %c0) -> (index, index)  : i32 {
      %11 = tts.make_tptr %arg1 to sizes: [4, 4], strides: [%6, %7], offsets: [%arg10, %c0], shape: [0, 0], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %12 = tts.make_tptr %arg0 to sizes: [4, 4], strides: [%1, %4], offsets: [%arg9, %5], shape: [%3, 0], order: [] : <f32> to tensor<4x4x!tt.ptr<f32>>
      %13 = "tts.load"(%12, %cst) <{operandSegmentSizes = array<i32: 1, 0, 1>, static_mask_dims = array<i64: 4, 3>}> : (tensor<4x4x!tt.ptr<f32>>, f32) -> tensor<4x4xf32>
      "tts.store"(%11, %13) <{static_mask_dims = array<i64>}> : (tensor<4x4x!tt.ptr<f32>>, tensor<4x4xf32>) -> ()
      %14 = arith.addi %arg9, %9 : index
      %15 = arith.addi %arg10, %9 : index
      scf.yield %14, %15 : index, index
    }
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir:1 offset :44:13: error: failed to legalize operation 'tts.make_tptr' that was explicitly marked illegal
    %31:2 = scf.for %arg8 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg9 = %15, %arg10 = %26) -> (tensor<4x4x!tt.ptr<f32>>, tensor<4x4x!tt.ptr<f32>>)  : i32 {
            ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir:1 offset :44:13: note: see current operation: %24 = "tts.make_tptr"(%1, %11, %14, %arg15, %15, %13) <{operandSegmentSizes = array<i32: 1, 2, 2, 1>, order = array<i32>, sizes = array<i64: 4, 4>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: -9223372036854775808, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index, index) -> tensor<4x4x!tt.ptr<f32>>
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/wraparound_stacked.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir (19 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %d, %100 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %d, %100 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: note: see current operation: tt.store %arg3, %19 : tensor<128x128x!tt.ptr<f32>>
processing val
%3 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<128x128xf32>) -> ()
tensor<128x128x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<i1>, %arg1: !tt.ptr<f32>, %arg2: !tt.ptr<f32>, %arg3: tensor<128x128x!tt.ptr<f32>>) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c0_i32_2 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <i1> to tensor<128x128x!tt.ptr<i1>>
    %1 = tts.make_tptr %arg1 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %2 = tts.make_tptr %arg2 to sizes: [128, 128], strides: [1, 1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<128x128x!tt.ptr<f32>>
    %3 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<i1>>) -> tensor<128x128xi1>
    %4 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %5 = "tts.load"(%2) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
    %6 = arith.select %3, %4, %5 : tensor<128x128xi1>, tensor<128x128xf32>
    %7 = "tts.create_ptr"(%arg3, %c0_i32) : (tensor<128x128x!tt.ptr<f32>>, i32) -> tensor<128x128x!tt.ptr<f32>>
    tt.store %7, %6 : tensor<128x128x!tt.ptr<f32>>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: error: failed to legalize operation 'tt.store' that was explicitly marked illegal
        tt.store %d, %100 : tensor<128x128x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir:1 offset :30:9: note: see current operation: "tt.store"(%15, %14) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xf32>) -> ()
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir (20 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
%10 = "tt.addptr"(%0, %8) : (i32, i32) -> !tt.ptr<f32>
processing val
%10 = "arith.addi"(%0, %8) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
processing user
%11:3 = "scf.for"(%6, %5, %4, %3, %10, %9) ({
^bb0(%arg5: index, %arg6: tensor<128x128xf32>, %arg7: !tt.ptr<f32>, %arg8: index):
  %16 = "arith.addi"(%arg8, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %17 = "tts.make_tptr"(%arg1, %16) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
  %18 = "tts.load"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
  %19 = "math.exp"(%18) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
  %20 = "arith.addf"(%arg6, %19) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
  %21 = "arith.index_cast"(%arg5) : (index) -> i32
  %22 = "arith.addi"(%arg8, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %23 = "tt.addptr"(%arg7, %21) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
  "scf.yield"(%20, %23, %22) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
}) : (index, index, index, tensor<128x128xf32>, i32, index) -> (tensor<128x128xf32>, !tt.ptr<f32>, index)
arg number: 4
%10 = "arith.addi"(%0, %8) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
init arg size
3
num region iter-args
3
dump from that index
%10 = "arith.addi"(%0, %8) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
iter arg
<block argument> of type '!tt.ptr<f32>' at index: 2
init arg
%3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<128x128xf32>}> : () -> tensor<128x128xf32>
%10 = "arith.addi"(%0, %8) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%9 = "arith.index_cast"(%8) : (i32) -> index
processing val
<block argument> of type '!tt.ptr<f32>' at index: 2
processing user
%23 = "tt.addptr"(%arg7, %21) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
processing val
%23 = "arith.addi"(%arg7, %21) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
processing user
"scf.yield"(%20, %23, %22) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
for op
%3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<128x128xf32>}> : () -> tensor<128x128xf32>
%10 = "arith.addi"(%0, %8) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%9 = "arith.index_cast"(%8) : (i32) -> index
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = 128 : index}> : () -> index
    %3 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<128x128xf32>}> : () -> tensor<128x128xf32>
    %4 = "arith.constant"() <{value = 3 : index}> : () -> index
    %5 = "arith.constant"() <{value = 12 : index}> : () -> index
    %6 = "arith.constant"() <{value = 0 : index}> : () -> index
    %7 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
    %8 = "arith.muli"(%7, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %9 = "arith.index_cast"(%8) : (i32) -> index
    %10 = "arith.addi"(%0, %8) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %11:3 = "scf.for"(%6, %5, %4, %3, %10, %9) ({
    ^bb0(%arg5: index, %arg6: tensor<128x128xf32>, %arg7: !tt.ptr<f32>, %arg8: index):
      %16 = "arith.addi"(%arg8, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %17 = "tts.make_tptr"(%arg1, %16) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
      %18 = "tts.load"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>) -> tensor<128x128xf32>
      %19 = "math.exp"(%18) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>) -> tensor<128x128xf32>
      %20 = "arith.addf"(%arg6, %19) <{fastmath = #arith.fastmath<none>}> : (tensor<128x128xf32>, tensor<128x128xf32>) -> tensor<128x128xf32>
      %21 = "arith.index_cast"(%arg5) : (index) -> i32
      %22 = "arith.addi"(%arg8, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %23 = "arith.addi"(%arg7, %21) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      "scf.yield"(%20, %23, %22) : (tensor<128x128xf32>, !tt.ptr<f32>, index) -> ()
    }) : (index, index, index, tensor<128x128xf32>, i32, index) -> (tensor<128x128xf32>, !tt.ptr<f32>, index)
    %12 = "arith.muli"(%7, %arg3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %13 = "arith.index_cast"(%12) : (i32) -> index
    %14 = "arith.addi"(%13, %2) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
    %15 = "tts.make_tptr"(%arg0, %14) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 128, 128>, static_offsets = array<i64: -9223372036854775808, 0>, static_shape = array<i64: 0, 0>, static_strides = array<i64: 1, 1>}> : (!tt.ptr<f32>, index) -> tensor<128x128x!tt.ptr<f32>>
    "tts.store"(%15, %11#0) <{static_mask_dims = array<i64>}> : (tensor<128x128x!tt.ptr<f32>>, tensor<128x128xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
block count: 1
block arg count: 4
init arg count: 3
reusing type for 0 to
index
reusing type for 1 to
tensor<128x128xf32>
mapping 2 to
i32
%10 = "arith.addi"(%0, %8) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
reusing type for 3 to
index
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir:1 offset :12:93: error: failed to legalize unresolved materialization from ('i32') to '!tt.ptr<f32>' that remained live after conversion
    %sum_out, %_ptr = scf.for %i = %c0 to %c12 step %c3 iter_args(%sum_iter = %tensor_cf0,  %ptr_iter = %2) ->  (tensor<128x128xf32>, !tt.ptr<f32> ) {
                                                                                            ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir:1 offset :12:93: note: see current operation: %16 = "builtin.unrealized_conversion_cast"(%arg7) : (i32) -> !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir:1 offset :31:19: note: see existing live user here: %24 = "arith.addi"(%16, %22) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %ptr_next = tt.addptr %ptr_iter, %cast_i : !tt.ptr<f32>, i32
                  ^
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for.mlir (21 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
%9 = "tt.addptr"(%0, %7) : (i32, i32) -> !tt.ptr<f32>
processing val
%9 = "arith.addi"(%0, %7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
processing user
%10:3 = "scf.for"(%5, %4, %3, %9, %8, %2) ({
^bb0(%arg5: index, %arg6: !tt.ptr<f32>, %arg7: index, %arg8: tensor<1024xf32>):
  %14 = "tts.make_tptr"(%arg1, %arg7) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
  %15 = "tts.load"(%14) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
  %16 = "math.exp"(%15) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
  %17 = "arith.addf"(%arg8, %16) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
  %18 = "arith.index_cast"(%arg5) : (index) -> i32
  %19 = "arith.addi"(%arg7, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  %20 = "tt.addptr"(%arg6, %18) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
  "scf.yield"(%20, %19, %17) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
}) : (index, index, index, i32, index, tensor<1024xf32>) -> (!tt.ptr<f32>, index, tensor<1024xf32>)
arg number: 3
%9 = "arith.addi"(%0, %7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
init arg size
3
num region iter-args
3
dump from that index
%9 = "arith.addi"(%0, %7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
iter arg
<block argument> of type '!tt.ptr<f32>' at index: 1
init arg
%9 = "arith.addi"(%0, %7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%8 = "arith.index_cast"(%7) : (i32) -> index
%2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1024xf32>}> : () -> tensor<1024xf32>
processing val
<block argument> of type '!tt.ptr<f32>' at index: 1
processing user
%20 = "tt.addptr"(%arg6, %18) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
processing val
%20 = "arith.addi"(%arg6, %18) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
processing user
"scf.yield"(%20, %19, %17) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
for op
%9 = "arith.addi"(%0, %7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
%8 = "arith.index_cast"(%7) : (i32) -> index
%2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1024xf32>}> : () -> tensor<1024xf32>
"builtin.module"() ({
  "tt.func"() <{arg_attrs = [{tt.divisibility = 16 : i32}, {tt.divisibility = 16 : i32}, {}, {}, {}], function_type = (!tt.ptr<f32>, !tt.ptr<f32>, i32, i32, i32) -> (), sym_name = "kernel"}> ({
  ^bb0(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32, %arg4: i32):
    %0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
    %2 = "arith.constant"() <{value = dense<0.000000e+00> : tensor<1024xf32>}> : () -> tensor<1024xf32>
    %3 = "arith.constant"() <{value = 3 : index}> : () -> index
    %4 = "arith.constant"() <{value = 12 : index}> : () -> index
    %5 = "arith.constant"() <{value = 0 : index}> : () -> index
    %6 = "tt.get_program_id"() <{axis = 0 : i32}> : () -> i32
    %7 = "arith.muli"(%6, %arg2) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %8 = "arith.index_cast"(%7) : (i32) -> index
    %9 = "arith.addi"(%0, %7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %10:3 = "scf.for"(%5, %4, %3, %9, %8, %2) ({
    ^bb0(%arg5: index, %arg6: !tt.ptr<f32>, %arg7: index, %arg8: tensor<1024xf32>):
      %14 = "tts.make_tptr"(%arg1, %arg7) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
      %15 = "tts.load"(%14) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
      %16 = "math.exp"(%15) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>) -> tensor<1024xf32>
      %17 = "arith.addf"(%arg8, %16) <{fastmath = #arith.fastmath<none>}> : (tensor<1024xf32>, tensor<1024xf32>) -> tensor<1024xf32>
      %18 = "arith.index_cast"(%arg5) : (index) -> i32
      %19 = "arith.addi"(%arg7, %arg5) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %20 = "arith.addi"(%arg6, %18) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      "scf.yield"(%20, %19, %17) : (!tt.ptr<f32>, index, tensor<1024xf32>) -> ()
    }) : (index, index, index, i32, index, tensor<1024xf32>) -> (!tt.ptr<f32>, index, tensor<1024xf32>)
    %11 = "arith.muli"(%6, %arg3) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
    %12 = "arith.index_cast"(%11) : (i32) -> index
    %13 = "tts.make_tptr"(%arg0, %12) <{operandSegmentSizes = array<i32: 1, 0, 1, 0>, order = array<i32>, sizes = array<i64: 1024>, static_offsets = array<i64: -9223372036854775808>, static_shape = array<i64: 0>, static_strides = array<i64: 1>}> : (!tt.ptr<f32>, index) -> tensor<1024x!tt.ptr<f32>>
    "tts.store"(%13, %10#2) <{static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>, tensor<1024xf32>) -> ()
    "tt.return"() : () -> ()
  }) : () -> ()
}) : () -> ()
block count: 1
block arg count: 4
init arg count: 3
reusing type for 0 to
index
mapping 1 to
i32
%9 = "arith.addi"(%0, %7) <{overflowFlags = #arith.overflow<none>}> : (i32, i32) -> i32
reusing type for 2 to
index
reusing type for 3 to
tensor<1024xf32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir:1 offset :13:67: error: failed to legalize unresolved materialization from ('i32') to '!tt.ptr<f32>' that remained live after conversion
    %_ptr, %sum_out = scf.for %i = %c0 to %c12 step %c3 iter_args(%ptr_iter = %2, %sum_iter = %tensor_cf0) ->  (!tt.ptr<f32>, tensor<1024xf32>) {
                                                                  ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir:1 offset :13:67: note: see current operation: %14 = "builtin.unrealized_conversion_cast"(%arg6) : (i32) -> !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir:1 offset :24:19: note: see existing live user here: %21 = "arith.addi"(%14, %19) <{overflowFlags = #arith.overflow<none>}> : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
      %ptr_next = tt.addptr %ptr_iter, %cast_i : !tt.ptr<f32>, i32
                  ^
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/addptr_scalar_for.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_middle_dim.mlir (22 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_middle_dim.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %out, %5 : tensor<32x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: note: see current operation: tt.store %arg2, %19 : tensor<32x16x!tt.ptr<bf16>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %out, %5 : tensor<32x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: note: see current operation: tt.store %arg2, %19 : tensor<32x16x!tt.ptr<bf16>>
processing val
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %6) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<32x16xbf16>) -> ()
tensor<32x16x!tt.ptr<bf16>>
module {
  tt.func @kernel(%arg0: !tt.ptr<bf16>, %arg1: !tt.ptr<bf16>, %arg2: tensor<32x16x!tt.ptr<bf16>>) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c256 = arith.constant 256 : index
    %0 = tts.make_tptr %arg0 to sizes: [32, 256, 16], strides: [%c256, 1, 1], offsets: [0, 0, 0], shape: [0, 0, 0], order: [] : <bf16> to tensor<32x256x16x!tt.ptr<bf16>>
    %1 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<32x256x16x!tt.ptr<bf16>>) -> tensor<32x256x16xbf16>
    %2 = "tt.reduce"(%1) <{axis = 1 : i32}> ({
    ^bb0(%arg3: bf16, %arg4: bf16):
      %4 = arith.addf %arg3, %arg4 : bf16
      tt.reduce.return %4 : bf16
    }) : (tensor<32x256x16xbf16>) -> tensor<32x16xbf16>
    %3 = "tts.create_ptr"(%arg2, %c0_i32) : (tensor<32x16x!tt.ptr<bf16>>, i32) -> tensor<32x16x!tt.ptr<bf16>>
    tt.store %3, %2 : tensor<32x16x!tt.ptr<bf16>>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: error: failed to legalize operation 'tt.store' that was explicitly marked illegal
    tt.store %out, %5 : tensor<32x16x!tt.ptr<bf16>>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir:1 offset :37:5: note: see current operation: "tt.store"(%11, %10) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<32x16x!tt.ptr<bf16>>, tensor<32x16xbf16>) -> ()
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/reducesum_middle_dim.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir (23 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
        tt.store %c, %6 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: note: see current operation: tt.store %arg2, %14 : tensor<1024x!tt.ptr<f32>>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: remark: PtrAnalysis: Failed to rewrite StoreOp
        tt.store %c, %6 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: note: see current operation: tt.store %arg2, %14 : tensor<1024x!tt.ptr<f32>>
processing val
%2 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%1 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %12) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, tensor<1024xf32>) -> ()
tensor<1024x!tt.ptr<f32>>
module {
  tt.func @kernel(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: tensor<1024x!tt.ptr<f32>>) {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %0 = tts.make_tptr %arg0 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %1 = tts.make_tptr %arg1 to sizes: [1024], strides: [1], offsets: [0], shape: [0], order: [] : <f32> to tensor<1024x!tt.ptr<f32>>
    %2 = "tts.load"(%0) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %3 = "tts.load"(%1) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<1024x!tt.ptr<f32>>) -> tensor<1024xf32>
    %4 = arith.addf %2, %3 : tensor<1024xf32>
    %5 = arith.subf %4, %3 : tensor<1024xf32>
    %6 = arith.mulf %5, %3 : tensor<1024xf32>
    %7 = arith.divf %6, %3 : tensor<1024xf32>
    %8 = arith.cmpf oeq, %7, %3 : tensor<1024xf32>
    %9 = arith.select %8, %2, %3 : tensor<1024xi1>, tensor<1024xf32>
    %10 = "tts.create_ptr"(%arg2, %c0_i32) : (tensor<1024x!tt.ptr<f32>>, i32) -> tensor<1024x!tt.ptr<f32>>
    tt.store %10, %9 : tensor<1024x!tt.ptr<f32>>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: error: failed to legalize operation 'tt.store' that was explicitly marked illegal
        tt.store %c, %6 : tensor<1024x!tt.ptr<f32>>
        ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir:1 offset :25:9: note: see current operation: "tt.store"(%17, %16) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (tensor<1024x!tt.ptr<f32>>, tensor<1024xf32>) -> ()
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir

--

********************
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_f32_axis1.mlir (24 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-05-layer-norm-fwd.mlir (25 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_mul_value_const.mlir (26 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/nested_loops.mlir (27 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax.mlir (28 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:1 offset :6:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
module {
  tt.func public @minmax_olt(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32) {
    %c0_i32 = arith.constant 0 : i32
    %0 = arith.cmpf olt, %arg1, %arg2 : f32
    %1 = arith.select %0, %arg1, %arg2 : f32
    %2 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    tt.store %2, %1 : !tt.ptr<f32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:11 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
module {
  tt.func public @minmax_ole(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32) {
    %c0_i32 = arith.constant 0 : i32
    %0 = arith.cmpf ole, %arg1, %arg2 : f32
    %1 = arith.select %0, %arg1, %arg2 : f32
    %2 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    tt.store %2, %1 : !tt.ptr<f32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:22 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
module {
  tt.func public @minmax_ogt(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32) {
    %c0_i32 = arith.constant 0 : i32
    %0 = arith.cmpf ogt, %arg1, %arg2 : f32
    %1 = arith.select %0, %arg1, %arg2 : f32
    %2 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    tt.store %2, %1 : !tt.ptr<f32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %1 : !tt.ptr<f32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:33 offset :7:5: note: see current operation: tt.store %arg0, %1 : !tt.ptr<f32>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, f32) -> ()
!tt.ptr<f32>
module {
  tt.func public @minmax_oge(%arg0: !tt.ptr<f32>, %arg1: f32, %arg2: f32) {
    %c0_i32 = arith.constant 0 : i32
    %0 = arith.cmpf oge, %arg1, %arg2 : f32
    %1 = arith.select %0, %arg1, %arg2 : f32
    %2 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<f32>, i32) -> !tt.ptr<f32>
    tt.store %2, %1 : !tt.ptr<f32>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:46:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:2:143: note: scanning from here
 func.func @minmax_olt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:2:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_olt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:5:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:53:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:13:143: note: scanning from here
 func.func @minmax_ole(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:13:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ole(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:16:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:60:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:24:143: note: scanning from here
 func.func @minmax_ogt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:24:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ogt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:27:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir:67:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
              ^
<stdin>:35:143: note: scanning from here
 func.func @minmax_oge(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:35:143: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_oge(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) {
                                                                                                                                              ^
<stdin>:38:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
          1: module { 
          2:  func.func @minmax_olt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
dag:46'0                                                                                                                                                   X error: no match found
dag:46'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
          3:  %c0 = arith.constant 0 : index 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          4:  %0 = arith.minimumf %arg1, %arg2 : f32 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          5:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:46'2                  ?                                                                                                                                           possible intended match
          6:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          7:  return 
dag:46'0     ~~~~~~~~
          8:  } 
dag:46'0     ~~~
          9: } 
dag:46'0     ~~
         10:  
dag:46'0     ~
         11: // ----- 
dag:46'0     ~~~~~~~~~
         12: module { 
dag:46'0     ~~~~~~~~~
         13:  func.func @minmax_ole(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
dag:46'0     ~~~~~~~~~~~~~~~~~~~~~~
dag:53'0                                                                                                                                                   X error: no match found
dag:53'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
         14:  %c0 = arith.constant 0 : index 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         15:  %0 = arith.minimumf %arg1, %arg2 : f32 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         16:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:53'2                  ?                                                                                                                                           possible intended match
         17:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         18:  return 
dag:53'0     ~~~~~~~~
         19:  } 
dag:53'0     ~~~
         20: } 
dag:53'0     ~~
         21:  
dag:53'0     ~
         22: // ----- 
dag:53'0     ~~~~~~~~~
         23: module { 
dag:53'0     ~~~~~~~~~
         24:  func.func @minmax_ogt(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
dag:53'0     ~~~~~~~~~~~~~~~~~~~~~~
dag:60'0                                                                                                                                                   X error: no match found
dag:60'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
         25:  %c0 = arith.constant 0 : index 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         26:  %0 = arith.maximumf %arg1, %arg2 : f32 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         27:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:60'2                  ?                                                                                                                                           possible intended match
         28:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         29:  return 
dag:60'0     ~~~~~~~~
         30:  } 
dag:60'0     ~~~
         31: } 
dag:60'0     ~~
         32:  
dag:60'0     ~
         33: // ----- 
dag:60'0     ~~~~~~~~~
         34: module { 
dag:60'0     ~~~~~~~~~
         35:  func.func @minmax_oge(%arg0: memref<*xf32>, %arg1: f32, %arg2: f32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32, %arg7: i32, %arg8: i32) { 
dag:60'0     ~~~~~~~~~~~~~~~~~~~~~~
dag:67'0                                                                                                                                                   X error: no match found
dag:67'1                                                                                                                                                     with "PARAM_0_" equal to "%arg0"
         36:  %c0 = arith.constant 0 : index 
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         37:  %0 = arith.maximumf %arg1, %arg2 : f32 
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         38:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xf32> to memref<1xf32, strided<[1], offset: ?>> 
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:67'2                  ?                                                                                                                                           possible intended match
         39:  affine.store %0, %reinterpret_cast[0] : memref<1xf32, strided<[1], offset: ?>> 
dag:67'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
         40:  return 
dag:67'0     ~~~~~~~~
         41:  } 
dag:67'0     ~~~
         42: } 
dag:67'0     ~~
         43:  
dag:67'0     ~
>>>>>>

--

********************
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_argmin_argmax.mlir (29 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_extern_elementwise.mlir (30 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_extern_elementwise.mlir (31 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/block_ptr_advance.mlir (32 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/nested_loops.mlir (33 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/nested_loops.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir
processing val
%c0_i32_0 = arith.constant 0 : i32
processing val
%c0_i32 = arith.constant 0 : i32
processing val
%c0_i32_0 = arith.constant 0 : i32
processing val
%c0_i32 = arith.constant 0 : i32
processing val
%c0_i32_0 = arith.constant 0 : i32
processing val
%c0_i32 = arith.constant 0 : i32
processing val
%c0_i32_0 = arith.constant 0 : i32
processing val
%c0_i32 = arith.constant 0 : i32
for op
%5 = arith.addi %arg5, %c1 : index
%6 = arith.addi %arg6, %c1 : index
for op
%c0 = arith.constant 0 : index
%c0 = arith.constant 0 : index
for op
%8 = arith.addi %arg5, %3 : index
%9 = arith.addi %arg6, %3 : index
for op
%c0 = arith.constant 0 : index
%c0 = arith.constant 0 : index
for op
%10 = arith.addi %arg9, %4 : index
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 2
<block argument> of type 'index' at index: 3
for op
<block argument> of type 'index' at index: 1
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 2
<block argument> of type 'index' at index: 3
for op
%c0 = arith.constant 0 : index
%2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
%c0 = arith.constant 0 : index
for op
<block argument> of type 'index' at index: 1
for op
%6 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5) -> (index)  : i32 {
  %9 = arith.addi %arg9, %4 : index
  scf.yield %9 : index
}
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 2
<block argument> of type 'index' at index: 3
for op
%c0 = arith.constant 0 : index
%2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
%c0 = arith.constant 0 : index
module {
  tt.func public @nested2_complex_body(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c3 = arith.constant 3 : index
    %c1 = arith.constant 1 : index
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = arith.muli %arg2, %c2_i32 : i32
    %3 = arith.index_cast %2 : i32 to index
    %4:2 = scf.for %arg4 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %c0) -> (index, index)  : i32 {
      %5 = arith.addi %arg5, %c1 : index
      %6 = arith.addi %arg6, %c1 : index
      %7:2 = scf.for %arg7 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg8 = %5, %arg9 = %6) -> (index, index)  : i32 {
        %12 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %13 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg8, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %14 = "tts.load"(%13) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%12, %14) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %15 = arith.addi %arg8, %c3 : index
        %16 = arith.addi %arg9, %c3 : index
        scf.yield %15, %16 : index, index
      }
      %8 = arith.addi %arg5, %3 : index
      %9 = arith.addi %8, %c1 : index
      %10 = arith.addi %arg6, %3 : index
      %11 = arith.addi %10, %c1 : index
      scf.yield %9, %11 : index, index
    }
    tt.return
  }
  tt.func public @nested2_use_loop_results(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c2_i32 = arith.constant 2 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c4_i32 = arith.constant 4 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = arith.muli %arg3, %c4_i32 : i32
    %3 = arith.index_cast %2 : i32 to index
    %4:2 = scf.for %arg4 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %c0) -> (index, index)  : i32 {
      %5 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg6, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %6 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg5, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %7 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%5, %7) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %8 = arith.addi %arg5, %3 : index
      %9 = arith.addi %arg6, %3 : index
      %10:2 = scf.for %arg7 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg8 = %8, %arg9 = %9) -> (index, index)  : i32 {
        %11 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %12 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg8, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%11, %13) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %14 = arith.addi %arg8, %3 : index
        %15 = arith.addi %arg9, %3 : index
        scf.yield %14, %15 : index, index
      }
      scf.yield %10#0, %10#1 : index, index
    }
    tt.return
  }
  tt.func public @nested3(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %3 = arith.muli %arg3, %c2_i32 : i32
    %4 = arith.index_cast %3 : i32 to index
    %5:3 = scf.for %arg4 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %2, %arg7 = %c0) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %6 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg5, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %7 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %8:3 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5, %arg10 = %arg6, %arg11 = %arg7) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %10 = arith.addi %arg9, %4 : index
        %11 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%10, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %12 = "tts.load"(%11) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %13:3 = scf.for %arg12 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg13 = %10, %arg14 = %arg10, %arg15 = %arg11) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
          %14 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg15, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %15 = arith.addi %arg13, %4 : index
          %16 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%15, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %17 = "tts.load"(%16) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          "tts.store"(%14, %7) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %18 = arith.addi %arg15, %4 : index
          %19 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%18, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%19, %12) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %20 = arith.addi %18, %4 : index
          %21 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%20, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%21, %17) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %22 = arith.addi %20, %4 : index
          %23 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          scf.yield %15, %23, %22 : index, tensor<2x2x!tt.ptr<f32>>, index
        }
        scf.yield %13#0, %13#1, %13#2 : index, tensor<2x2x!tt.ptr<f32>>, index
      }
      %9 = arith.addi %8#0, %4 : index
      scf.yield %9, %8#1, %8#2 : index, tensor<2x2x!tt.ptr<f32>>, index
    }
    tt.return
  }
  tt.func public @nested_use_same_level_loop_result(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %3 = arith.muli %arg3, %c2_i32 : i32
    %4 = arith.index_cast %3 : i32 to index
    %5:3 = scf.for %arg4 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %2, %arg7 = %c0) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %6 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5) -> (index)  : i32 {
        %9 = arith.addi %arg9, %4 : index
        scf.yield %9 : index
      }
      %7:3 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %6, %arg10 = %arg6, %arg11 = %arg7) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %9 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg11, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %10 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %11 = "tts.load"(%10) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %12 = arith.addi %arg9, %4 : index
        %13 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%12, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %14 = "tts.load"(%13) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%9, %11) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %15 = arith.addi %arg11, %4 : index
        %16 = arith.addi %15, %4 : index
        %17 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%16, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        "tts.store"(%17, %14) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %18 = arith.addi %16, %4 : index
        %19 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%18, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %20 = arith.addi %12, %4 : index
        scf.yield %20, %19, %18 : index, tensor<2x2x!tt.ptr<f32>>, index
      }
      %8 = arith.addi %7#0, %4 : index
      scf.yield %8, %7#1, %7#2 : index, tensor<2x2x!tt.ptr<f32>>, index
    }
    tt.return
  }
}
block count: 1
block arg count: 4
init arg count: 3
reusing type for 0 to
i32
reusing type for 1 to
index
mapping 2 to
tensor<2x2x!tt.ptr<f32>>
%2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
reusing type for 3 to
index
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir:1 offset :109:13: error: failed to legalize operation 'scf.for' that was explicitly marked illegal
    %20:2 = scf.for %arg4 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg5 = %11, %arg6 = %15) -> (tensor<2x2x!tt.ptr<f32>>, tensor<2x2x!tt.ptr<f32>>)  : i32 {
            ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir:1 offset :109:13: note: see current operation: 
%11:3 = "scf.for"(%4, %5, %3, %2, %8, %2) ({
^bb0(%arg4: i32, %arg5: index, %arg6: tensor<2x2x!tt.ptr<f32>>, %arg7: index):
  %12 = "tts.make_tptr"(%arg0, %6, %7, %arg5, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
  %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %14:3 = "scf.for"(%4, %5, %3, %arg5, %arg6, %arg7) ({
  ^bb0(%arg8: i32, %arg9: index, %arg10: tensor<2x2x!tt.ptr<f32>>, %arg11: index):
    %16 = "arith.addi"(%arg9, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
    %17 = "tts.make_tptr"(%arg0, %6, %7, %16, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
    %18 = "tts.load"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    %19:3 = "scf.for"(%4, %5, %3, %16, %arg10, %arg11) ({
    ^bb0(%arg12: i32, %arg13: index, %arg14: tensor<2x2x!tt.ptr<f32>>, %arg15: index):
      %20 = "tts.make_tptr"(%arg1, %6, %7, %arg15, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
      %21 = "arith.addi"(%arg13, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %22 = "tts.make_tptr"(%arg0, %6, %7, %21, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
      %23 = "tts.load"(%22) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%20, %13) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %24 = "arith.addi"(%arg15, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %25 = "tts.make_tptr"(%arg1, %6, %7, %24, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%25, %18) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %26 = "arith.addi"(%24, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %27 = "tts.make_tptr"(%arg1, %6, %7, %26, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%27, %23) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %28 = "arith.addi"(%26, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %29 = "tts.make_tptr"(%arg1, %6, %7, %28, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
      "scf.yield"(%21, %29, %28) : (index, tensor<2x2x!tt.ptr<f32>>, index) -> ()
    }) : (i32, i32, i32, index, tensor<2x2x!tt.ptr<f32>>, index) -> (index, tensor<2x2x!tt.ptr<f32>>, index)
    "scf.yield"(%19#0, %19#1, %19#2) : (index, tensor<2x2x!tt.ptr<f32>>, index) -> ()
  }) : (i32, i32, i32, index, tensor<2x2x!tt.ptr<f32>>, index) -> (index, tensor<2x2x!tt.ptr<f32>>, index)
  %15 = "arith.addi"(%14#0, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  "scf.yield"(%15, %14#1, %14#2) : (index, tensor<2x2x!tt.ptr<f32>>, index) -> ()
}) : (i32, i32, i32, index, tensor<2x2x!tt.ptr<f32>>, index) -> (index, tensor<2x2x!tt.ptr<f32>>, index)
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/nested_loops.mlir

--

********************
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_reduce.mlir (34 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_reduce.mlir' FAILED ********************
Exit Code: 1

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental  /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --split-input-file --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:1 offset :11:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
!tt.ptr<i32>
module {
  tt.func public @minmax_sgt(%arg0: !tt.ptr<i32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %2 = arith.cmpi sgt, %arg1, %arg2 : i32
      %3 = arith.select %2, %arg1, %arg2 : i32
      tt.reduce.return %3 : i32
    }) : (tensor<4096xi32>) -> i32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    tt.store %1, %0 : !tt.ptr<i32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:37 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
!tt.ptr<i32>
module {
  tt.func public @minmax_ugt(%arg0: !tt.ptr<i32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %2 = arith.cmpi ugt, %arg1, %arg2 : i32
      %3 = arith.select %2, %arg1, %arg2 : i32
      tt.reduce.return %3 : i32
    }) : (tensor<4096xi32>) -> i32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    tt.store %1, %0 : !tt.ptr<i32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:74 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
!tt.ptr<i32>
module {
  tt.func public @minmax_slt(%arg0: !tt.ptr<i32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %2 = arith.cmpi slt, %arg1, %arg2 : i32
      %3 = arith.select %2, %arg1, %arg2 : i32
      tt.reduce.return %3 : i32
    }) : (tensor<4096xi32>) -> i32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    tt.store %1, %0 : !tt.ptr<i32>
    tt.return
  }
}
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: remark: PtrAnalysis: pointer is not replace with tts.make_tptr so storeOp cannot be rewritten
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: remark: PtrAnalysis: Failed to rewrite StoreOp
    tt.store %arg0, %63 : !tt.ptr<i32>
    ^
within split at /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:112 offset :12:5: note: see current operation: tt.store %arg0, %0 : !tt.ptr<i32>
processing val
%0 = "arith.constant"() <{value = 0 : i32}> : () -> i32
processing user
"tt.store"(%0, %2) <{boundaryCheck = array<i32>, cache = 1 : i32, evict = 1 : i32}> : (i32, i32) -> ()
!tt.ptr<i32>
module {
  tt.func public @minmax_ult(%arg0: !tt.ptr<i32>) {
    %c0_i32 = arith.constant 0 : i32
    %cst = arith.constant dense<0> : tensor<4096xi32>
    %0 = "tt.reduce"(%cst) <{axis = 0 : i32}> ({
    ^bb0(%arg1: i32, %arg2: i32):
      %2 = arith.cmpi ult, %arg1, %arg2 : i32
      %3 = arith.select %2, %arg1, %arg2 : i32
      tt.reduce.return %3 : i32
    }) : (tensor<4096xi32>) -> i32
    %1 = "tts.create_ptr"(%arg0, %c0_i32) : (!tt.ptr<i32>, i32) -> !tt.ptr<i32>
    tt.store %1, %0 : !tt.ptr<i32>
    tt.return
  }
}
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:20:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:2:119: note: scanning from here
 func.func @minmax_sgt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:2:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_sgt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:16:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:57:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:24:119: note: scanning from here
 func.func @minmax_ugt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:24:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ugt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:37:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:94:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:45:119: note: scanning from here
 func.func @minmax_slt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:45:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_slt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:59:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir:132:15: error: CHECK-DAG: expected string not found in input
// CHECK-DAG: [[VAR_reinterpret_cast_:%.+]] = memref.reinterpret_cast [[PARAM_0_]] to offset: [0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
              ^
<stdin>:67:119: note: scanning from here
 func.func @minmax_ult(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:67:119: note: with "PARAM_0_" equal to "%arg0"
 func.func @minmax_ult(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) {
                                                                                                                      ^
<stdin>:81:14: note: possible intended match here
 %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>>
             ^

Input file: <stdin>
Check file: /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/convert_minmax_reduce.mlir

-dump-input=help explains the following input dump.

Input was:
<<<<<<
           1: module { 
           2:  func.func @minmax_sgt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:20'0                                                                                                                            X error: no match found
dag:20'1                                                                                                                              with "PARAM_0_" equal to "%arg0"
           3:  %c0 = arith.constant 0 : index 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           4:  %c-2147483648_i32 = arith.constant -2147483648 : i32 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           5:  %c0_i32 = arith.constant 0 : i32 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           6:  %0 = tensor.empty() : tensor<4096xi32> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           7:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          11:  (%in: i32, %init: i32) { 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~
          12:  %3 = arith.maxsi %in, %init : i32 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          13:  linalg.yield %3 : i32 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~
          14:  } 
dag:20'0      ~~~
          15:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          16:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:20'2                   ?                                                                                                                                           possible intended match
          17:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          18:  return 
dag:20'0      ~~~~~~~~
          19:  } 
dag:20'0      ~~~
          20: } 
dag:20'0      ~~
          21:  
dag:20'0      ~
          22: // ----- 
dag:20'0      ~~~~~~~~~
          23: module { 
dag:20'0      ~~~~~~~~~
          24:  func.func @minmax_ugt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:20'0      ~~~~~~~~~~~~~~~~~~~~~~
dag:57'0                                                                                                                            X error: no match found
dag:57'1                                                                                                                              with "PARAM_0_" equal to "%arg0"
          25:  %c0 = arith.constant 0 : index 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          26:  %c0_i32 = arith.constant 0 : i32 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          27:  %0 = tensor.empty() : tensor<4096xi32> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          28:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          29:  %2 = bufferization.alloc_tensor() : tensor<i32> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          32:  (%in: i32, %init: i32) { 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~
          33:  %3 = arith.maxui %in, %init : i32 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          34:  linalg.yield %3 : i32 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~
          35:  } 
dag:57'0      ~~~
          36:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          37:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:57'2                   ?                                                                                                                                           possible intended match
          38:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          39:  return 
dag:57'0      ~~~~~~~~
          40:  } 
dag:57'0      ~~~
          41: } 
dag:57'0      ~~
          42:  
dag:57'0      ~
          43: // ----- 
dag:57'0      ~~~~~~~~~
          44: module { 
dag:57'0      ~~~~~~~~~
          45:  func.func @minmax_slt(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:57'0      ~~~~~~~~~~~~~~~~~~~~~~
dag:94'0                                                                                                                            X error: no match found
dag:94'1                                                                                                                              with "PARAM_0_" equal to "%arg0"
          46:  %c0 = arith.constant 0 : index 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          47:  %c2147483647_i32 = arith.constant 2147483647 : i32 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          48:  %c0_i32 = arith.constant 0 : i32 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          49:  %0 = tensor.empty() : tensor<4096xi32> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          50:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          54:  (%in: i32, %init: i32) { 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~
          55:  %3 = arith.minsi %in, %init : i32 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          56:  linalg.yield %3 : i32 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~
          57:  } 
dag:94'0      ~~~
          58:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          59:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:94'2                   ?                                                                                                                                           possible intended match
          60:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          61:  return 
dag:94'0      ~~~~~~~~
          62:  } 
dag:94'0      ~~~
          63: } 
dag:94'0      ~~
          64:  
dag:94'0      ~
          65: // ----- 
dag:94'0      ~~~~~~~~~
          66: module { 
dag:94'0      ~~~~~~~~~
          67:  func.func @minmax_ult(%arg0: memref<*xi32>, %arg1: i32, %arg2: i32, %arg3: i32, %arg4: i32, %arg5: i32, %arg6: i32) { 
dag:94'0      ~~~~~~~~~~~~~~~~~~~~~~
dag:132'0                                                                                                                           X error: no match found
dag:132'1                                                                                                                             with "PARAM_0_" equal to "%arg0"
          68:  %c0 = arith.constant 0 : index 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          69:  %c-1_i32 = arith.constant -1 : i32 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          70:  %c0_i32 = arith.constant 0 : i32 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          71:  %0 = tensor.empty() : tensor<4096xi32> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          72:  %1 = linalg.fill ins(%c0_i32 : i32) outs(%0 : tensor<4096xi32>) -> tensor<4096xi32> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
           .
           .
           .
          76:  (%in: i32, %init: i32) { 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~
          77:  %3 = arith.minui %in, %init : i32 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          78:  linalg.yield %3 : i32 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~
          79:  } 
dag:132'0     ~~~
          80:  %extracted = tensor.extract %reduced[] : tensor<i32> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          81:  %reinterpret_cast = memref.reinterpret_cast %arg0 to offset: [%c0], sizes: [1], strides: [1] : memref<*xi32> to memref<1xi32, strided<[1], offset: ?>> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
dag:132'2                  ?                                                                                                                                           possible intended match
          82:  affine.store %extracted, %reinterpret_cast[0] : memref<1xi32, strided<[1], offset: ?>> 
dag:132'0     ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
          83:  return 
dag:132'0     ~~~~~~~~
          84:  } 
dag:132'0     ~~~
          85: } 
dag:132'0     ~~
          86:  
dag:132'0     ~
>>>>>>

--

********************
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/unsupported_extern_elementwise.mlir (35 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/ridiculously_nested_loops.mlir (36 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/arith_not_ptr_arith.mlir (37 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_accumulation.mlir (38 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/make_tensor_ptr_ordering_error.mlir (39 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-02-fused-softmax.mlir (40 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/bitcast.mlir (41 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-05-layer-norm-fwd.mlir (42 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/triton-to-structured-prepass.mlir (43 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/masked_ldst_sitofp_other.mlir (44 of 215)
XFAIL: TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_unsupported_add_offset.mlir (45 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_add_value.mlir (46 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/wraparound_unsupported_add_offset.mlir (47 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_2d_example.mlir (48 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_2d_elemwise_arith_unary.mlir (49 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_tensor_reshape.mlir (50 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-03-matrix-multiplication.mlir (51 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_more_init_args.mlir (52 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-05-layer-norm-dwdb.mlir (53 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/masked_ldst_2d.mlir (54 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_minmax_reduce.mlir (55 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterargs_not_used_ptranalysis_e2e.mlir (56 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_f32_axis1.mlir (57 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reduce_extend_fp32_precision.mlir (58 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_splat.mlir (59 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_used_before_update.mlir (60 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/early_return.mlir (61 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_loopback.mlir (62 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-03-matrix-multiplication.mlir (63 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_f32_axis0.mlir (64 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/kernel-01-vector-add.mlir (65 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_1d_elemwise_arith_ternary.mlir (66 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_argmin_argmax_2d.mlir (67 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_advance.mlir (68 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-05-layer-norm-fwd.mlir (69 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/early_return.mlir (70 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_reshape_broadcast.mlir (71 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-02-fused-softmax.mlir (72 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-03-matrix-multiplication.mlir (73 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_1d_elemwise_arith_binary.mlir (74 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_for.mlir (75 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_2d_elemwise_arith_binary.mlir (76 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-05-layer-norm-dwdb.mlir (77 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_argmin_argmax.mlir (78 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_1d_elemwise_arith_unary.mlir (79 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_f32_axis1.mlir (80 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/bitcast.mlir (81 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/use_end_chain.mlir (82 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_nested.mlir (83 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_loopback.mlir (84 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/unsupported_extern_elementwise.mlir (85 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_used_after_update.mlir (86 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_more_init_args.mlir (87 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_2d_elemwise_arith_ternary.mlir (88 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_dim1.mlir (89 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/wraparound_stacked.mlir (90 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/get_num_programs.mlir (91 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_bf16_axis1.mlir (92 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/dot.mlir (93 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/block_ptr_advance.mlir (94 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/tensor_indices_loop_iterargs_nested.mlir (95 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_addi_reduce.mlir (96 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-01-vector-add.mlir (97 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_argmin_argmax_2d.mlir (98 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_mul_const_const.mlir (99 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/masked_ldst_2d.mlir (100 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_nested.mlir (101 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_2d_elemwise_arith_unary.mlir (102 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/dot.mlir (103 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_nested.mlir (104 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/use_dot_opc.mlir (105 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_2d_example.mlir (106 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_loopback.mlir (107 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/dot.mlir (108 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_accumulation.mlir (109 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_2d_example.mlir (110 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_scalar.mlir (111 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_splat_2d.mlir (112 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_bf16_axis0.mlir (113 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_minmax_reduce.mlir (114 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/kernel-05-layer-norm-dwdb.mlir (115 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_used_before_update.mlir (116 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_expand_ptr.mlir (117 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_used_before_update.mlir (118 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/wraparound_stacked.mlir (119 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_reshape_broadcast.mlir (120 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_splat_2d.mlir (121 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_splat.mlir (122 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterarg_with_masks.mlir (123 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_argmin_argmax.mlir (124 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_add_value.mlir (125 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/block_ptr_advance.mlir (126 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_f32_axis0.mlir (127 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-02-fused-softmax.mlir (128 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_splat.mlir (129 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_nested.mlir (130 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_scalar.mlir (131 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_for_2d.mlir (132 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterargs_not_used_ptranalysis_prepass.mlir (133 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_1d_elemwise_arith_ternary.mlir (134 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_loopback.mlir (135 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_nested.mlir (136 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/masked_ldst_sitofp_other.mlir (137 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/kernel-01-vector-add.mlir (138 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/masked_ldst_1d.mlir (139 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/masked_ldst_2d.mlir (140 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_minmax_fp_reduce.mlir (141 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/triton_assert.mlir (142 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_minmax_fp_reduce.mlir (143 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_argmin_argmax_2d.mlir (144 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducemax_32_256_bf16.mlir (145 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_for_2d.mlir (146 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_bf16_axis0.mlir (147 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_broadcast.mlir (148 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/use_dot_opc.mlir (149 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_mul_value_const.mlir (150 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/wraparound_side_by_side.mlir (151 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/masked_ldst_1d.mlir (152 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducemax_32_256_bf16.mlir (153 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_used_after_update.mlir (154 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/get_num_programs.mlir (155 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/dot.mlir (156 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_accumulation.mlir (157 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_for_more_init_args.mlir (158 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/wraparound_side_by_side.mlir (159 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_extern_elementwise.mlir (160 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/bitcast.mlir (161 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_bf16_axis0.mlir (162 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_dim1.mlir (163 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_512_256_bf16_axis1.mlir (164 of 215)
XFAIL: TRITON-SHARED :: Conversion/TritonToLinalg/wraparound_unsupported_add_offset.mlir (165 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_add_value.mlir (166 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/masked_ldst_1d.mlir (167 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_splat_2d.mlir (168 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_mul_const_const.mlir (169 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_nested.mlir (170 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_broadcast.mlir (171 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/use_dot_opc.mlir (172 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/use_mid_chain.mlir (173 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_addi_reduce.mlir (174 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_1d_elemwise_arith_unary.mlir (175 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/tensor_indices_loop_iterarg_with_masks.mlir (176 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/arith_not_ptr_arith.mlir (177 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_expand_ptr.mlir (178 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_scalar_for.mlir (179 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_1d_elemwise_arith_binary.mlir (180 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_2d_elemwise_arith_ternary.mlir (181 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/sign_extend_i32_to_i64.mlir (182 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/bitcast.mlir (183 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_reshape_broadcast.mlir (184 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/unsupported_extern_elementwise.mlir (185 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_splat_float.mlir (186 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/cumsum.mlir (187 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/use_mid_chain.mlir (188 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/masked_ldst_sitofp_other.mlir (189 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_middle_dim.mlir (190 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/triton_assert.mlir (191 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/convert_tensor_reshape.mlir (192 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_512_256_f32_axis0.mlir (193 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/cumsum.mlir (194 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_for_expand_ptr.mlir (195 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/use_mid_chain.mlir (196 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/use_end_chain.mlir (197 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/cumsum.mlir (198 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_scalar_broadcast.mlir (199 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_mul_value_const.mlir (200 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/reducesum_middle_dim.mlir (201 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_minmax.mlir (202 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_2d_elemwise_arith_binary.mlir (203 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_for_used_after_update.mlir (204 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/use_end_chain.mlir (205 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/addptr_loopback.mlir (206 of 215)
XFAIL: TRITON-SHARED :: Conversion/TritonToLinalg/addptr_dim1.mlir (207 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/arith_not_ptr_arith.mlir (208 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToStructured/tensor_indices_loop_iterargs_nested.mlir (209 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/reducesum_512_256_bf16_axis1.mlir (210 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/triton_assert.mlir (211 of 215)
PASS: TRITON-SHARED :: Conversion/TritonArithToLinalg/convert_tensor_reshape.mlir (212 of 215)
PASS: TRITON-SHARED :: Conversion/StructuredToMemref/addptr_mul_const_const.mlir (213 of 215)
PASS: TRITON-SHARED :: Conversion/TritonToLinalg/convert_splat_float.mlir (214 of 215)
FAIL: TRITON-SHARED :: Conversion/StructuredToMemref/ridiculously_nested_loops.mlir (215 of 215)
******************** TEST 'TRITON-SHARED :: Conversion/StructuredToMemref/ridiculously_nested_loops.mlir' FAILED ********************
Exit Code: 2

Command Output (stderr):
--
RUN: at line 1: /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir | FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir
+ /home/nhat/github/triton_shared/triton/python/build/cmake.linux-x86_64-cpython-3.8/third_party/triton_shared/tools/triton-shared-opt/triton-shared-opt --triton-to-linalg-experimental /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir
+ FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir
processing val
%c0_i32_0 = arith.constant 0 : i32
processing val
%c0_i32 = arith.constant 0 : i32
for op
%68 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
%67 = arith.addi %arg77, %4 : index
<block argument> of type 'tensor<2x2xf32>' at index: 4
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 5
<block argument> of type 'index' at index: 6
for op
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 2
<block argument> of type 'index' at index: 3
<block argument> of type 'tensor<2x2xf32>' at index: 4
<block argument> of type 'tensor<2x2xf32>' at index: 5
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 6
<block argument> of type 'index' at index: 7
for op
<block argument> of type 'tensor<2x2xf32>' at index: 6
%55 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%54, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
%54 = arith.addi %arg61, %4 : index
<block argument> of type 'tensor<2x2xf32>' at index: 7
%56 = "tts.load"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
%62 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
%61 = arith.addi %59, %4 : index
for op
%50 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%49, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
%49 = arith.addi %arg53, %4 : index
<block argument> of type 'tensor<2x2xf32>' at index: 4
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 5
<block argument> of type 'index' at index: 6
<block argument> of type 'tensor<2x2xf32>' at index: 7
%51 = "tts.load"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
for op
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 2
<block argument> of type 'index' at index: 3
<block argument> of type 'tensor<2x2xf32>' at index: 4
<block argument> of type 'tensor<2x2xf32>' at index: 5
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 6
<block argument> of type 'index' at index: 7
%47 = "tts.load"(%46) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
for op
<block argument> of type 'tensor<2x2xf32>' at index: 6
%37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
%36 = arith.addi %arg37, %4 : index
<block argument> of type 'tensor<2x2xf32>' at index: 7
%38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
%44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
%43 = arith.addi %41, %4 : index
for op
%32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
%31 = arith.addi %arg29, %4 : index
<block argument> of type 'tensor<2x2xf32>' at index: 4
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 5
<block argument> of type 'index' at index: 6
<block argument> of type 'tensor<2x2xf32>' at index: 7
%33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
for op
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 2
<block argument> of type 'index' at index: 3
<block argument> of type 'tensor<2x2xf32>' at index: 4
<block argument> of type 'tensor<2x2xf32>' at index: 5
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 6
<block argument> of type 'index' at index: 7
%29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
for op
<block argument> of type 'tensor<2x2xf32>' at index: 4
%18 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%17, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
%17 = arith.addi %arg14, %4 : index
<block argument> of type 'tensor<2x2xf32>' at index: 5
%19 = "tts.load"(%18) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
%25 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%24, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
%24 = arith.addi %22, %4 : index
for op
%32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
%31 = arith.addi %arg29, %4 : index
<block argument> of type 'tensor<2x2xf32>' at index: 4
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 5
<block argument> of type 'index' at index: 6
for op
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 2
<block argument> of type 'index' at index: 3
<block argument> of type 'tensor<2x2xf32>' at index: 4
<block argument> of type 'tensor<2x2xf32>' at index: 5
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 6
<block argument> of type 'index' at index: 7
for op
%26:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %arg17, %arg21 = %18, %arg22 = %17, %arg23 = %arg18, %arg24 = %19, %arg25 = %25, %arg26 = %24) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
  %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
  %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %30:7 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26, %arg34 = %29) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
    %31 = arith.addi %arg29, %4 : index
    %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    %34:7 = scf.for %arg35 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg36 = %32, %arg37 = %31, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %arg33, %arg41 = %arg34, %arg42 = %33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
      %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %36 = arith.addi %arg37, %4 : index
      %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%35, %arg41) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %39 = arith.addi %arg40, %4 : index
      %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%40, %arg42) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %41 = arith.addi %39, %4 : index
      %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %43 = arith.addi %41, %4 : index
      %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %45:7 = scf.for %arg43 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg44 = %arg41, %arg45 = %37, %arg46 = %36, %arg47 = %arg42, %arg48 = %38, %arg49 = %44, %arg50 = %43) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %46 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %47 = "tts.load"(%46) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %48:7 = scf.for %arg51 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg52 = %arg45, %arg53 = %arg46, %arg54 = %arg47, %arg55 = %arg48, %arg56 = %arg49, %arg57 = %arg50, %arg58 = %47) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
          %49 = arith.addi %arg53, %4 : index
          %50 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%49, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %51 = "tts.load"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          %52:7 = scf.for %arg59 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg60 = %50, %arg61 = %49, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %arg57, %arg65 = %arg58, %arg66 = %51) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
            %53 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg64, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %54 = arith.addi %arg61, %4 : index
            %55 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%54, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %56 = "tts.load"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            "tts.store"(%53, %arg65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %57 = arith.addi %arg64, %4 : index
            %58 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%57, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%58, %arg66) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %59 = arith.addi %57, %4 : index
            %60 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%59, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%60, %56) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %61 = arith.addi %59, %4 : index
            %62 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %63:7 = scf.for %arg67 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg68 = %arg65, %arg69 = %55, %arg70 = %54, %arg71 = %arg66, %arg72 = %56, %arg73 = %62, %arg74 = %61) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
              %64 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg70, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %65 = "tts.load"(%64) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %66:6 = scf.for %arg75 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg76 = %arg69, %arg77 = %arg70, %arg78 = %arg71, %arg79 = %arg72, %arg80 = %arg73, %arg81 = %arg74) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                %67 = arith.addi %arg77, %4 : index
                %68 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %69 = "tts.load"(%68) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                %70:5 = scf.for %arg82 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg83 = %68, %arg84 = %67, %arg85 = %arg79, %arg86 = %arg80, %arg87 = %arg81) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                  %71 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg87, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %72 = arith.addi %arg84, %4 : index
                  %73 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%72, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  "tts.store"(%71, %65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %75 = arith.addi %arg87, %4 : index
                  %76 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%75, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%76, %69) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %77 = arith.addi %75, %4 : index
                  %78 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%77, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%78, %74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %79 = arith.addi %77, %4 : index
                  %80 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%79, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  scf.yield %73, %72, %74, %80, %79 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                }
                scf.yield %70#0, %70#1, %69, %70#2, %70#3, %70#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
              }
              scf.yield %65, %66#0, %66#1, %66#2, %66#3, %66#4, %66#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
            }
            scf.yield %63#1, %63#2, %63#4, %63#5, %63#6, %63#0, %63#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
          }
          scf.yield %52#0, %52#1, %52#6, %52#2, %52#3, %52#4, %52#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
        }
        scf.yield %48#6, %48#0, %48#1, %48#2, %48#3, %48#4, %48#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
      }
      scf.yield %45#1, %45#2, %45#4, %45#5, %45#6, %45#0, %45#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
    }
    scf.yield %34#0, %34#1, %34#6, %34#2, %34#3, %34#4, %34#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
  }
  scf.yield %30#6, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
}
%26:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %arg17, %arg21 = %18, %arg22 = %17, %arg23 = %arg18, %arg24 = %19, %arg25 = %25, %arg26 = %24) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
  %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
  %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %30:7 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26, %arg34 = %29) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
    %31 = arith.addi %arg29, %4 : index
    %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    %34:7 = scf.for %arg35 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg36 = %32, %arg37 = %31, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %arg33, %arg41 = %arg34, %arg42 = %33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
      %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %36 = arith.addi %arg37, %4 : index
      %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%35, %arg41) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %39 = arith.addi %arg40, %4 : index
      %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%40, %arg42) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %41 = arith.addi %39, %4 : index
      %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %43 = arith.addi %41, %4 : index
      %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %45:7 = scf.for %arg43 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg44 = %arg41, %arg45 = %37, %arg46 = %36, %arg47 = %arg42, %arg48 = %38, %arg49 = %44, %arg50 = %43) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %46 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %47 = "tts.load"(%46) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %48:7 = scf.for %arg51 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg52 = %arg45, %arg53 = %arg46, %arg54 = %arg47, %arg55 = %arg48, %arg56 = %arg49, %arg57 = %arg50, %arg58 = %47) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
          %49 = arith.addi %arg53, %4 : index
          %50 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%49, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %51 = "tts.load"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          %52:7 = scf.for %arg59 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg60 = %50, %arg61 = %49, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %arg57, %arg65 = %arg58, %arg66 = %51) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
            %53 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg64, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %54 = arith.addi %arg61, %4 : index
            %55 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%54, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %56 = "tts.load"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            "tts.store"(%53, %arg65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %57 = arith.addi %arg64, %4 : index
            %58 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%57, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%58, %arg66) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %59 = arith.addi %57, %4 : index
            %60 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%59, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%60, %56) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %61 = arith.addi %59, %4 : index
            %62 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %63:7 = scf.for %arg67 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg68 = %arg65, %arg69 = %55, %arg70 = %54, %arg71 = %arg66, %arg72 = %56, %arg73 = %62, %arg74 = %61) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
              %64 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg70, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %65 = "tts.load"(%64) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %66:6 = scf.for %arg75 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg76 = %arg69, %arg77 = %arg70, %arg78 = %arg71, %arg79 = %arg72, %arg80 = %arg73, %arg81 = %arg74) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                %67 = arith.addi %arg77, %4 : index
                %68 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %69 = "tts.load"(%68) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                %70:5 = scf.for %arg82 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg83 = %68, %arg84 = %67, %arg85 = %arg79, %arg86 = %arg80, %arg87 = %arg81) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                  %71 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg87, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %72 = arith.addi %arg84, %4 : index
                  %73 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%72, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  "tts.store"(%71, %65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %75 = arith.addi %arg87, %4 : index
                  %76 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%75, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%76, %69) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %77 = arith.addi %75, %4 : index
                  %78 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%77, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%78, %74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %79 = arith.addi %77, %4 : index
                  %80 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%79, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  scf.yield %73, %72, %74, %80, %79 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                }
                scf.yield %70#0, %70#1, %69, %70#2, %70#3, %70#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
              }
              scf.yield %65, %66#0, %66#1, %66#2, %66#3, %66#4, %66#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
            }
            scf.yield %63#1, %63#2, %63#4, %63#5, %63#6, %63#0, %63#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
          }
          scf.yield %52#0, %52#1, %52#6, %52#2, %52#3, %52#4, %52#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
        }
        scf.yield %48#6, %48#0, %48#1, %48#2, %48#3, %48#4, %48#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
      }
      scf.yield %45#1, %45#2, %45#4, %45#5, %45#6, %45#0, %45#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
    }
    scf.yield %34#0, %34#1, %34#6, %34#2, %34#3, %34#4, %34#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
  }
  scf.yield %30#6, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
}
%26:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %arg17, %arg21 = %18, %arg22 = %17, %arg23 = %arg18, %arg24 = %19, %arg25 = %25, %arg26 = %24) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
  %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
  %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %30:7 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26, %arg34 = %29) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
    %31 = arith.addi %arg29, %4 : index
    %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    %34:7 = scf.for %arg35 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg36 = %32, %arg37 = %31, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %arg33, %arg41 = %arg34, %arg42 = %33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
      %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %36 = arith.addi %arg37, %4 : index
      %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%35, %arg41) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %39 = arith.addi %arg40, %4 : index
      %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%40, %arg42) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %41 = arith.addi %39, %4 : index
      %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %43 = arith.addi %41, %4 : index
      %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %45:7 = scf.for %arg43 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg44 = %arg41, %arg45 = %37, %arg46 = %36, %arg47 = %arg42, %arg48 = %38, %arg49 = %44, %arg50 = %43) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %46 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %47 = "tts.load"(%46) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %48:7 = scf.for %arg51 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg52 = %arg45, %arg53 = %arg46, %arg54 = %arg47, %arg55 = %arg48, %arg56 = %arg49, %arg57 = %arg50, %arg58 = %47) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
          %49 = arith.addi %arg53, %4 : index
          %50 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%49, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %51 = "tts.load"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          %52:7 = scf.for %arg59 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg60 = %50, %arg61 = %49, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %arg57, %arg65 = %arg58, %arg66 = %51) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
            %53 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg64, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %54 = arith.addi %arg61, %4 : index
            %55 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%54, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %56 = "tts.load"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            "tts.store"(%53, %arg65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %57 = arith.addi %arg64, %4 : index
            %58 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%57, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%58, %arg66) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %59 = arith.addi %57, %4 : index
            %60 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%59, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%60, %56) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %61 = arith.addi %59, %4 : index
            %62 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %63:7 = scf.for %arg67 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg68 = %arg65, %arg69 = %55, %arg70 = %54, %arg71 = %arg66, %arg72 = %56, %arg73 = %62, %arg74 = %61) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
              %64 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg70, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %65 = "tts.load"(%64) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %66:6 = scf.for %arg75 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg76 = %arg69, %arg77 = %arg70, %arg78 = %arg71, %arg79 = %arg72, %arg80 = %arg73, %arg81 = %arg74) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                %67 = arith.addi %arg77, %4 : index
                %68 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %69 = "tts.load"(%68) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                %70:5 = scf.for %arg82 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg83 = %68, %arg84 = %67, %arg85 = %arg79, %arg86 = %arg80, %arg87 = %arg81) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                  %71 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg87, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %72 = arith.addi %arg84, %4 : index
                  %73 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%72, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  "tts.store"(%71, %65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %75 = arith.addi %arg87, %4 : index
                  %76 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%75, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%76, %69) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %77 = arith.addi %75, %4 : index
                  %78 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%77, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%78, %74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %79 = arith.addi %77, %4 : index
                  %80 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%79, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  scf.yield %73, %72, %74, %80, %79 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                }
                scf.yield %70#0, %70#1, %69, %70#2, %70#3, %70#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
              }
              scf.yield %65, %66#0, %66#1, %66#2, %66#3, %66#4, %66#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
            }
            scf.yield %63#1, %63#2, %63#4, %63#5, %63#6, %63#0, %63#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
          }
          scf.yield %52#0, %52#1, %52#6, %52#2, %52#3, %52#4, %52#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
        }
        scf.yield %48#6, %48#0, %48#1, %48#2, %48#3, %48#4, %48#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
      }
      scf.yield %45#1, %45#2, %45#4, %45#5, %45#6, %45#0, %45#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
    }
    scf.yield %34#0, %34#1, %34#6, %34#2, %34#3, %34#4, %34#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
  }
  scf.yield %30#6, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
}
%26:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %arg17, %arg21 = %18, %arg22 = %17, %arg23 = %arg18, %arg24 = %19, %arg25 = %25, %arg26 = %24) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
  %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
  %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %30:7 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26, %arg34 = %29) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
    %31 = arith.addi %arg29, %4 : index
    %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    %34:7 = scf.for %arg35 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg36 = %32, %arg37 = %31, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %arg33, %arg41 = %arg34, %arg42 = %33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
      %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %36 = arith.addi %arg37, %4 : index
      %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%35, %arg41) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %39 = arith.addi %arg40, %4 : index
      %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%40, %arg42) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %41 = arith.addi %39, %4 : index
      %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %43 = arith.addi %41, %4 : index
      %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %45:7 = scf.for %arg43 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg44 = %arg41, %arg45 = %37, %arg46 = %36, %arg47 = %arg42, %arg48 = %38, %arg49 = %44, %arg50 = %43) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %46 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %47 = "tts.load"(%46) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %48:7 = scf.for %arg51 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg52 = %arg45, %arg53 = %arg46, %arg54 = %arg47, %arg55 = %arg48, %arg56 = %arg49, %arg57 = %arg50, %arg58 = %47) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
          %49 = arith.addi %arg53, %4 : index
          %50 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%49, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %51 = "tts.load"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          %52:7 = scf.for %arg59 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg60 = %50, %arg61 = %49, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %arg57, %arg65 = %arg58, %arg66 = %51) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
            %53 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg64, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %54 = arith.addi %arg61, %4 : index
            %55 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%54, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %56 = "tts.load"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            "tts.store"(%53, %arg65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %57 = arith.addi %arg64, %4 : index
            %58 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%57, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%58, %arg66) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %59 = arith.addi %57, %4 : index
            %60 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%59, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%60, %56) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %61 = arith.addi %59, %4 : index
            %62 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %63:7 = scf.for %arg67 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg68 = %arg65, %arg69 = %55, %arg70 = %54, %arg71 = %arg66, %arg72 = %56, %arg73 = %62, %arg74 = %61) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
              %64 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg70, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %65 = "tts.load"(%64) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %66:6 = scf.for %arg75 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg76 = %arg69, %arg77 = %arg70, %arg78 = %arg71, %arg79 = %arg72, %arg80 = %arg73, %arg81 = %arg74) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                %67 = arith.addi %arg77, %4 : index
                %68 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %69 = "tts.load"(%68) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                %70:5 = scf.for %arg82 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg83 = %68, %arg84 = %67, %arg85 = %arg79, %arg86 = %arg80, %arg87 = %arg81) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                  %71 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg87, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %72 = arith.addi %arg84, %4 : index
                  %73 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%72, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  "tts.store"(%71, %65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %75 = arith.addi %arg87, %4 : index
                  %76 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%75, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%76, %69) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %77 = arith.addi %75, %4 : index
                  %78 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%77, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%78, %74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %79 = arith.addi %77, %4 : index
                  %80 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%79, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  scf.yield %73, %72, %74, %80, %79 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                }
                scf.yield %70#0, %70#1, %69, %70#2, %70#3, %70#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
              }
              scf.yield %65, %66#0, %66#1, %66#2, %66#3, %66#4, %66#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
            }
            scf.yield %63#1, %63#2, %63#4, %63#5, %63#6, %63#0, %63#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
          }
          scf.yield %52#0, %52#1, %52#6, %52#2, %52#3, %52#4, %52#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
        }
        scf.yield %48#6, %48#0, %48#1, %48#2, %48#3, %48#4, %48#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
      }
      scf.yield %45#1, %45#2, %45#4, %45#5, %45#6, %45#0, %45#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
    }
    scf.yield %34#0, %34#1, %34#6, %34#2, %34#3, %34#4, %34#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
  }
  scf.yield %30#6, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
}
%26:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %arg17, %arg21 = %18, %arg22 = %17, %arg23 = %arg18, %arg24 = %19, %arg25 = %25, %arg26 = %24) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
  %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
  %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %30:7 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26, %arg34 = %29) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
    %31 = arith.addi %arg29, %4 : index
    %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    %34:7 = scf.for %arg35 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg36 = %32, %arg37 = %31, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %arg33, %arg41 = %arg34, %arg42 = %33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
      %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %36 = arith.addi %arg37, %4 : index
      %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%35, %arg41) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %39 = arith.addi %arg40, %4 : index
      %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%40, %arg42) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %41 = arith.addi %39, %4 : index
      %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %43 = arith.addi %41, %4 : index
      %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %45:7 = scf.for %arg43 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg44 = %arg41, %arg45 = %37, %arg46 = %36, %arg47 = %arg42, %arg48 = %38, %arg49 = %44, %arg50 = %43) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %46 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %47 = "tts.load"(%46) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %48:7 = scf.for %arg51 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg52 = %arg45, %arg53 = %arg46, %arg54 = %arg47, %arg55 = %arg48, %arg56 = %arg49, %arg57 = %arg50, %arg58 = %47) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
          %49 = arith.addi %arg53, %4 : index
          %50 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%49, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %51 = "tts.load"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          %52:7 = scf.for %arg59 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg60 = %50, %arg61 = %49, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %arg57, %arg65 = %arg58, %arg66 = %51) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
            %53 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg64, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %54 = arith.addi %arg61, %4 : index
            %55 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%54, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %56 = "tts.load"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            "tts.store"(%53, %arg65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %57 = arith.addi %arg64, %4 : index
            %58 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%57, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%58, %arg66) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %59 = arith.addi %57, %4 : index
            %60 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%59, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%60, %56) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %61 = arith.addi %59, %4 : index
            %62 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %63:7 = scf.for %arg67 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg68 = %arg65, %arg69 = %55, %arg70 = %54, %arg71 = %arg66, %arg72 = %56, %arg73 = %62, %arg74 = %61) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
              %64 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg70, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %65 = "tts.load"(%64) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %66:6 = scf.for %arg75 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg76 = %arg69, %arg77 = %arg70, %arg78 = %arg71, %arg79 = %arg72, %arg80 = %arg73, %arg81 = %arg74) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                %67 = arith.addi %arg77, %4 : index
                %68 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %69 = "tts.load"(%68) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                %70:5 = scf.for %arg82 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg83 = %68, %arg84 = %67, %arg85 = %arg79, %arg86 = %arg80, %arg87 = %arg81) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                  %71 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg87, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %72 = arith.addi %arg84, %4 : index
                  %73 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%72, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  "tts.store"(%71, %65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %75 = arith.addi %arg87, %4 : index
                  %76 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%75, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%76, %69) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %77 = arith.addi %75, %4 : index
                  %78 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%77, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%78, %74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %79 = arith.addi %77, %4 : index
                  %80 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%79, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  scf.yield %73, %72, %74, %80, %79 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                }
                scf.yield %70#0, %70#1, %69, %70#2, %70#3, %70#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
              }
              scf.yield %65, %66#0, %66#1, %66#2, %66#3, %66#4, %66#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
            }
            scf.yield %63#1, %63#2, %63#4, %63#5, %63#6, %63#0, %63#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
          }
          scf.yield %52#0, %52#1, %52#6, %52#2, %52#3, %52#4, %52#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
        }
        scf.yield %48#6, %48#0, %48#1, %48#2, %48#3, %48#4, %48#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
      }
      scf.yield %45#1, %45#2, %45#4, %45#5, %45#6, %45#0, %45#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
    }
    scf.yield %34#0, %34#1, %34#6, %34#2, %34#3, %34#4, %34#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
  }
  scf.yield %30#6, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
}
%26:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %arg17, %arg21 = %18, %arg22 = %17, %arg23 = %arg18, %arg24 = %19, %arg25 = %25, %arg26 = %24) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
  %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
  %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %30:7 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26, %arg34 = %29) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
    %31 = arith.addi %arg29, %4 : index
    %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    %34:7 = scf.for %arg35 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg36 = %32, %arg37 = %31, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %arg33, %arg41 = %arg34, %arg42 = %33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
      %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %36 = arith.addi %arg37, %4 : index
      %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%35, %arg41) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %39 = arith.addi %arg40, %4 : index
      %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%40, %arg42) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %41 = arith.addi %39, %4 : index
      %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %43 = arith.addi %41, %4 : index
      %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %45:7 = scf.for %arg43 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg44 = %arg41, %arg45 = %37, %arg46 = %36, %arg47 = %arg42, %arg48 = %38, %arg49 = %44, %arg50 = %43) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %46 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %47 = "tts.load"(%46) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %48:7 = scf.for %arg51 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg52 = %arg45, %arg53 = %arg46, %arg54 = %arg47, %arg55 = %arg48, %arg56 = %arg49, %arg57 = %arg50, %arg58 = %47) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
          %49 = arith.addi %arg53, %4 : index
          %50 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%49, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %51 = "tts.load"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          %52:7 = scf.for %arg59 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg60 = %50, %arg61 = %49, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %arg57, %arg65 = %arg58, %arg66 = %51) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
            %53 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg64, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %54 = arith.addi %arg61, %4 : index
            %55 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%54, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %56 = "tts.load"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            "tts.store"(%53, %arg65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %57 = arith.addi %arg64, %4 : index
            %58 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%57, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%58, %arg66) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %59 = arith.addi %57, %4 : index
            %60 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%59, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%60, %56) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %61 = arith.addi %59, %4 : index
            %62 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %63:7 = scf.for %arg67 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg68 = %arg65, %arg69 = %55, %arg70 = %54, %arg71 = %arg66, %arg72 = %56, %arg73 = %62, %arg74 = %61) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
              %64 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg70, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %65 = "tts.load"(%64) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %66:6 = scf.for %arg75 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg76 = %arg69, %arg77 = %arg70, %arg78 = %arg71, %arg79 = %arg72, %arg80 = %arg73, %arg81 = %arg74) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                %67 = arith.addi %arg77, %4 : index
                %68 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %69 = "tts.load"(%68) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                %70:5 = scf.for %arg82 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg83 = %68, %arg84 = %67, %arg85 = %arg79, %arg86 = %arg80, %arg87 = %arg81) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                  %71 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg87, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %72 = arith.addi %arg84, %4 : index
                  %73 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%72, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  "tts.store"(%71, %65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %75 = arith.addi %arg87, %4 : index
                  %76 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%75, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%76, %69) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %77 = arith.addi %75, %4 : index
                  %78 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%77, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%78, %74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %79 = arith.addi %77, %4 : index
                  %80 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%79, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  scf.yield %73, %72, %74, %80, %79 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                }
                scf.yield %70#0, %70#1, %69, %70#2, %70#3, %70#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
              }
              scf.yield %65, %66#0, %66#1, %66#2, %66#3, %66#4, %66#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
            }
            scf.yield %63#1, %63#2, %63#4, %63#5, %63#6, %63#0, %63#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
          }
          scf.yield %52#0, %52#1, %52#6, %52#2, %52#3, %52#4, %52#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
        }
        scf.yield %48#6, %48#0, %48#1, %48#2, %48#3, %48#4, %48#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
      }
      scf.yield %45#1, %45#2, %45#4, %45#5, %45#6, %45#0, %45#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
    }
    scf.yield %34#0, %34#1, %34#6, %34#2, %34#3, %34#4, %34#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
  }
  scf.yield %30#6, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
}
%26:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %arg17, %arg21 = %18, %arg22 = %17, %arg23 = %arg18, %arg24 = %19, %arg25 = %25, %arg26 = %24) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
  %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
  %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %30:7 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26, %arg34 = %29) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
    %31 = arith.addi %arg29, %4 : index
    %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    %34:7 = scf.for %arg35 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg36 = %32, %arg37 = %31, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %arg33, %arg41 = %arg34, %arg42 = %33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
      %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %36 = arith.addi %arg37, %4 : index
      %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%35, %arg41) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %39 = arith.addi %arg40, %4 : index
      %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%40, %arg42) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %41 = arith.addi %39, %4 : index
      %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %43 = arith.addi %41, %4 : index
      %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %45:7 = scf.for %arg43 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg44 = %arg41, %arg45 = %37, %arg46 = %36, %arg47 = %arg42, %arg48 = %38, %arg49 = %44, %arg50 = %43) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %46 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %47 = "tts.load"(%46) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %48:7 = scf.for %arg51 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg52 = %arg45, %arg53 = %arg46, %arg54 = %arg47, %arg55 = %arg48, %arg56 = %arg49, %arg57 = %arg50, %arg58 = %47) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
          %49 = arith.addi %arg53, %4 : index
          %50 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%49, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %51 = "tts.load"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          %52:7 = scf.for %arg59 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg60 = %50, %arg61 = %49, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %arg57, %arg65 = %arg58, %arg66 = %51) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
            %53 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg64, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %54 = arith.addi %arg61, %4 : index
            %55 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%54, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %56 = "tts.load"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            "tts.store"(%53, %arg65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %57 = arith.addi %arg64, %4 : index
            %58 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%57, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%58, %arg66) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %59 = arith.addi %57, %4 : index
            %60 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%59, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%60, %56) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %61 = arith.addi %59, %4 : index
            %62 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %63:7 = scf.for %arg67 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg68 = %arg65, %arg69 = %55, %arg70 = %54, %arg71 = %arg66, %arg72 = %56, %arg73 = %62, %arg74 = %61) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
              %64 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg70, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %65 = "tts.load"(%64) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %66:6 = scf.for %arg75 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg76 = %arg69, %arg77 = %arg70, %arg78 = %arg71, %arg79 = %arg72, %arg80 = %arg73, %arg81 = %arg74) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                %67 = arith.addi %arg77, %4 : index
                %68 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %69 = "tts.load"(%68) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                %70:5 = scf.for %arg82 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg83 = %68, %arg84 = %67, %arg85 = %arg79, %arg86 = %arg80, %arg87 = %arg81) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                  %71 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg87, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %72 = arith.addi %arg84, %4 : index
                  %73 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%72, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  "tts.store"(%71, %65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %75 = arith.addi %arg87, %4 : index
                  %76 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%75, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%76, %69) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %77 = arith.addi %75, %4 : index
                  %78 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%77, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%78, %74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %79 = arith.addi %77, %4 : index
                  %80 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%79, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  scf.yield %73, %72, %74, %80, %79 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                }
                scf.yield %70#0, %70#1, %69, %70#2, %70#3, %70#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
              }
              scf.yield %65, %66#0, %66#1, %66#2, %66#3, %66#4, %66#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
            }
            scf.yield %63#1, %63#2, %63#4, %63#5, %63#6, %63#0, %63#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
          }
          scf.yield %52#0, %52#1, %52#6, %52#2, %52#3, %52#4, %52#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
        }
        scf.yield %48#6, %48#0, %48#1, %48#2, %48#3, %48#4, %48#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
      }
      scf.yield %45#1, %45#2, %45#4, %45#5, %45#6, %45#0, %45#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
    }
    scf.yield %34#0, %34#1, %34#6, %34#2, %34#3, %34#4, %34#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
  }
  scf.yield %30#6, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
}
for op
%11 = arith.addi %arg9, %4 : index
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 2
<block argument> of type 'index' at index: 3
<block argument> of type 'tensor<2x2xf32>' at index: 4
%13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
for op
<block argument> of type 'index' at index: 1
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 2
<block argument> of type 'index' at index: 3
%7 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
for op
%15 = arith.addi %arg13, %4 : index
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 2
<block argument> of type 'index' at index: 3
for op
<block argument> of type 'index' at index: 1
<block argument> of type 'tensor<2x2x!tt.ptr<f32>>' at index: 2
<block argument> of type 'index' at index: 3
for op
%8:4 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5, %arg10 = %arg6, %arg11 = %arg7, %arg12 = %7) -> (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
  %11 = arith.addi %arg9, %4 : index
  %12 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%11, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
  %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %14:5 = scf.for %arg13 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg14 = %11, %arg15 = %arg10, %arg16 = %arg11, %arg17 = %arg12, %arg18 = %13) -> (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
    %16 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg16, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %17 = arith.addi %arg14, %4 : index
    %18 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%17, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %19 = "tts.load"(%18) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    "tts.store"(%16, %arg17) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
    %20 = arith.addi %arg16, %4 : index
    %21 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%20, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    "tts.store"(%21, %arg18) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
    %22 = arith.addi %20, %4 : index
    %23 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    "tts.store"(%23, %19) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
    %24 = arith.addi %22, %4 : index
    %25 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%24, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %26:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %arg17, %arg21 = %18, %arg22 = %17, %arg23 = %arg18, %arg24 = %19, %arg25 = %25, %arg26 = %24) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %30:7 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26, %arg34 = %29) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
        %31 = arith.addi %arg29, %4 : index
        %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %34:7 = scf.for %arg35 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg36 = %32, %arg37 = %31, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %arg33, %arg41 = %arg34, %arg42 = %33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
          %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %36 = arith.addi %arg37, %4 : index
          %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          "tts.store"(%35, %arg41) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %39 = arith.addi %arg40, %4 : index
          %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%40, %arg42) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %41 = arith.addi %39, %4 : index
          %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %43 = arith.addi %41, %4 : index
          %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %45:7 = scf.for %arg43 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg44 = %arg41, %arg45 = %37, %arg46 = %36, %arg47 = %arg42, %arg48 = %38, %arg49 = %44, %arg50 = %43) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
            %46 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %47 = "tts.load"(%46) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            %48:7 = scf.for %arg51 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg52 = %arg45, %arg53 = %arg46, %arg54 = %arg47, %arg55 = %arg48, %arg56 = %arg49, %arg57 = %arg50, %arg58 = %47) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
              %49 = arith.addi %arg53, %4 : index
              %50 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%49, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %51 = "tts.load"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %52:7 = scf.for %arg59 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg60 = %50, %arg61 = %49, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %arg57, %arg65 = %arg58, %arg66 = %51) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
                %53 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg64, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %54 = arith.addi %arg61, %4 : index
                %55 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%54, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %56 = "tts.load"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                "tts.store"(%53, %arg65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %57 = arith.addi %arg64, %4 : index
                %58 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%57, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%58, %arg66) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %59 = arith.addi %57, %4 : index
                %60 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%59, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%60, %56) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %61 = arith.addi %59, %4 : index
                %62 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %63:7 = scf.for %arg67 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg68 = %arg65, %arg69 = %55, %arg70 = %54, %arg71 = %arg66, %arg72 = %56, %arg73 = %62, %arg74 = %61) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                  %64 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg70, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %65 = "tts.load"(%64) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  %66:6 = scf.for %arg75 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg76 = %arg69, %arg77 = %arg70, %arg78 = %arg71, %arg79 = %arg72, %arg80 = %arg73, %arg81 = %arg74) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                    %67 = arith.addi %arg77, %4 : index
                    %68 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                    %69 = "tts.load"(%68) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                    %70:5 = scf.for %arg82 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg83 = %68, %arg84 = %67, %arg85 = %arg79, %arg86 = %arg80, %arg87 = %arg81) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                      %71 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg87, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      %72 = arith.addi %arg84, %4 : index
                      %73 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%72, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                      "tts.store"(%71, %65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %75 = arith.addi %arg87, %4 : index
                      %76 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%75, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      "tts.store"(%76, %69) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %77 = arith.addi %75, %4 : index
                      %78 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%77, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      "tts.store"(%78, %74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %79 = arith.addi %77, %4 : index
                      %80 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%79, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      scf.yield %73, %72, %74, %80, %79 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                    }
                    scf.yield %70#0, %70#1, %69, %70#2, %70#3, %70#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                  }
                  scf.yield %65, %66#0, %66#1, %66#2, %66#3, %66#4, %66#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                }
                scf.yield %63#1, %63#2, %63#4, %63#5, %63#6, %63#0, %63#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
              }
              scf.yield %52#0, %52#1, %52#6, %52#2, %52#3, %52#4, %52#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
            }
            scf.yield %48#6, %48#0, %48#1, %48#2, %48#3, %48#4, %48#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
          }
          scf.yield %45#1, %45#2, %45#4, %45#5, %45#6, %45#0, %45#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
        }
        scf.yield %34#0, %34#1, %34#6, %34#2, %34#3, %34#4, %34#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
      }
      scf.yield %30#6, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
    }
    %27:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %26#0, %arg21 = %26#1, %arg22 = %26#2, %arg23 = %26#3, %arg24 = %26#4, %arg25 = %26#5, %arg26 = %26#6) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %30:6 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %31 = arith.addi %arg29, %4 : index
        %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %34:5 = scf.for %arg34 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg35 = %32, %arg36 = %31, %arg37 = %arg31, %arg38 = %arg32, %arg39 = %arg33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
          %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %36 = arith.addi %arg36, %4 : index
          %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          "tts.store"(%35, %29) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %39 = arith.addi %arg39, %4 : index
          %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%40, %33) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %41 = arith.addi %39, %4 : index
          %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %43 = arith.addi %41, %4 : index
          %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          scf.yield %37, %36, %38, %44, %43 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
        }
        scf.yield %34#0, %34#1, %33, %34#2, %34#3, %34#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
      }
      scf.yield %29, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
    }
    scf.yield %27#2, %27#5, %27#6, %27#0, %27#3 : index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
  }
  %15 = arith.addi %14#0, %4 : index
  scf.yield %15, %14#1, %14#2, %14#3 : index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
}
%8:4 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5, %arg10 = %arg6, %arg11 = %arg7, %arg12 = %7) -> (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
  %11 = arith.addi %arg9, %4 : index
  %12 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%11, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
  %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %14:5 = scf.for %arg13 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg14 = %11, %arg15 = %arg10, %arg16 = %arg11, %arg17 = %arg12, %arg18 = %13) -> (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
    %16 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg16, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %17 = arith.addi %arg14, %4 : index
    %18 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%17, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %19 = "tts.load"(%18) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    "tts.store"(%16, %arg17) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
    %20 = arith.addi %arg16, %4 : index
    %21 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%20, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    "tts.store"(%21, %arg18) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
    %22 = arith.addi %20, %4 : index
    %23 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    "tts.store"(%23, %19) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
    %24 = arith.addi %22, %4 : index
    %25 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%24, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %26:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %arg17, %arg21 = %18, %arg22 = %17, %arg23 = %arg18, %arg24 = %19, %arg25 = %25, %arg26 = %24) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %30:7 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26, %arg34 = %29) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
        %31 = arith.addi %arg29, %4 : index
        %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %34:7 = scf.for %arg35 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg36 = %32, %arg37 = %31, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %arg33, %arg41 = %arg34, %arg42 = %33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
          %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %36 = arith.addi %arg37, %4 : index
          %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          "tts.store"(%35, %arg41) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %39 = arith.addi %arg40, %4 : index
          %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%40, %arg42) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %41 = arith.addi %39, %4 : index
          %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %43 = arith.addi %41, %4 : index
          %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %45:7 = scf.for %arg43 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg44 = %arg41, %arg45 = %37, %arg46 = %36, %arg47 = %arg42, %arg48 = %38, %arg49 = %44, %arg50 = %43) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
            %46 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %47 = "tts.load"(%46) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            %48:7 = scf.for %arg51 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg52 = %arg45, %arg53 = %arg46, %arg54 = %arg47, %arg55 = %arg48, %arg56 = %arg49, %arg57 = %arg50, %arg58 = %47) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
              %49 = arith.addi %arg53, %4 : index
              %50 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%49, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %51 = "tts.load"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %52:7 = scf.for %arg59 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg60 = %50, %arg61 = %49, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %arg57, %arg65 = %arg58, %arg66 = %51) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
                %53 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg64, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %54 = arith.addi %arg61, %4 : index
                %55 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%54, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %56 = "tts.load"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                "tts.store"(%53, %arg65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %57 = arith.addi %arg64, %4 : index
                %58 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%57, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%58, %arg66) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %59 = arith.addi %57, %4 : index
                %60 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%59, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%60, %56) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %61 = arith.addi %59, %4 : index
                %62 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %63:7 = scf.for %arg67 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg68 = %arg65, %arg69 = %55, %arg70 = %54, %arg71 = %arg66, %arg72 = %56, %arg73 = %62, %arg74 = %61) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                  %64 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg70, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %65 = "tts.load"(%64) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  %66:6 = scf.for %arg75 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg76 = %arg69, %arg77 = %arg70, %arg78 = %arg71, %arg79 = %arg72, %arg80 = %arg73, %arg81 = %arg74) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                    %67 = arith.addi %arg77, %4 : index
                    %68 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                    %69 = "tts.load"(%68) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                    %70:5 = scf.for %arg82 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg83 = %68, %arg84 = %67, %arg85 = %arg79, %arg86 = %arg80, %arg87 = %arg81) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                      %71 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg87, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      %72 = arith.addi %arg84, %4 : index
                      %73 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%72, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                      "tts.store"(%71, %65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %75 = arith.addi %arg87, %4 : index
                      %76 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%75, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      "tts.store"(%76, %69) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %77 = arith.addi %75, %4 : index
                      %78 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%77, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      "tts.store"(%78, %74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %79 = arith.addi %77, %4 : index
                      %80 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%79, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      scf.yield %73, %72, %74, %80, %79 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                    }
                    scf.yield %70#0, %70#1, %69, %70#2, %70#3, %70#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                  }
                  scf.yield %65, %66#0, %66#1, %66#2, %66#3, %66#4, %66#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                }
                scf.yield %63#1, %63#2, %63#4, %63#5, %63#6, %63#0, %63#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
              }
              scf.yield %52#0, %52#1, %52#6, %52#2, %52#3, %52#4, %52#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
            }
            scf.yield %48#6, %48#0, %48#1, %48#2, %48#3, %48#4, %48#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
          }
          scf.yield %45#1, %45#2, %45#4, %45#5, %45#6, %45#0, %45#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
        }
        scf.yield %34#0, %34#1, %34#6, %34#2, %34#3, %34#4, %34#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
      }
      scf.yield %30#6, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
    }
    %27:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %26#0, %arg21 = %26#1, %arg22 = %26#2, %arg23 = %26#3, %arg24 = %26#4, %arg25 = %26#5, %arg26 = %26#6) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %30:6 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %31 = arith.addi %arg29, %4 : index
        %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %34:5 = scf.for %arg34 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg35 = %32, %arg36 = %31, %arg37 = %arg31, %arg38 = %arg32, %arg39 = %arg33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
          %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %36 = arith.addi %arg36, %4 : index
          %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          "tts.store"(%35, %29) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %39 = arith.addi %arg39, %4 : index
          %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%40, %33) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %41 = arith.addi %39, %4 : index
          %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %43 = arith.addi %41, %4 : index
          %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          scf.yield %37, %36, %38, %44, %43 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
        }
        scf.yield %34#0, %34#1, %33, %34#2, %34#3, %34#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
      }
      scf.yield %29, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
    }
    scf.yield %27#2, %27#5, %27#6, %27#0, %27#3 : index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
  }
  %15 = arith.addi %14#0, %4 : index
  scf.yield %15, %14#1, %14#2, %14#3 : index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
}
%8:4 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5, %arg10 = %arg6, %arg11 = %arg7, %arg12 = %7) -> (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
  %11 = arith.addi %arg9, %4 : index
  %12 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%11, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
  %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %14:5 = scf.for %arg13 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg14 = %11, %arg15 = %arg10, %arg16 = %arg11, %arg17 = %arg12, %arg18 = %13) -> (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
    %16 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg16, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %17 = arith.addi %arg14, %4 : index
    %18 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%17, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %19 = "tts.load"(%18) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    "tts.store"(%16, %arg17) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
    %20 = arith.addi %arg16, %4 : index
    %21 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%20, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    "tts.store"(%21, %arg18) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
    %22 = arith.addi %20, %4 : index
    %23 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    "tts.store"(%23, %19) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
    %24 = arith.addi %22, %4 : index
    %25 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%24, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %26:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %arg17, %arg21 = %18, %arg22 = %17, %arg23 = %arg18, %arg24 = %19, %arg25 = %25, %arg26 = %24) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %30:7 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26, %arg34 = %29) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
        %31 = arith.addi %arg29, %4 : index
        %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %34:7 = scf.for %arg35 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg36 = %32, %arg37 = %31, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %arg33, %arg41 = %arg34, %arg42 = %33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
          %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %36 = arith.addi %arg37, %4 : index
          %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          "tts.store"(%35, %arg41) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %39 = arith.addi %arg40, %4 : index
          %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%40, %arg42) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %41 = arith.addi %39, %4 : index
          %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %43 = arith.addi %41, %4 : index
          %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %45:7 = scf.for %arg43 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg44 = %arg41, %arg45 = %37, %arg46 = %36, %arg47 = %arg42, %arg48 = %38, %arg49 = %44, %arg50 = %43) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
            %46 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %47 = "tts.load"(%46) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            %48:7 = scf.for %arg51 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg52 = %arg45, %arg53 = %arg46, %arg54 = %arg47, %arg55 = %arg48, %arg56 = %arg49, %arg57 = %arg50, %arg58 = %47) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
              %49 = arith.addi %arg53, %4 : index
              %50 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%49, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %51 = "tts.load"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %52:7 = scf.for %arg59 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg60 = %50, %arg61 = %49, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %arg57, %arg65 = %arg58, %arg66 = %51) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
                %53 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg64, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %54 = arith.addi %arg61, %4 : index
                %55 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%54, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %56 = "tts.load"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                "tts.store"(%53, %arg65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %57 = arith.addi %arg64, %4 : index
                %58 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%57, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%58, %arg66) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %59 = arith.addi %57, %4 : index
                %60 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%59, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%60, %56) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %61 = arith.addi %59, %4 : index
                %62 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %63:7 = scf.for %arg67 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg68 = %arg65, %arg69 = %55, %arg70 = %54, %arg71 = %arg66, %arg72 = %56, %arg73 = %62, %arg74 = %61) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                  %64 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg70, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %65 = "tts.load"(%64) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  %66:6 = scf.for %arg75 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg76 = %arg69, %arg77 = %arg70, %arg78 = %arg71, %arg79 = %arg72, %arg80 = %arg73, %arg81 = %arg74) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                    %67 = arith.addi %arg77, %4 : index
                    %68 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                    %69 = "tts.load"(%68) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                    %70:5 = scf.for %arg82 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg83 = %68, %arg84 = %67, %arg85 = %arg79, %arg86 = %arg80, %arg87 = %arg81) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                      %71 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg87, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      %72 = arith.addi %arg84, %4 : index
                      %73 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%72, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                      "tts.store"(%71, %65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %75 = arith.addi %arg87, %4 : index
                      %76 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%75, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      "tts.store"(%76, %69) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %77 = arith.addi %75, %4 : index
                      %78 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%77, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      "tts.store"(%78, %74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %79 = arith.addi %77, %4 : index
                      %80 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%79, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      scf.yield %73, %72, %74, %80, %79 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                    }
                    scf.yield %70#0, %70#1, %69, %70#2, %70#3, %70#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                  }
                  scf.yield %65, %66#0, %66#1, %66#2, %66#3, %66#4, %66#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                }
                scf.yield %63#1, %63#2, %63#4, %63#5, %63#6, %63#0, %63#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
              }
              scf.yield %52#0, %52#1, %52#6, %52#2, %52#3, %52#4, %52#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
            }
            scf.yield %48#6, %48#0, %48#1, %48#2, %48#3, %48#4, %48#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
          }
          scf.yield %45#1, %45#2, %45#4, %45#5, %45#6, %45#0, %45#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
        }
        scf.yield %34#0, %34#1, %34#6, %34#2, %34#3, %34#4, %34#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
      }
      scf.yield %30#6, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
    }
    %27:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %26#0, %arg21 = %26#1, %arg22 = %26#2, %arg23 = %26#3, %arg24 = %26#4, %arg25 = %26#5, %arg26 = %26#6) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %30:6 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %31 = arith.addi %arg29, %4 : index
        %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %34:5 = scf.for %arg34 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg35 = %32, %arg36 = %31, %arg37 = %arg31, %arg38 = %arg32, %arg39 = %arg33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
          %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %36 = arith.addi %arg36, %4 : index
          %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          "tts.store"(%35, %29) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %39 = arith.addi %arg39, %4 : index
          %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%40, %33) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %41 = arith.addi %39, %4 : index
          %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %43 = arith.addi %41, %4 : index
          %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          scf.yield %37, %36, %38, %44, %43 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
        }
        scf.yield %34#0, %34#1, %33, %34#2, %34#3, %34#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
      }
      scf.yield %29, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
    }
    scf.yield %27#2, %27#5, %27#6, %27#0, %27#3 : index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
  }
  %15 = arith.addi %14#0, %4 : index
  scf.yield %15, %14#1, %14#2, %14#3 : index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
}
for op
%c0 = arith.constant 0 : index
%2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
%c0 = arith.constant 0 : index
module {
  tt.func public @nested_who_knows_how_many_levels(%arg0: !tt.ptr<f32>, %arg1: !tt.ptr<f32>, %arg2: i32, %arg3: i32) attributes {noinline = false} {
    %c0_i32 = arith.constant 0 : i32
    %c0_i32_0 = arith.constant 0 : i32
    %c0 = arith.constant 0 : index
    %c1_i32 = arith.constant 1 : i32
    %c0_i32_1 = arith.constant 0 : i32
    %c2_i32 = arith.constant 2 : i32
    %0 = arith.index_cast %arg2 : i32 to index
    %1 = arith.index_cast %arg3 : i32 to index
    %2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
    %3 = arith.muli %arg3, %c2_i32 : i32
    %4 = arith.index_cast %3 : i32 to index
    %5:3 = scf.for %arg4 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg5 = %c0, %arg6 = %2, %arg7 = %c0) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
      %6 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg5, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
      %7 = "tts.load"(%6) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %8:4 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %arg5, %arg10 = %arg6, %arg11 = %arg7, %arg12 = %7) -> (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
        %11 = arith.addi %arg9, %4 : index
        %12 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%11, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %14:5 = scf.for %arg13 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg14 = %11, %arg15 = %arg10, %arg16 = %arg11, %arg17 = %arg12, %arg18 = %13) -> (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
          %16 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg16, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %17 = arith.addi %arg14, %4 : index
          %18 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%17, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %19 = "tts.load"(%18) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          "tts.store"(%16, %arg17) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %20 = arith.addi %arg16, %4 : index
          %21 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%20, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%21, %arg18) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %22 = arith.addi %20, %4 : index
          %23 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          "tts.store"(%23, %19) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
          %24 = arith.addi %22, %4 : index
          %25 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%24, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %26:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %arg17, %arg21 = %18, %arg22 = %17, %arg23 = %arg18, %arg24 = %19, %arg25 = %25, %arg26 = %24) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
            %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            %30:7 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26, %arg34 = %29) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
              %31 = arith.addi %arg29, %4 : index
              %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %34:7 = scf.for %arg35 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg36 = %32, %arg37 = %31, %arg38 = %arg31, %arg39 = %arg32, %arg40 = %arg33, %arg41 = %arg34, %arg42 = %33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
                %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg40, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %36 = arith.addi %arg37, %4 : index
                %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                "tts.store"(%35, %arg41) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %39 = arith.addi %arg40, %4 : index
                %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%40, %arg42) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %41 = arith.addi %39, %4 : index
                %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %43 = arith.addi %41, %4 : index
                %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %45:7 = scf.for %arg43 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg44 = %arg41, %arg45 = %37, %arg46 = %36, %arg47 = %arg42, %arg48 = %38, %arg49 = %44, %arg50 = %43) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                  %46 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg46, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                  %47 = "tts.load"(%46) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  %48:7 = scf.for %arg51 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg52 = %arg45, %arg53 = %arg46, %arg54 = %arg47, %arg55 = %arg48, %arg56 = %arg49, %arg57 = %arg50, %arg58 = %47) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)  : i32 {
                    %49 = arith.addi %arg53, %4 : index
                    %50 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%49, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                    %51 = "tts.load"(%50) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                    %52:7 = scf.for %arg59 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg60 = %50, %arg61 = %49, %arg62 = %arg55, %arg63 = %arg56, %arg64 = %arg57, %arg65 = %arg58, %arg66 = %51) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)  : i32 {
                      %53 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg64, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      %54 = arith.addi %arg61, %4 : index
                      %55 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%54, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      %56 = "tts.load"(%55) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                      "tts.store"(%53, %arg65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %57 = arith.addi %arg64, %4 : index
                      %58 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%57, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      "tts.store"(%58, %arg66) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %59 = arith.addi %57, %4 : index
                      %60 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%59, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      "tts.store"(%60, %56) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                      %61 = arith.addi %59, %4 : index
                      %62 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%61, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                      %63:7 = scf.for %arg67 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg68 = %arg65, %arg69 = %55, %arg70 = %54, %arg71 = %arg66, %arg72 = %56, %arg73 = %62, %arg74 = %61) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                        %64 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg70, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                        %65 = "tts.load"(%64) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                        %66:6 = scf.for %arg75 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg76 = %arg69, %arg77 = %arg70, %arg78 = %arg71, %arg79 = %arg72, %arg80 = %arg73, %arg81 = %arg74) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                          %67 = arith.addi %arg77, %4 : index
                          %68 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%67, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                          %69 = "tts.load"(%68) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                          %70:5 = scf.for %arg82 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg83 = %68, %arg84 = %67, %arg85 = %arg79, %arg86 = %arg80, %arg87 = %arg81) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                            %71 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg87, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                            %72 = arith.addi %arg84, %4 : index
                            %73 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%72, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                            %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                            "tts.store"(%71, %65) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                            %75 = arith.addi %arg87, %4 : index
                            %76 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%75, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                            "tts.store"(%76, %69) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                            %77 = arith.addi %75, %4 : index
                            %78 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%77, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                            "tts.store"(%78, %74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                            %79 = arith.addi %77, %4 : index
                            %80 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%79, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                            scf.yield %73, %72, %74, %80, %79 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                          }
                          scf.yield %70#0, %70#1, %69, %70#2, %70#3, %70#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                        }
                        scf.yield %65, %66#0, %66#1, %66#2, %66#3, %66#4, %66#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                      }
                      scf.yield %63#1, %63#2, %63#4, %63#5, %63#6, %63#0, %63#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
                    }
                    scf.yield %52#0, %52#1, %52#6, %52#2, %52#3, %52#4, %52#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
                  }
                  scf.yield %48#6, %48#0, %48#1, %48#2, %48#3, %48#4, %48#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
                }
                scf.yield %45#1, %45#2, %45#4, %45#5, %45#6, %45#0, %45#3 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
              }
              scf.yield %34#0, %34#1, %34#6, %34#2, %34#3, %34#4, %34#5 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
            }
            scf.yield %30#6, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
          }
          %27:7 = scf.for %arg19 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg20 = %26#0, %arg21 = %26#1, %arg22 = %26#2, %arg23 = %26#3, %arg24 = %26#4, %arg25 = %26#5, %arg26 = %26#6) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
            %28 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg22, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %29 = "tts.load"(%28) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            %30:6 = scf.for %arg27 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg28 = %arg21, %arg29 = %arg22, %arg30 = %arg23, %arg31 = %arg24, %arg32 = %arg25, %arg33 = %arg26) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
              %31 = arith.addi %arg29, %4 : index
              %32 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%31, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
              %33 = "tts.load"(%32) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %34:5 = scf.for %arg34 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg35 = %32, %arg36 = %31, %arg37 = %arg31, %arg38 = %arg32, %arg39 = %arg33) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
                %35 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %36 = arith.addi %arg36, %4 : index
                %37 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%36, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                %38 = "tts.load"(%37) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                "tts.store"(%35, %29) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %39 = arith.addi %arg39, %4 : index
                %40 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%39, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%40, %33) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %41 = arith.addi %39, %4 : index
                %42 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%41, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                "tts.store"(%42, %38) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                %43 = arith.addi %41, %4 : index
                %44 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%43, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
                scf.yield %37, %36, %38, %44, %43 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
              }
              scf.yield %34#0, %34#1, %33, %34#2, %34#3, %34#4 : tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
            }
            scf.yield %29, %30#0, %30#1, %30#2, %30#3, %30#4, %30#5 : tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index
          }
          scf.yield %27#2, %27#5, %27#6, %27#0, %27#3 : index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>
        }
        %15 = arith.addi %14#0, %4 : index
        scf.yield %15, %14#1, %14#2, %14#3 : index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>
      }
      %9:3 = scf.for %arg8 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg9 = %8#0, %arg10 = %8#1, %arg11 = %8#2) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
        %11 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg9, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
        %12 = "tts.load"(%11) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %13:3 = scf.for %arg12 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg13 = %arg9, %arg14 = %arg10, %arg15 = %arg11) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
          %15 = arith.addi %arg13, %4 : index
          %16 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%15, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
          %17 = "tts.load"(%16) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          %18:3 = scf.for %arg16 = %c0_i32_1 to %c2_i32 step %c1_i32 iter_args(%arg17 = %15, %arg18 = %arg14, %arg19 = %arg15) -> (index, tensor<2x2x!tt.ptr<f32>>, index)  : i32 {
            %19 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%arg19, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %20 = arith.addi %arg17, %4 : index
            %21 = tts.make_tptr %arg0 to sizes: [2, 2], strides: [%0, %1], offsets: [%20, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            %22 = "tts.load"(%21) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            "tts.store"(%19, %12) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %23 = arith.addi %arg19, %4 : index
            %24 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%23, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%24, %17) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %25 = arith.addi %23, %4 : index
            %26 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%25, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%26, %22) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %27 = arith.addi %25, %4 : index
            %28 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [%27, %c0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
            scf.yield %20, %28, %27 : index, tensor<2x2x!tt.ptr<f32>>, index
          }
          scf.yield %18#0, %18#1, %18#2 : index, tensor<2x2x!tt.ptr<f32>>, index
        }
        %14 = arith.addi %13#0, %4 : index
        scf.yield %14, %13#1, %13#2 : index, tensor<2x2x!tt.ptr<f32>>, index
      }
      %10 = arith.addi %9#0, %4 : index
      scf.yield %10, %9#1, %9#2 : index, tensor<2x2x!tt.ptr<f32>>, index
    }
    tt.return
  }
}
block count: 1
block arg count: 4
init arg count: 3
reusing type for 0 to
i32
reusing type for 1 to
index
mapping 2 to
tensor<2x2x!tt.ptr<f32>>
%2 = tts.make_tptr %arg1 to sizes: [2, 2], strides: [%0, %1], offsets: [0, 0], shape: [0, 0], order: [] : <f32> to tensor<2x2x!tt.ptr<f32>>
reusing type for 3 to
index
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir:32:13: error: failed to legalize operation 'scf.for' that was explicitly marked illegal
    %24:2 = scf.for %arg4 = %c0_i32 to %c2_i32 step %c1_i32 iter_args(%arg5 = %11, %arg6 = %15) -> (tensor<2x2x!tt.ptr<f32>>, tensor<2x2x!tt.ptr<f32>>)  : i32 {
            ^
/home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir:32:13: note: see current operation: 
%11:3 = "scf.for"(%4, %5, %3, %2, %8, %2) ({
^bb0(%arg4: i32, %arg5: index, %arg6: tensor<2x2x!tt.ptr<f32>>, %arg7: index):
  %12 = "tts.make_tptr"(%arg0, %6, %7, %arg5, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
  %13 = "tts.load"(%12) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
  %14:4 = "scf.for"(%4, %5, %3, %arg5, %arg6, %arg7, %13) ({
  ^bb0(%arg20: i32, %arg21: index, %arg22: tensor<2x2x!tt.ptr<f32>>, %arg23: index, %arg24: tensor<2x2xf32>):
    %35 = "arith.addi"(%arg21, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
    %36 = "tts.make_tptr"(%arg0, %6, %7, %35, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
    %37 = "tts.load"(%36) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    %38:5 = "scf.for"(%4, %5, %3, %35, %arg22, %arg23, %arg24, %37) ({
    ^bb0(%arg25: i32, %arg26: index, %arg27: tensor<2x2x!tt.ptr<f32>>, %arg28: index, %arg29: tensor<2x2xf32>, %arg30: tensor<2x2xf32>):
      %40 = "tts.make_tptr"(%arg1, %6, %7, %arg28, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
      %41 = "arith.addi"(%arg26, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %42 = "tts.make_tptr"(%arg0, %6, %7, %41, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
      %43 = "tts.load"(%42) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      "tts.store"(%40, %arg29) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %44 = "arith.addi"(%arg28, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %45 = "tts.make_tptr"(%arg1, %6, %7, %44, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%45, %arg30) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %46 = "arith.addi"(%44, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %47 = "tts.make_tptr"(%arg1, %6, %7, %46, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
      "tts.store"(%47, %43) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
      %48 = "arith.addi"(%46, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %49 = "tts.make_tptr"(%arg1, %6, %7, %48, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
      %50:7 = "scf.for"(%4, %5, %3, %arg29, %42, %41, %arg30, %43, %49, %48) ({
      ^bb0(%arg52: i32, %arg53: tensor<2x2xf32>, %arg54: tensor<2x2x!tt.ptr<f32>>, %arg55: index, %arg56: tensor<2x2xf32>, %arg57: tensor<2x2xf32>, %arg58: tensor<2x2x!tt.ptr<f32>>, %arg59: index):
        %69 = "tts.make_tptr"(%arg0, %6, %7, %arg55, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
        %70 = "tts.load"(%69) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %71:7 = "scf.for"(%4, %5, %3, %arg54, %arg55, %arg56, %arg57, %arg58, %arg59, %70) ({
        ^bb0(%arg60: i32, %arg61: tensor<2x2x!tt.ptr<f32>>, %arg62: index, %arg63: tensor<2x2xf32>, %arg64: tensor<2x2xf32>, %arg65: tensor<2x2x!tt.ptr<f32>>, %arg66: index, %arg67: tensor<2x2xf32>):
          %72 = "arith.addi"(%arg62, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
          %73 = "tts.make_tptr"(%arg0, %6, %7, %72, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
          %74 = "tts.load"(%73) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          %75:7 = "scf.for"(%4, %5, %3, %73, %72, %arg64, %arg65, %arg66, %arg67, %74) ({
          ^bb0(%arg68: i32, %arg69: tensor<2x2x!tt.ptr<f32>>, %arg70: index, %arg71: tensor<2x2xf32>, %arg72: tensor<2x2x!tt.ptr<f32>>, %arg73: index, %arg74: tensor<2x2xf32>, %arg75: tensor<2x2xf32>):
            %76 = "tts.make_tptr"(%arg1, %6, %7, %arg73, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
            %77 = "arith.addi"(%arg70, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
            %78 = "tts.make_tptr"(%arg0, %6, %7, %77, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
            %79 = "tts.load"(%78) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            "tts.store"(%76, %arg74) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %80 = "arith.addi"(%arg73, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
            %81 = "tts.make_tptr"(%arg1, %6, %7, %80, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%81, %arg75) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %82 = "arith.addi"(%80, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
            %83 = "tts.make_tptr"(%arg1, %6, %7, %82, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%83, %79) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %84 = "arith.addi"(%82, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
            %85 = "tts.make_tptr"(%arg1, %6, %7, %84, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
            %86:7 = "scf.for"(%4, %5, %3, %arg74, %78, %77, %arg75, %79, %85, %84) ({
            ^bb0(%arg76: i32, %arg77: tensor<2x2xf32>, %arg78: tensor<2x2x!tt.ptr<f32>>, %arg79: index, %arg80: tensor<2x2xf32>, %arg81: tensor<2x2xf32>, %arg82: tensor<2x2x!tt.ptr<f32>>, %arg83: index):
              %87 = "tts.make_tptr"(%arg0, %6, %7, %arg79, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
              %88 = "tts.load"(%87) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
              %89:7 = "scf.for"(%4, %5, %3, %arg78, %arg79, %arg80, %arg81, %arg82, %arg83, %88) ({
              ^bb0(%arg84: i32, %arg85: tensor<2x2x!tt.ptr<f32>>, %arg86: index, %arg87: tensor<2x2xf32>, %arg88: tensor<2x2xf32>, %arg89: tensor<2x2x!tt.ptr<f32>>, %arg90: index, %arg91: tensor<2x2xf32>):
                %90 = "arith.addi"(%arg86, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
                %91 = "tts.make_tptr"(%arg0, %6, %7, %90, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
                %92 = "tts.load"(%91) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                %93:7 = "scf.for"(%4, %5, %3, %91, %90, %arg88, %arg89, %arg90, %arg91, %92) ({
                ^bb0(%arg92: i32, %arg93: tensor<2x2x!tt.ptr<f32>>, %arg94: index, %arg95: tensor<2x2xf32>, %arg96: tensor<2x2x!tt.ptr<f32>>, %arg97: index, %arg98: tensor<2x2xf32>, %arg99: tensor<2x2xf32>):
                  %94 = "tts.make_tptr"(%arg1, %6, %7, %arg97, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
                  %95 = "arith.addi"(%arg94, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
                  %96 = "tts.make_tptr"(%arg0, %6, %7, %95, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
                  %97 = "tts.load"(%96) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                  "tts.store"(%94, %arg98) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %98 = "arith.addi"(%arg97, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
                  %99 = "tts.make_tptr"(%arg1, %6, %7, %98, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%99, %arg99) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %100 = "arith.addi"(%98, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
                  %101 = "tts.make_tptr"(%arg1, %6, %7, %100, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
                  "tts.store"(%101, %97) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                  %102 = "arith.addi"(%100, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
                  %103 = "tts.make_tptr"(%arg1, %6, %7, %102, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
                  %104:7 = "scf.for"(%4, %5, %3, %arg98, %96, %95, %arg99, %97, %103, %102) ({
                  ^bb0(%arg100: i32, %arg101: tensor<2x2xf32>, %arg102: tensor<2x2x!tt.ptr<f32>>, %arg103: index, %arg104: tensor<2x2xf32>, %arg105: tensor<2x2xf32>, %arg106: tensor<2x2x!tt.ptr<f32>>, %arg107: index):
                    %105 = "tts.make_tptr"(%arg0, %6, %7, %arg103, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
                    %106 = "tts.load"(%105) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                    %107:6 = "scf.for"(%4, %5, %3, %arg102, %arg103, %arg104, %arg105, %arg106, %arg107) ({
                    ^bb0(%arg108: i32, %arg109: tensor<2x2x!tt.ptr<f32>>, %arg110: index, %arg111: tensor<2x2xf32>, %arg112: tensor<2x2xf32>, %arg113: tensor<2x2x!tt.ptr<f32>>, %arg114: index):
                      %108 = "arith.addi"(%arg110, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
                      %109 = "tts.make_tptr"(%arg0, %6, %7, %108, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
                      %110 = "tts.load"(%109) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                      %111:5 = "scf.for"(%4, %5, %3, %109, %108, %arg112, %arg113, %arg114) ({
                      ^bb0(%arg115: i32, %arg116: tensor<2x2x!tt.ptr<f32>>, %arg117: index, %arg118: tensor<2x2xf32>, %arg119: tensor<2x2x!tt.ptr<f32>>, %arg120: index):
                        %112 = "tts.make_tptr"(%arg1, %6, %7, %arg120, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
                        %113 = "arith.addi"(%arg117, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
                        %114 = "tts.make_tptr"(%arg0, %6, %7, %113, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
                        %115 = "tts.load"(%114) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
                        "tts.store"(%112, %106) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                        %116 = "arith.addi"(%arg120, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
                        %117 = "tts.make_tptr"(%arg1, %6, %7, %116, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
                        "tts.store"(%117, %110) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                        %118 = "arith.addi"(%116, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
                        %119 = "tts.make_tptr"(%arg1, %6, %7, %118, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
                        "tts.store"(%119, %115) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
                        %120 = "arith.addi"(%118, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
                        %121 = "tts.make_tptr"(%arg1, %6, %7, %120, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
                        "scf.yield"(%114, %113, %115, %121, %120) : (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> ()
                      }) : (i32, i32, i32, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)
                      "scf.yield"(%111#0, %111#1, %110, %111#2, %111#3, %111#4) : (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> ()
                    }) : (i32, i32, i32, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)
                    "scf.yield"(%106, %107#0, %107#1, %107#2, %107#3, %107#4, %107#5) : (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> ()
                  }) : (i32, i32, i32, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)
                  "scf.yield"(%104#1, %104#2, %104#4, %104#5, %104#6, %104#0, %104#3) : (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>) -> ()
                }) : (i32, i32, i32, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)
                "scf.yield"(%93#0, %93#1, %93#6, %93#2, %93#3, %93#4, %93#5) : (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>) -> ()
              }) : (i32, i32, i32, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)
              "scf.yield"(%89#6, %89#0, %89#1, %89#2, %89#3, %89#4, %89#5) : (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> ()
            }) : (i32, i32, i32, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)
            "scf.yield"(%86#1, %86#2, %86#4, %86#5, %86#6, %86#0, %86#3) : (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>) -> ()
          }) : (i32, i32, i32, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)
          "scf.yield"(%75#0, %75#1, %75#6, %75#2, %75#3, %75#4, %75#5) : (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>) -> ()
        }) : (i32, i32, i32, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)
        "scf.yield"(%71#6, %71#0, %71#1, %71#2, %71#3, %71#4, %71#5) : (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> ()
      }) : (i32, i32, i32, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)
      %51:7 = "scf.for"(%4, %5, %3, %50#0, %50#1, %50#2, %50#3, %50#4, %50#5, %50#6) ({
      ^bb0(%arg31: i32, %arg32: tensor<2x2xf32>, %arg33: tensor<2x2x!tt.ptr<f32>>, %arg34: index, %arg35: tensor<2x2xf32>, %arg36: tensor<2x2xf32>, %arg37: tensor<2x2x!tt.ptr<f32>>, %arg38: index):
        %52 = "tts.make_tptr"(%arg0, %6, %7, %arg34, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
        %53 = "tts.load"(%52) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        %54:6 = "scf.for"(%4, %5, %3, %arg33, %arg34, %arg35, %arg36, %arg37, %arg38) ({
        ^bb0(%arg39: i32, %arg40: tensor<2x2x!tt.ptr<f32>>, %arg41: index, %arg42: tensor<2x2xf32>, %arg43: tensor<2x2xf32>, %arg44: tensor<2x2x!tt.ptr<f32>>, %arg45: index):
          %55 = "arith.addi"(%arg41, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
          %56 = "tts.make_tptr"(%arg0, %6, %7, %55, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
          %57 = "tts.load"(%56) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
          %58:5 = "scf.for"(%4, %5, %3, %56, %55, %arg43, %arg44, %arg45) ({
          ^bb0(%arg46: i32, %arg47: tensor<2x2x!tt.ptr<f32>>, %arg48: index, %arg49: tensor<2x2xf32>, %arg50: tensor<2x2x!tt.ptr<f32>>, %arg51: index):
            %59 = "tts.make_tptr"(%arg1, %6, %7, %arg51, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
            %60 = "arith.addi"(%arg48, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
            %61 = "tts.make_tptr"(%arg0, %6, %7, %60, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
            %62 = "tts.load"(%61) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
            "tts.store"(%59, %53) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %63 = "arith.addi"(%arg51, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
            %64 = "tts.make_tptr"(%arg1, %6, %7, %63, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%64, %57) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %65 = "arith.addi"(%63, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
            %66 = "tts.make_tptr"(%arg1, %6, %7, %65, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
            "tts.store"(%66, %62) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
            %67 = "arith.addi"(%65, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
            %68 = "tts.make_tptr"(%arg1, %6, %7, %67, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
            "scf.yield"(%61, %60, %62, %68, %67) : (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> ()
          }) : (i32, i32, i32, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)
          "scf.yield"(%58#0, %58#1, %57, %58#2, %58#3, %58#4) : (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> ()
        }) : (i32, i32, i32, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> (tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)
        "scf.yield"(%53, %54#0, %54#1, %54#2, %54#3, %54#4, %54#5) : (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> ()
      }) : (i32, i32, i32, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index) -> (tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>, tensor<2x2x!tt.ptr<f32>>, index)
      "scf.yield"(%51#2, %51#5, %51#6, %51#0, %51#3) : (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>) -> ()
    }) : (i32, i32, i32, index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>) -> (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>, tensor<2x2xf32>)
    %39 = "arith.addi"(%38#0, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
    "scf.yield"(%39, %38#1, %38#2, %38#3) : (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>) -> ()
  }) : (i32, i32, i32, index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>) -> (index, tensor<2x2x!tt.ptr<f32>>, index, tensor<2x2xf32>)
  %15:3 = "scf.for"(%4, %5, %3, %14#0, %14#1, %14#2) ({
  ^bb0(%arg8: i32, %arg9: index, %arg10: tensor<2x2x!tt.ptr<f32>>, %arg11: index):
    %17 = "tts.make_tptr"(%arg0, %6, %7, %arg9, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
    %18 = "tts.load"(%17) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
    %19:3 = "scf.for"(%4, %5, %3, %arg9, %arg10, %arg11) ({
    ^bb0(%arg12: i32, %arg13: index, %arg14: tensor<2x2x!tt.ptr<f32>>, %arg15: index):
      %21 = "arith.addi"(%arg13, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
      %22 = "tts.make_tptr"(%arg0, %6, %7, %21, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
      %23 = "tts.load"(%22) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
      %24:3 = "scf.for"(%4, %5, %3, %21, %arg14, %arg15) ({
      ^bb0(%arg16: i32, %arg17: index, %arg18: tensor<2x2x!tt.ptr<f32>>, %arg19: index):
        %25 = "tts.make_tptr"(%arg1, %6, %7, %arg19, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
        %26 = "arith.addi"(%arg17, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
        %27 = "tts.make_tptr"(%arg0, %6, %7, %26, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
        %28 = "tts.load"(%27) <{operandSegmentSizes = array<i32: 1, 0, 0>, static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>) -> tensor<2x2xf32>
        "tts.store"(%25, %18) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %29 = "arith.addi"(%arg19, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
        %30 = "tts.make_tptr"(%arg1, %6, %7, %29, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
        "tts.store"(%30, %23) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %31 = "arith.addi"(%29, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
        %32 = "tts.make_tptr"(%arg1, %6, %7, %31, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
        "tts.store"(%32, %28) <{static_mask_dims = array<i64>}> : (tensor<2x2x!tt.ptr<f32>>, tensor<2x2xf32>) -> ()
        %33 = "arith.addi"(%31, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
        %34 = "tts.make_tptr"(%arg1, %6, %7, %33, %2) <{operandSegmentSizes = array<i32: 1, 2, 2, 0>, order = array<i32>, sizes = array<i64: 2, 2>, static_offsets = array<i64: -9223372036854775808, -9223372036854775808>, static_shape = array<i64: 0, 0>, static_strides = array<i64: -9223372036854775808, -9223372036854775808>}> : (!tt.ptr<f32>, index, index, index, index) -> tensor<2x2x!tt.ptr<f32>>
        "scf.yield"(%26, %34, %33) : (index, tensor<2x2x!tt.ptr<f32>>, index) -> ()
      }) : (i32, i32, i32, index, tensor<2x2x!tt.ptr<f32>>, index) -> (index, tensor<2x2x!tt.ptr<f32>>, index)
      "scf.yield"(%24#0, %24#1, %24#2) : (index, tensor<2x2x!tt.ptr<f32>>, index) -> ()
    }) : (i32, i32, i32, index, tensor<2x2x!tt.ptr<f32>>, index) -> (index, tensor<2x2x!tt.ptr<f32>>, index)
    %20 = "arith.addi"(%19#0, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
    "scf.yield"(%20, %19#1, %19#2) : (index, tensor<2x2x!tt.ptr<f32>>, index) -> ()
  }) : (i32, i32, i32, index, tensor<2x2x!tt.ptr<f32>>, index) -> (index, tensor<2x2x!tt.ptr<f32>>, index)
  %16 = "arith.addi"(%15#0, %10) <{overflowFlags = #arith.overflow<none>}> : (index, index) -> index
  "scf.yield"(%16, %15#1, %15#2) : (index, tensor<2x2x!tt.ptr<f32>>, index) -> ()
}) : (i32, i32, i32, index, tensor<2x2x!tt.ptr<f32>>, index) -> (index, tensor<2x2x!tt.ptr<f32>>, index)
FileCheck error: '<stdin>' is empty.
FileCheck command line:  FileCheck /home/nhat/github/triton_shared/test/Conversion/StructuredToMemref/ridiculously_nested_loops.mlir

--

********************
********************
Failed Tests (27):
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_chain.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_for_2d.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/addptr_scalar_loopback.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/block_ptr_complex_offset.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_binary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_ternary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_1d_elemwise_arith_unary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_binary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_ternary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_2d_elemwise_arith_unary.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_addi_reduce.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_fp_reduce.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_minmax_reduce.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/convert_splat_float.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/nested_loops.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/reducemax_32_256_bf16.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_middle_dim.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/reducesum_scalar.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/ridiculously_nested_loops.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_loop_iterargs.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_nested_loop.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/scalar_store_no_iterargs.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_side_by_side.mlir
  TRITON-SHARED :: Conversion/StructuredToMemref/wraparound_stacked.mlir


Testing Time: 2.41s

Total Discovered Tests: 215
  Passed           : 185 (86.05%)
  Expectedly Failed:   3 (1.40%)
  Failed           :  27 (12.56%)
